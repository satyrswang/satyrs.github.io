<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AB分流</title>
    <url>/2021/03/11/AB%E5%88%86%E6%B5%81/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Apriori_fptree</title>
    <url>/2021/03/11/Apriori-fptree/</url>
    <content><![CDATA[<ul>
<li><p>Apriori {</p>
</li>
<li><p>input<br>{ID1:[item1,item2…],ID2:[item3,item2…],…}</p>
</li>
<li><p>output<br>item1-&gt;item2,item3…</p>
</li>
<li><p>math<br>频率及条件概率的简单应用<br>支持度: 频数/样本总量<br>置信度: 条件概率<br>如果子集不为频繁集则超集一定不为；反之如果超集是频繁集则子集均为频繁集。</p>
</li>
<li><p>parameters<br><code>minSupport</code><br><code>minConf</code></p>
</li>
<li><p>过程<br>1-4完成了频繁集的搜寻，5及之后产生规则。</p>
</li>
</ul>
<ol>
<li><p><code>list</code>存放每个用户的  <code>itemset</code>，生成[[],[]]存放所有item并排序，<code>map(frozenset, C1)</code></p>
</li>
<li><p>第一轮遍历，生成一个<code>list</code>存放所有支持度大于<code>minSupport</code>，大于则<code>insert(0,key)</code>。遍历的函数<code>scanD</code>所生成<code>list</code>的元素是<code>frozenset</code>。如果<code>can.issubset(tid)</code>且<code>！ssCnt.has_key(can)</code>则加入到<code>supportData</code>。</p>
</li>
<li><p>list存放所有频繁物品集，<code>supportData</code>存放所有计算过的物品集的支持度，以<code>frozenset</code>作为<code>key</code>。两者更新的过程是在<code>apriori</code>中循环调用<code>aprioriGen</code>和<code>scanD </code>，再更新。直到<code>scanD</code>得到的频繁物品集为空。</p>
</li>
<li><p><code>aprioriGen</code>的过程，两层循环，遍历上一个(即物品集中个数为目前需要产生的个数-1)频繁物品集，<code>L1 = list(Lk[i])[:k-2];L2 = list(Lk[j])[:k-2]</code>取前k-2项比较，若相同则<code>retList.append(Lk[i] | Lk[j])</code>将物品集union。是一个merging过程。</p>
</li>
<li><p>如果频繁集<code>frozenset</code>中item多于2，先<code>rulesFromConseq</code>再<code>calcConf</code>。<code>rulesFromConseq</code>是个递归过程，</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def rulesFromConseq(freqSet, H, supportData, brl, minConf&#x3D;0.7):</span><br><span class="line">    m &#x3D; len(H[0])</span><br><span class="line">    if (len(freqSet) &gt; (m + 1)): #停止条件</span><br><span class="line">        Hmp1 &#x3D; aprioriGen(H, m+1)</span><br><span class="line">        Hmp1 &#x3D; calcConf(freqSet, Hmp1, supportData, brl, minConf)</span><br><span class="line">        if (len(Hmp1) &gt; 1):   #至少需要两个元素才能够merge</span><br><span class="line">            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)</span><br></pre></td></tr></table></figure>
<p>这里一个问题是，如果<code>len(Hmp1) =1</code>，但是<code>len(freqSet) &gt; (len(Hmp1[0]) + 1)</code>仍然成立，因此修改为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def rulesFromConseq(freqSet, H, supportData, brl, minConf&#x3D;0.7):</span><br><span class="line">    m &#x3D; len(H[0])</span><br><span class="line">    if (len(freqSet) &gt; (m + 1)): #停止条件</span><br><span class="line">        if(len(H) &gt; 1):</span><br><span class="line">            Hmp1 &#x3D; aprioriGen(H, m+1)</span><br><span class="line">        Hmp1 &#x3D; calcConf(freqSet, Hmp1, supportData, brl, minConf)</span><br><span class="line">        rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)</span><br></pre></td></tr></table></figure>
<p>}</p>
</li>
</ol>
<ul>
<li><p>fptree {</p>
</li>
<li><p>概念<br>闭项：超集的支持度为s，子集的支持度都不超过s。<br>条件模式基： 即一个item追溯到root的所有路径<br>条件fp树 ： 即根据条件模式基创建的tree<br><code>myCondTree, myHead = createTree(condPattBases, minSup)</code></p>
</li>
<li><p>准备<br><code>headertable</code> : <code>dict</code>，<code>value</code>为<code>[count,treeNode]</code><br><code>treeNode</code> : <code>class</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def __init__(self, nameValue, numOccur, parentNode):</span><br><span class="line">     self.name &#x3D; nameValue</span><br><span class="line">     self.count &#x3D; numOccur</span><br><span class="line">     self.nodeLink &#x3D; None</span><br><span class="line">     self.parent &#x3D; parentNode      </span><br><span class="line">     self.children &#x3D; &#123;&#125; </span><br></pre></td></tr></table></figure>
<p>主要方法：<code>createTree</code> <code>updateTree</code>  <code>mineTree</code><br>辅助方法：<code>updateHeader</code> <code>findPrefixPath</code> <code>ascendTree</code></p>
</li>
<li><p>过程</p>
</li>
</ul>
<ol>
<li><code>createTree</code>首先第一次遍历计算<code>count</code>，<code>headerTable[item] = headerTable.get(item, 0) + dataSet[trans]</code>将<code>count</code>简单赋值为1。注意到这里的dataSet类型。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def createInitSet(dataSet):</span><br><span class="line">    retDict &#x3D; &#123;&#125;</span><br><span class="line">    for trans in dataSet:</span><br><span class="line">        retDict[frozenset(trans)] &#x3D; 1</span><br><span class="line">    return retDict</span><br></pre></td></tr></table></figure>
获得<code>freqItemSet = set(headerTable.keys())</code>后第二次遍历。先对item排序，<code>orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p: p[1], reverse=True)] </code>，再<code>updateTree(orderedItems, retTree, headerTable, count)</code>。</li>
<li><code>updateTree</code>，这里就是普通的对树的操作，也是递归。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if len(items) &gt; 1:#call updateTree() with remaining ordered items</span><br><span class="line">        updateTree(items[1::], inTree.children[items[0]], headerTable, count)</span><br></pre></td></tr></table></figure>
唯一注意之处，需要<code>updateHeader</code>。</li>
<li><code>mineTree</code>和<code>Apriori</code>中的<code>rulesFromConseq </code>一样较复杂，包含递归。先生成条件模式基，再生成conditional-fptree，再递归。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if myHead !&#x3D; None:                  </span><br><span class="line">   mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList)</span><br></pre></td></tr></table></figure>
循环递归mineTree的过程即生成规则过程，直到频繁2项集都得到。<br>}</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>CRF</title>
    <url>/2021/03/09/CRF/</url>
    <content><![CDATA[<br>

<p>本文主要介绍 线性链的CRF。应用于标注问题。<br>介绍：概率图模型、CRF的定义和表示方法，以及三个基本问题：概率计算、学习和预测。</p>
<a id="more"></a>

<br>

<h3 id="概率无向图模型"><a href="#概率无向图模型" class="headerlink" title="概率无向图模型"></a>概率无向图模型</h3><p>1、无向图表示的随机变量之间：成对马尔科夫性、局部马尔科夫性、全局马尔科夫性。</p>
<p>2、概率无向图模型定义：<br>联合概率满足上面的三个马尔科夫性，则称此联合概率分布为概率无向图模型或者马尔科夫随机出。</p>
<p>3、团与最大团</p>
<p>4、因子分解<br>联合分布表示为 最大团上的随机变量的函数的乘积形式的操作，称为概率无向图模型的因子分解。</p>
<p>这个函数，就是 势函数。要求是正的。一般为指数函数。</p>
<p>5、条件随机场</p>
<p>给定随机变量x的条件下，随机变量y的马尔科夫随机场。</p>
<p>学习时，学习条件概率模型。预测时利用条件概率，求得最大输出序列y。</p>
<p>定义：</p>
<p><img src="/2021/03/09/CRF/crf.png" alt="crf"></p>
<!-- <img src=crf.png width=80% height=300> -->

<p><img src="/2021/03/09/CRF/lccrf.png" alt="lccrf"></p>
<!-- <img src=lccrf.png width=80% height=300> -->


<br>

<br>

<h3 id="三种表达形式"><a href="#三种表达形式" class="headerlink" title="三种表达形式"></a>三种表达形式</h3><p>1、参数化形式</p>
<p>公式：<br><img src="/2021/03/09/CRF/%E5%8F%82%E6%95%B0%E5%8C%96%E5%85%AC%E5%BC%8F.png" alt="参数化公式"></p>
<!-- <img src=参数化公式.png width=70% height=200> -->


<p>解释如下：<br><img src="/2021/03/09/CRF/%E5%8F%82%E6%95%B0%E5%8C%96%E5%85%AC%E5%BC%8F%E8%A7%A3%E9%87%8A2_1.png" alt="参数化公式解释2_1"></p>
<!-- <img src=参数化公式解释2_1.png width=70% height=200> -->

<p><img src="/2021/03/09/CRF/%E5%8F%82%E6%95%B0%E5%8C%96%E5%85%AC%E5%BC%8F%E8%A7%A3%E9%87%8A2_2.png" alt="参数化公式解释2_2"></p>
<!-- <img src=参数化公式解释2_2.png width=70% height=200> -->


<p>即：<br><img src="/2021/03/09/CRF/%E8%A7%92%E5%BA%A6.png" alt="角度"></p>
<!-- <img src=角度.png width=70% height=200> -->


<p>2、参数化简化的形式推导<br>略</p>
<p>3、矩阵形式<br>例子更清楚：<br><img src="/2021/03/09/CRF/%E7%9F%A9%E9%98%B5%E5%BD%A2%E5%BC%8F%E4%BE%8B%E5%AD%901.png" alt="矩阵形式例子1"><br><img src="/2021/03/09/CRF/%E7%9F%A9%E9%98%B5%E5%BD%A2%E5%BC%8F%E4%BE%8B%E5%AD%902.png" alt="矩阵形式例子2"></p>
<!-- <img src=矩阵形式例子1.png width=70% height=100>
<img src=矩阵形式例子2.png width=70% height=700> -->


<p>矩阵形式推导：<br><img src="/2021/03/09/CRF/%E7%9F%A9%E9%98%B5%E6%8E%A8%E5%AF%BC.png" alt="矩阵推导"></p>
<!-- <img src=矩阵推导.png width=70% height=500> -->


<br>
<br>


<h3 id="三个问题"><a href="#三个问题" class="headerlink" title="三个问题"></a>三个问题</h3><h4 id="模型基本问题"><a href="#模型基本问题" class="headerlink" title="模型基本问题"></a>模型基本问题</h4><p>模型问题包含 learning 和 inference。<br>learning即 parameter estimation。求 θ。<br>inference：<br>(以下 y 为隐变量)<br>1 marginal prob ： 当建模对象为joint dist，求p(xt)即求边缘概率问题。<br>2 conditional prob ： 求 p(x|y)<br>3 MAP inference ： decoding ， 求  y = argmax p(y|x)</p>
<h4 id="CRF-learning"><a href="#CRF-learning" class="headerlink" title="CRF learning"></a>CRF learning</h4><p>1、问题定义<br><img src="/2021/03/09/CRF/learning%E9%97%AE%E9%A2%98%E5%AE%9A%E4%B9%89.png" alt="learning问题定义"></p>
<p>2、todo – 数学推导</p>
<h4 id="CRF-marginal-prob"><a href="#CRF-marginal-prob" class="headerlink" title="CRF marginal prob"></a>CRF marginal prob</h4><p>1、即求 P(yt = i | x)<br>给定x条件下的 隐变量yt 的边缘概率。<br>即 词性标注中，给定一句话，判断出 y1(第一个词)是动词(i)的概率是多少。</p>
<p>2、硬算，复杂度高。指数级计算不可行。<br>简化：</p>
<p>数学转化。<br>用到了变量消除法， sum+product，又叫信念传播，belief propagate。<br>HMM的前向 后向传播也就是belief propagate。</p>
<p><img src="/2021/03/09/CRF/sumproduct.png" alt="sumproduct"><br><img src="/2021/03/09/CRF/sumproduct2.png" alt="sumproduct2"></p>
<h4 id="CRF-decoding"><a href="#CRF-decoding" class="headerlink" title="CRF decoding"></a>CRF decoding</h4><p>求 y的序列，使得 argmax p(y|x)<br>– 类似于 HMM 问题。</p>
]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>Decorator</title>
    <url>/2021/02/04/Decorator/</url>
    <content><![CDATA[<h2 id="functional-programming-concepts"><a href="#functional-programming-concepts" class="headerlink" title="functional programming concepts"></a><strong>functional programming concepts</strong></h2><p>分两类：</p>
<ul>
<li>Function decorators</li>
<li>Class decorators<a id="more"></a></li>
</ul>
<blockquote>
<p>A decorator in Python is any callable Python object that is used to <strong>modify a function or a class</strong>. A reference to a function “func” or a class “C” is passed to a decorator and the decorator returns a modified function or class. The modified functions or classes usually contain calls to the original function “func” or class “C”. </p>
</blockquote>
<h2 id="show-me-the-code"><a href="#show-me-the-code" class="headerlink" title="show me the code"></a><strong>show me the code</strong></h2><ul>
<li><em>参数检查</em><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def argument_test_natural_number(f):</span><br><span class="line">    def helper(x):</span><br><span class="line">        if type(x) &#x3D;&#x3D; int and x &gt; 0:</span><br><span class="line">            return f(x)</span><br><span class="line">        else:</span><br><span class="line">            raise Exception(&quot;Argument is not an integer&quot;)</span><br><span class="line">    return helper</span><br><span class="line">    </span><br><span class="line">@argument_test_natural_number</span><br><span class="line">def factorial(n):</span><br><span class="line">    if n &#x3D;&#x3D; 1:</span><br><span class="line">        return 1</span><br><span class="line">    else:</span><br><span class="line">        return n * factorial(n-1)</span><br><span class="line"></span><br><span class="line">for i in range(1,10):</span><br><span class="line">	print(i, factorial(i))</span><br><span class="line"></span><br><span class="line">print(factorial(-1))</span><br></pre></td></tr></table></figure></li>
<li><em>统计次数</em><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def call_counter(func):</span><br><span class="line">    def helper(*args, **kwargs):</span><br><span class="line">        helper.calls +&#x3D; 1</span><br><span class="line">        return func(*args, **kwargs)</span><br><span class="line">    helper.calls &#x3D; 0</span><br><span class="line"></span><br><span class="line">    return helper</span><br><span class="line"></span><br><span class="line">@call_counter</span><br><span class="line">def succ(x):</span><br><span class="line">    return x + 1</span><br><span class="line"></span><br><span class="line">@call_counter</span><br><span class="line">def mul1(x, y&#x3D;1):</span><br><span class="line">    return x*y + 1</span><br><span class="line"></span><br><span class="line">print(succ.calls)</span><br><span class="line">for i in range(10):</span><br><span class="line">    succ(i)</span><br><span class="line">mul1(3, 4)</span><br><span class="line">mul1(4)</span><br><span class="line">mul1(y&#x3D;3, x&#x3D;2)</span><br><span class="line">    </span><br><span class="line">print(succ.calls)</span><br><span class="line">print(mul1.calls)</span><br></pre></td></tr></table></figure></li>
<li><em>含参数的decorator</em><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def greeting(expr):</span><br><span class="line">    def greeting_decorator(func):</span><br><span class="line">        def function_wrapper(x):</span><br><span class="line">            print(expr + &quot;, &quot; + func.__name__ + &quot; returns:&quot;)</span><br><span class="line">            func(x)</span><br><span class="line">        return function_wrapper</span><br><span class="line">    return greeting_decorator</span><br><span class="line"></span><br><span class="line">@greeting(&quot;-wyq-&quot;)</span><br><span class="line">def foo(x):</span><br><span class="line">    print(42)</span><br><span class="line"></span><br><span class="line">foo(&quot;Hi&quot;)</span><br></pre></td></tr></table></figure></li>
<li><em>using import 要注意变量的域</em></li>
</ul>
<p>greeting_decorator.py  没用functools的版本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def greeting(func):</span><br><span class="line">    def function_wrapper(x):</span><br><span class="line">        &quot;&quot;&quot; function_wrapper of greeting &quot;&quot;&quot;</span><br><span class="line">        print(&quot;Hi, &quot; + func.__name__ + &quot; returns:&quot;)</span><br><span class="line">        return func(x)</span><br><span class="line">    function_wrapper.__name__ &#x3D; func.__name__</span><br><span class="line">    function_wrapper.__doc__ &#x3D; func.__doc__</span><br><span class="line">    function_wrapper.__module__ &#x3D; func.__module__</span><br><span class="line">    return function_wrapper</span><br></pre></td></tr></table></figure>
<p>anotherfile.py:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from greeting_decorator import greeting</span><br><span class="line"></span><br><span class="line">@greeting</span><br><span class="line">def f(x):</span><br><span class="line">    &quot;&quot;&quot; just some silly function &quot;&quot;&quot;</span><br><span class="line">    return x + 4</span><br><span class="line"></span><br><span class="line">f(10)</span><br><span class="line">print(&quot;function name: &quot; + f.__name__)</span><br><span class="line">print(&quot;docstring: &quot; + f.__doc__)</span><br><span class="line">print(&quot;module name: &quot; + f.__module__)</span><br></pre></td></tr></table></figure>
<p>greeting_decorator.py</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from functools import wraps</span><br><span class="line"></span><br><span class="line">def greeting(func):</span><br><span class="line">    @wraps(func)</span><br><span class="line">    def function_wrapper(x):</span><br><span class="line">        &quot;&quot;&quot; function_wrapper of greeting &quot;&quot;&quot;</span><br><span class="line">        print(&quot;Hi, &quot; + func.__name__ + &quot; returns:&quot;)</span><br><span class="line">        return func(x)</span><br><span class="line">    return function_wrapper</span><br></pre></td></tr></table></figure>
<p>否则将返回</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function name: function_wrapper</span><br><span class="line">docstring:  function_wrapper of greeting </span><br><span class="line">module name: greeting_decorator</span><br></pre></td></tr></table></figure>
<ul>
<li><em><code>__call__</code></em><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class Fibonacci:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.cache &#x3D; &#123;&#125;</span><br><span class="line">    def __call__(self, n):</span><br><span class="line">        if n not in self.cache:</span><br><span class="line">            if n &#x3D;&#x3D; 0:</span><br><span class="line">                self.cache[0] &#x3D; 0</span><br><span class="line">            elif n &#x3D;&#x3D; 1:</span><br><span class="line">                self.cache[1] &#x3D; 1</span><br><span class="line">            else:</span><br><span class="line">                self.cache[n] &#x3D; self.__call__(n-1) + self.__call__(n-2)</span><br><span class="line">        return self.cache[n]</span><br><span class="line"></span><br><span class="line">fib &#x3D; Fibonacci()</span><br><span class="line"></span><br><span class="line">for i in range(15):</span><br><span class="line">    print(fib(i), end&#x3D;&quot;, &quot;)</span><br></pre></td></tr></table></figure></li>
<li><em>using class</em><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">class decorator2:</span><br><span class="line">    </span><br><span class="line">    def __init__(self, f):</span><br><span class="line">        self.f &#x3D; f</span><br><span class="line">        </span><br><span class="line">    def __call__(self):</span><br><span class="line">        print(&quot;Decorating&quot;, self.f.__name__)</span><br><span class="line">        self.f()</span><br><span class="line"></span><br><span class="line">@decorator2</span><br><span class="line">def foo():</span><br><span class="line">    print(&quot;inside foo()&quot;)</span><br><span class="line"></span><br><span class="line">foo()</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>DeepFm</title>
    <url>/2021/03/08/DeepFm/</url>
    <content><![CDATA[<br>

<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>在推荐领域较流行的深度模型方案：</p>
<p>实战：阿里MLR、阿里DIN、阿里ESSM、京东强化学习推荐、facebook个性化推荐dlrm、Deep Neural Networks for YouTube Recommendations、华为DeepFM、google2016 wide&amp;deep learning、googleDeep&amp;Cross Network等。</p>
<a id="more"></a>
<p>DeepFm模型及进化：XDeepFM(deep进化)、AFM(加入attention)、FFM(field-aware)、PNN、FNN、NFM等。</p>
<p>其中，DeepFM在论文中通过大量实验证明，DeepFM的AUC和Logloss都优于目前的最好效果。效率上，DeepFM和目前最优的效果的深度模型相当。在Benchmark数据集和商业数据集上，DeepFM效果超过目前所有模型。</p>
<h3 id="Q1：FM解决什么问题？"><a href="#Q1：FM解决什么问题？" class="headerlink" title="Q1：FM解决什么问题？"></a>Q1：FM解决什么问题？</h3><p>1、普通的线性模型，我们都是将各个特征独立考虑的，并没有考虑到特征与特征之间的相互关系。<br>为了表述特征间的相关性，我们采用多项式模型。</p>
<p>在多项式模型中，特征xi与xj的组合用xixj表示。为了简单起见，我们讨论二阶多项式模型。<br>2、与线性模型相比，FM的模型就多了后面特征组合的部分。<br><img src="/2021/03/08/DeepFm/%E4%BA%8C%E9%A1%B9%E5%BC%8F.png" alt="二项式"></p>
<h3 id="Q2：FM参数求解？"><a href="#Q2：FM参数求解？" class="headerlink" title="Q2：FM参数求解？"></a>Q2：FM参数求解？</h3><p>1、公式中，组合部分的特征相关参数共有n(n−1)/2个。在数据很稀疏的情况下xi,xj都不为0的情况非常少，这样将导致ωij无法通过训练得出。</p>
<p>为了求出ωij，我们对每一个特征分量xi引入辅助向量Vi=(vi1,vi2,⋯,vik)。然后，利用vivj^T对ωij进行求解。</p>
<img src="/2021/03/08/DeepFm/引入V.png" width="70%" height="200">

<p>2、如何求解V？</p>
<p>推导公式网上到处都有。</p>
<p>3、得到公式推导结果后，对w求导，梯度下降进行训练。</p>
<h4 id="Q3：FFM？"><a href="#Q3：FFM？" class="headerlink" title="Q3：FFM？"></a>Q3：FFM？</h4><p>公式：</p>
<img src="/2021/03/08/DeepFm/ffm_gs.png" width="70%" height="150">


<p>举例：</p>
<img src="/2021/03/08/DeepFm/ffm.png" width="50%" height="400">


<h4 id="Q4：why-DeepFm？"><a href="#Q4：why-DeepFm？" class="headerlink" title="Q4：why DeepFm？"></a>Q4：why DeepFm？</h4><p>1、因子分解机(Factorization Machines, FM)通过对于每一维特征的隐变量内积来提取特征组合。最终的结果也非常好。<br>但是，虽然理论上来讲FM可以对高阶特征组合进行建模，但实际上因为计算复杂度的原因一般都只用到了二阶特征组合。<br>那么对于高阶的特征组合来说，通过多层的神经网络即DNN去解决。</p>
<p>2、One-hot类型的特征输入到DNN中，会导致网络参数太多。<br>如何解决这个问题呢，类似于FFM中的思想，将特征分为不同的field：让Dense Vector进行组合，来表示高阶特征。</p>
<img src="/2021/03/08/DeepFm/field.png" width="70%" height="400">

<p>3、但是低阶和高阶特征组合隐含地体现在隐藏层中，如果我们希望把低阶特征组合单独建模，然后融合高阶特征组合。<br>=&gt;就得到了DeepFm。</p>
<h4 id="Q5：what-DeepFm？"><a href="#Q5：what-DeepFm？" class="headerlink" title="Q5：what DeepFm？"></a>Q5：what DeepFm？</h4><p>1、有两种融合方式，分别为串行和并行的结构。<br>这里介绍并行结构。</p>
<img src="/2021/03/08/DeepFm/structure.png" width="80%" height="500">
<img src="/2021/03/08/DeepFm/deepfm.png" width="70%" height="700">


<p>2、emb部分</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">#embeddings</span><br><span class="line">#weights[&#39;feature_embeddings&#39;] 存放的每一个值其实就是FM中的vik</span><br><span class="line">weights[&#39;feature_embeddings&#39;] &#x3D; tf.Variable(</span><br><span class="line">    tf.random_normal([self.feature_size,self.embedding_size],0.0,0.01),</span><br><span class="line">    name&#x3D;&#39;feature_embeddings&#39;)</span><br><span class="line"></span><br><span class="line">weights[&#39;feature_bias&#39;] &#x3D; tf.Variable(tf.random_normal([self.feature_size,1],0.0,1.0),name&#x3D;&#39;feature_bias&#39;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># model</span><br><span class="line">self.embeddings &#x3D; tf.nn.embedding_lookup(self.weights[&#39;feature_embeddings&#39;],self.feat_index) # N * F * K</span><br><span class="line">feat_value &#x3D; tf.reshape(self.feat_value,shape&#x3D;[-1,self.field_size,1])</span><br><span class="line">self.embeddings &#x3D; tf.multiply(self.embeddings,feat_value)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如果是离散值，则embedding lookup之后，每个维度✖️1，连续值则✖️连续值。<br>✖️后的结果就是公式里的 Vi,f · Xi</p>
<p>3、dnn部分<br>为了更好的发挥DNN模型学习high-order特征的能力，文中设计了一套子网络结构，将原始的稀疏表示特征映射为稠密的特征向量。<br>子网络设计时的两个要点：</p>
<p>不同field特征长度不同，但是子网络输出的向量需具有相同维度；<br>利用FM模型的隐特征向量V作为网络权重初始化来获得子网络输出向量。文中将FM的预训练V向量作为网络权重初始化替换为直接将FM和DNN进行整体联合训练，从而实现了一个端到端的模型。 （即lookup）</p>
<p>4、fm</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># second order term</span><br><span class="line"># sum-square-part</span><br><span class="line">self.summed_features_emb &#x3D; tf.reduce_sum(self.embeddings,1) # None * k</span><br><span class="line">self.summed_features_emb_square &#x3D; tf.square(self.summed_features_emb) # None * K</span><br><span class="line"></span><br><span class="line"># squre-sum-part</span><br><span class="line">self.squared_features_emb &#x3D; tf.square(self.embeddings)</span><br><span class="line">self.squared_sum_features_emb &#x3D; tf.reduce_sum(self.squared_features_emb, 1)  # None * K</span><br><span class="line"></span><br><span class="line">#second order</span><br><span class="line">self.y_second_order &#x3D; 0.5 * tf.subtract(self.summed_features_emb_square,self.squared_sum_features_emb)</span><br><span class="line">self.y_second_order &#x3D; tf.nn.dropout(self.y_second_order,self.dropout_keep_fm[1])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="Q6：扩展，自定义算子？"><a href="#Q6：扩展，自定义算子？" class="headerlink" title="Q6：扩展，自定义算子？"></a>Q6：扩展，自定义算子？</h4><p>我们需要找到所有的特征，one-hot后的可能性取值。然后才能构建用来lookup的table。<br>这里就可以对tensorflow里的hashtable算子进行扩展。</p>
]]></content>
      <categories>
        <category>dl</category>
      </categories>
      <tags>
        <tag>dl</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM</title>
    <url>/2021/01/31/LSTM/</url>
    <content><![CDATA[<ul>
<li>篇幅稍长，分为四个部分</li>
</ul>
<ol>
<li>background</li>
<li>step-by-step</li>
<li>show me the code</li>
<li>deep thinking</li>
</ol>
<p>codes<br><a href="https://github.com/satyrswang/blog-jianshu/blob/master/LSTM.lua">https://github.com/satyrswang/blog-jianshu/blob/master/LSTM.lua</a></p>
<h2 id="background"><a href="#background" class="headerlink" title="background"></a>background</h2><ul>
<li><p>what?<br>rnn和feedforward network有嘛不同？</p>
<blockquote>
<p>It’s the easiest to implement an RNN just as a feedforward network with some parts of the input feeding into the middle of the stack, and a bunch of outputs coming out from there as well. There is no magic internal state kept in the network. It’s provided as a part of the input!</p>
</blockquote>
<a id="more"></a>
<p>只是把隐层有拎出来作为下一个隐层的input。=_=<br>然而，理论支持吗？</p>
</li>
<li><p>Problem</p>
<ul>
<li>视频那么多帧，前一帧连着后一帧，间隔又短，那么是否可用前一帧来预测后一帧？<br>看情况。</li>
<li>完形填空 the clouds are in the ___<br>I grew up in France… I speak fluent <em>French</em>.<br>当gap变大，France和<em>French</em>距离那么远，RNN没用了。</li>
<li>为什么gap大了，就没用了？理论证明如下：<br><a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf">Bengio, et al. (1994)</a><br><a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf">Hochreiter (1991) German</a></li>
</ul>
</li>
<li><p>然而，LSTMs 不会因为gap惹事儿。<br>Long Short Term Memory networks<br><img src="/2021/01/31/LSTM/chain.webp" alt="chain"></p>
</li>
</ul>
<h2 id="step-by-step"><a href="#step-by-step" class="headerlink" title="step-by-step"></a>step-by-step</h2><ul>
<li>图第二个干嘛了？你先别看图，听我讲：<br>注意这里横着看，看的是chain中第t个</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#过程1 --名字是 input transform</span><br><span class="line">输入 ：input中的x(t)，chain中前一个x输出的结果h(t-1)</span><br><span class="line">参数 ：x的权重w1，h的权重w2，加一个bias</span><br><span class="line">激活函数 ：tanh</span><br></pre></td></tr></table></figure>
<p>以上得到一个结果记为c_in</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#过程2 --名字是 三个gates，每个gate如下</span><br><span class="line">输入 ：input中的x(t)，chain中前一个x输出的结果h(t-1)</span><br><span class="line">参数 ：x的权重w1，h的权重w2，加一个bias</span><br><span class="line">激活函数 ：g</span><br></pre></td></tr></table></figure>
<p>得到三个结果记为i , f , o<br>先保留一个问题： 过程1、2的输入虽然都是x h变量，但是是一样的吗？还是x h这两个向量的部分值呢？<br>有了c_in,i , f , o 之后干嘛，我怎么得到这一层的h？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#过程3 -- 名字是 state update </span><br><span class="line">输入 ：c_in,i , f , o ,c_out(t-1)</span><br><span class="line">输出 ：新的h(t)， c_out(t)</span><br></pre></td></tr></table></figure>
<p>c_out(t-1) 是chain中前一个的输出呗。h、c_out怎么计算的？<br>c_out(t)  =  f * c_out(t-1) + i * c_in<br>h(t)  =  o * tanh(c_out(t))</p>
<ul>
<li>就这么简单？<br>是的。为什么能这样呢？<blockquote>
<p>Because of the <strong>gating mechanism</strong> the cell can keep a piece of information for long periods of time during work and <strong>protect the gradient inside the cell from harmful changes during the training</strong>. Vanilla LSTMs don’t have <strong>a forget gate</strong> and add unchanged cell state during the update (it can be seen as a recurrent connection with a constant weight of 1), what is often referred to as a Constant Error Carousel (CEC). It’s called like that, because <strong>it solves a serious RNN training problem of vanishing and exploding gradients</strong>, which in turn makes it possible to learn long-term relationships.</p>
</blockquote>
</li>
</ul>
<p>原来，因为有个<strong>gating mechanism</strong> 就是 过程2 嘛，解决了RNN的gradient的问题。为什么能解决<strong>vanishing and exploding gradients</strong>的问题呢？理论支持去看论文。</p>
<h2 id="show-me-the-code"><a href="#show-me-the-code" class="headerlink" title="show me the code"></a>show me the code</h2><p>基于 Torch7</p>
<ul>
<li>snippet1: inputs<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local inputs &#x3D; &#123;&#125;</span><br><span class="line">table.insert(inputs, nn.Identity()())   -- x(t)</span><br><span class="line">table.insert(inputs, nn.Identity()())   -- c_out(t-1)</span><br><span class="line">table.insert(inputs, nn.Identity()())   -- h(t-1)</span><br><span class="line">local input &#x3D; inputs[1]</span><br><span class="line">local prev_c &#x3D; inputs[2]</span><br><span class="line">local prev_h &#x3D; inputs[3]</span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li><p>  想想看我们要什么？你回答完了之后，听我讲：<br>三个变量 ：过程1、2要的x(t) h(t-1)和过程3还要的c_out(t-1)</p>
</li>
<li><p>  怎么得到？<br>这里用到了<code>nn.Identity()()</code> 和 <code>table.insert</code></p>
<blockquote>
<p>The array-like objects in lua are called tables.<br>nn.Identity() - passes on the input (used as a placeholder for input)</p>
</blockquote>
</li>
</ol>
<p>如果你用tf，那么nn.Identify就是placeholder</p>
<ul>
<li>snippet2: Computing gate values<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local i2h &#x3D; nn.Linear(input_size, 4 * rnn_size)(input) </span><br><span class="line">local h2h &#x3D; nn.Linear(rnn_size, 4 * rnn_size)(prev_h)   </span><br><span class="line">local preactivations &#x3D; nn.CAddTable()(&#123;i2h, h2h&#125;)    </span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li> <code>4 * rnn_size</code>什么鬼？<br>过程1、2在激活前是不是都是x(t) h(t-1)的线性变换？即<code>nn.Linear</code>。<br><code>preactivations</code>将i2h, h2h作加法运算返回一个vector。<br>我们将线性变换的结果分成4份，每份<code>rnn_size</code>多个值。为什么分为4份？记得我们有三个gates吗 ，得到i,f,o？<blockquote>
<p>The first will be used for <strong>i</strong>n gates, second for <strong>f</strong>orget gates, third for <strong>o</strong>ut gates and the last one <strong>as a cell input</strong> .</p>
</blockquote>
</li>
</ol>
<p>就跟玩儿似的。这里<strong>as a cell input</strong>就是直赋值给了h(t)，作为chain下一个的输入。也解释了之前的保留问题，即输入并不是一样的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local pre_sigmoid_chunk &#x3D; nn.Narrow(2, 1, 3 * rnn_size)(preactivations)</span><br><span class="line">local all_gates &#x3D; nn.Sigmoid()(pre_sigmoid_chunk)</span><br><span class="line">local in_chunk &#x3D; nn.Narrow(2, 3 * rnn_size + 1, rnn_size)(preactivations)</span><br><span class="line">local in_transform &#x3D; nn.Tanh()(in_chunk)</span><br><span class="line">local in_gate &#x3D; nn.Narrow(2, 1, rnn_size)(all_gates)</span><br><span class="line">local forget_gate &#x3D; nn.Narrow(2, rnn_size + 1, rnn_size)(all_gates)</span><br><span class="line">local out_gate &#x3D; nn.Narrow(2, 2 * rnn_size + 1, rnn_size)(all_gates)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><p> <code>nn.Narrow</code>什么鬼？</p>
<blockquote>
<p>select appropriate parts of the preactivation vector.</p>
</blockquote>
</li>
<li><p>  其他很简单啊，前3份传入gates要<code>nn.Sigmoid()</code>激活。3另一份只需要<code>nn.Tanh()</code>激活。</p>
</li>
</ol>
<ul>
<li><p>snippet3: Cell and hidden state<br>gates结果i f o也有了。进入过程3了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local c_forget &#x3D; nn.CMulTable()(&#123;forget_gate, prev_c&#125;)</span><br><span class="line">local c_input &#x3D; nn.CMulTable()(&#123;in_gate, in_transform&#125;)</span><br><span class="line">local next_c &#x3D; nn.CAddTable()(&#123; c_forget, c_input&#125;)</span><br><span class="line">local c_transform &#x3D; nn.Tanh()(next_c)</span><br><span class="line">local next_h &#x3D; nn.CMulTable()(&#123;out_gate, c_transform&#125;)</span><br></pre></td></tr></table></figure>
<p>按公式计算。没说的。得到<code>next_c</code>和<code>next_h</code></p>
</li>
<li><p>snippet4: define module</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">outputs &#x3D; &#123;&#125;</span><br><span class="line">table.insert(outputs, next_c)</span><br><span class="line">table.insert(outputs, next_h)</span><br><span class="line">return nn.gModule(inputs, outputs)</span><br></pre></td></tr></table></figure></li>
<li><p>手残党的snippet5: 栗子</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">require &#39;nn&#39;</span><br><span class="line">require &#39;nngraph&#39;</span><br><span class="line">LSTM &#x3D; require &#39;LSTM.lua&#39;  --以上snippet</span><br><span class="line">--创建3层LSTM，输入3输出3</span><br><span class="line">network &#x3D; &#123;LSTM.create(3, 4), LSTM.create(4, 4), LSTM.create(4, 3)&#125;</span><br><span class="line">--准备</span><br><span class="line">local x &#x3D; torch.randn(1, 3)</span><br><span class="line">local previous_state &#x3D; &#123;</span><br><span class="line">  &#123;torch.zeros(1, 4), torch.zeros(1,4)&#125;,</span><br><span class="line">  &#123;torch.zeros(1, 4), torch.zeros(1,4)&#125;,</span><br><span class="line">  &#123;torch.zeros(1, 3), torch.zeros(1,3)&#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#x3D; nil</span><br><span class="line">next_state &#x3D; &#123;&#125;</span><br><span class="line"></span><br><span class="line">--feed数据</span><br><span class="line">local layer_input &#x3D; &#123;x, table.unpack(previous_state[1])&#125;</span><br><span class="line">for l &#x3D; 1, #network do</span><br><span class="line">  local layer_output &#x3D; network[l]:forward(layer_input)</span><br><span class="line">  table.insert(next_state, layer_output)</span><br><span class="line">  local layer_h &#x3D; layer_output[2]</span><br><span class="line">  if l &lt; #network then</span><br><span class="line">    layer_input &#x3D; &#123;layer_h, table.unpack(previous_state[l + 1])&#125;</span><br><span class="line">  else</span><br><span class="line">    output &#x3D; layer_h</span><br><span class="line">  end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">print(next_state)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure>
<h2 id="deep-thinking"><a href="#deep-thinking" class="headerlink" title="deep thinking"></a>deep thinking</h2><p>尽管已经很长了。还是要写理解。这时你可以看图了。</p>
<blockquote>
<p>what information we’re going to throw away from the cell state<br>what new information we’re going to store in the cell state</p>
</blockquote>
</li>
</ul>
<p>1、 什么是forget gate？</p>
<ul>
<li>其实就是将x h线性变换后做一个sigmoid， 如果结果是0，代表forget  c_out(t-1)。</li>
<li>这个例子非常好：<blockquote>
<p>the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.</p>
</blockquote>
</li>
</ul>
<p>2、 i 和 c_in?</p>
<ul>
<li>两步，第一步i，i = 1相当于是确定哪些值我们需要update或者说需要更新输入的多大成分，想象为将c_in scale了i倍；而tanh相当于为需要更新的值确定了更新成什么c_in。</li>
<li>相乘，则确定了新的候选值，再与f相加，我们便确定了新的状态。</li>
</ul>
<blockquote>
<p>we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.</p>
</blockquote>
<p>3、 那么输出什么？</p>
<ul>
<li>首先我们需要确定哪些更新后的状态需要输出，用sigmoid，得到的o就是我们想要输出的部分。 </li>
<li> 然后 基于更新好的状态c_out(t)，将其tanh控制在[-1,1]之间。乘以o，输出我们要输出的。<blockquote>
<p>since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output <strong>whether the subject is singular or plural</strong>, so that we know what form a verb should be conjugated into if that’s what follows next.</p>
</blockquote>
</li>
</ul>
<p>4、 各类变种<br> <a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf">Gers &amp; Schmidhuber (2000)</a><br><a href="http://arxiv.org/pdf/1406.1078v3.pdf">Cho, et al. (2014)</a><br><a href="http://arxiv.org/pdf/1508.03790v2.pdf">Yao, et al. (2015)</a><br><a href="http://arxiv.org/pdf/1402.3511v1.pdf">Koutnik, et al. (2014)</a></p>
<p>5、 比对各类变种的结论<br><a href="http://arxiv.org/pdf/1503.04069.pdf">Greff, et al. (2015)</a><br><a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz, et al. (2015)</a></p>
<p>欢迎补充材料。<br>reference:<br><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p>
]]></content>
      <categories>
        <category>dl</category>
      </categories>
      <tags>
        <tag>dl</tag>
      </tags>
  </entry>
  <entry>
    <title>bean解析及注册源码</title>
    <url>/2021/03/11/bean%E8%A7%A3%E6%9E%90%E5%8F%8A%E6%B3%A8%E5%86%8C%E6%BA%90%E7%A0%81/</url>
    <content><![CDATA[<br>

<p>S1<code>xml文件等资源类 </code> – 对各种资源类的封装+encode</p>
<a id="more"></a>
<p><img src="https://upload-images.jianshu.io/upload_images/8716089-f03da4d523f26bbb.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="resource.jpg"></p>
<p>S2<code>读取xml文件</code> – 对xml文件的校验、load、read(这里的read调用BeanDefinitionDocumentReader)<br>主要在<code>XmlBeanDefinitionReader</code>中</p>
<p>S3<code>解析属性(xml中标签)</code> –从xml到Bean<br>实现在<code>DefaultBeanDefinitionDocumentReader</code><br><code>doRegisterBeanDefinitions()</code> 中解析了<code>profile</code>属性，并且其中的<code>parseBeanDefinitions()</code>是解析xml的开始。</p>
<p>根据不同的<code>namespace</code>和<code>nodename</code>，分别不同处理</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) &#123;</span><br><span class="line">	importBeanDefinitionResource(ele);</span><br><span class="line">&#125;</span><br><span class="line">else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) &#123;</span><br><span class="line">	processAliasRegistration(ele);</span><br><span class="line">&#125;</span><br><span class="line">else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) &#123;</span><br><span class="line">	processBeanDefinition(ele, delegate);</span><br><span class="line">&#125;</span><br><span class="line">else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) &#123;</span><br><span class="line">	&#x2F;&#x2F; recurse</span><br><span class="line">	doRegisterBeanDefinitions(ele);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>处理过程涉及到<code>BeanDefinitionParserDelegate BeanDefinitionHolder BeanDefinitionReaderUtils XmlReaderContext</code></p>
<blockquote>
<p>delegate中对元素(属性)进行解析，结果放入holder中，此时holder已经包含了各种属性。再由Utils中将holder进行注册。最后由context将注册结果通知监听器。</p>
</blockquote>
<p>S4<code>注册</code></p>
]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>dssm</title>
    <url>/2021/03/08/dssm/</url>
    <content><![CDATA[<h4 id="DSSM"><a href="#DSSM" class="headerlink" title="DSSM"></a>DSSM</h4><ul>
<li><p>任务<br>用来预测两个句子的语义相似度，又可以获得某句子的低维语义Embedding向量。</p>
<a id="more"></a></li>
<li><p>场景<br>DSSM 模型的最大特点就是 Query 和 Document 是两个独立的子网络，后来这一特色被移植到推荐算法的召回环节，即对用户端（User）和物品端（Item）分别构建独立的子网络塔式结构。<br>两个子网络产生的 Embedding 向量可以独自获取及缓存。</p>
</li>
</ul>
<p>当模型训练完成时，物品的 Embedding 是可以保存成词表的，线上应用的时候只需要查找对应的 Embedding 即可。因此线上只需要计算 （用户，上下文） 一侧的 Embedding，基于 Annoy 或 Faiss 技术索引得到用户偏好的候选集。</p>
<ul>
<li>word hashing<br>word hashing方法是用来减少输入向量的维度，该方法基于字母的n-gram。给定一个单词（good），我们首先增加词的开始和结束部分（#good#），然后将该词转换为字母 [公式] -gram的形式（假设为trigrams：#go，goo，ood，od#）。最后该词使用字母 n-gram的向量来表示。</li>
</ul>
<p>这种方法的问题在于有可能造成冲突，因为两个不同的词可能有相同的n-gram向量来表示。与原始的ont-hot向量表示的词典大小相比，word hashing明显降低了向量表示的维度。</p>
<ul>
<li>优点</li>
</ul>
<p>1、解决了LSA、LDA、Autoencoder等方法存在的一个最大的问题：字典爆炸（导致计算复杂度非常高），因为在英文单词中，词的数量可能是没有限制的，但是字母n-gram的数量通常是有限的.<br>2、基于词的特征表示比较难处理新词，字母的 n-gram可以有效表示，鲁棒性较强<br>3、使用有监督方法，优化语义embedding的映射问题<br>4、省去了人工的特征工程</p>
<ul>
<li>缺点</li>
</ul>
<p>1、word hashing可能造成冲突<br>2、DSSM采用了词袋模型，损失了上下文信息<br>3、在排序中，搜索引擎的排序由多种因素决定，由于用户点击时doc的排名越靠前，点击的概率就越大，如果仅仅用点击来判断是否为正负样本，噪声比较大，难以收敛<br>4、对于中文而言，处理方式与英文有很多不一样的地方。中文往往需要进行分词，但是我们可以仿照英文的处理方式，将中文的最小粒度看作是单字（在某些文献里看到过用偏旁部首，笔画，拼音等方法）</p>
<ul>
<li><p>扩展<br>对DSSM的优化出现了很多的变种，有CNN-DSSM，LSTM-DSSM，MV-DSSM等。</p>
</li>
<li><p>trick</p>
</li>
</ul>
<img src="/2021/03/08/dssm/trick.png" width="80%" height="400">

<hr>
<ul>
<li>架构</li>
</ul>
<img src="/2021/03/08/dssm/dssm.png" width="70%" height="900">


]]></content>
      <categories>
        <category>dl</category>
      </categories>
      <tags>
        <tag>dl</tag>
      </tags>
  </entry>
  <entry>
    <title>dubbo-spi</title>
    <url>/2021/01/31/dubbo-spi/</url>
    <content><![CDATA[<h2 id="spi"><a href="#spi" class="headerlink" title="spi"></a>spi</h2><p><img src="/2021/01/31/dubbo-spi/jdbc.png" alt="jdbc实现"></p>
<p><strong>SPI 的缺点</strong><br>JDK 标准的 SPI 会一次性加载实例化扩展点的所有实现，JDK 启动的时候会一次性全部加载。<br>1如果有的扩展点实现初始化很耗时或者如果有些实现类并没有用到， 会很浪费资源。<br>2如果扩展点加载失败，会导致调用方报错，而且这个错误很难定位到。</p>
<a id="more"></a>

<p><strong>dubbo spi</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Protocol  p &#x3D; ExtensionLoader.getExtensionLoader(xxx.class).getAdaptiveExtension();</span><br><span class="line">ExtensionLoader.getExtensionLoader(xxx.class).getExtension(name);</span><br><span class="line">ExtensionLoader.getExtensionLoader(xxx.class).getActivateExtension(url, key);</span><br></pre></td></tr></table></figure>
<p><code>protocol</code>会在运行的时候判断一下应该选用这个Protocol接口的哪个实现类来实例化对象。<br>动态的根据配置去找到对应的实现类。如果你没有配置，那就走默认的实现类。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SPI(&quot;dubbo&quot;)  </span><br><span class="line">public interface Protocol &#123;  </span><br><span class="line">      </span><br><span class="line">    int getDefaultPort();  </span><br><span class="line">  </span><br><span class="line">    @Adaptive  </span><br><span class="line">    &lt;T&gt; Exporter&lt;T&gt; export(Invoker&lt;T&gt; invoker) throws RpcException;  </span><br><span class="line">  </span><br><span class="line">    @Adaptive  </span><br><span class="line">    &lt;T&gt; Invoker&lt;T&gt; refer(Class&lt;T&gt; type, URL url) throws RpcException;  </span><br><span class="line"></span><br><span class="line">    void destroy();  </span><br><span class="line">  </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line">dubbo&#x3D;org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol</span><br></pre></td></tr></table></figure>
<p><code>@SPI(“dubbo”)</code>：通过 SPI 机制来提供实现类，实现类是通过 dubbo 作为默认 key 去配置文件里找到的，配置文件名称与接口全限定名一样的，通过 dubbo 作为 key 可以找到默认的实现类就是 org.apache.dubbo.rpc.protocol.dubbo.DubboProtocol</p>
<p><code>@Adaptive</code>：如果想要动态替换掉默认的实现类，需要使用 @Adaptive 。表示动态代理实现。在运行的时候会针对 Protocol 生成<code>代理类</code>，这个代理类的那俩方法里面会有<code>代理代码</code>，代理代码会在运行的时候动态根据 url 中的 protocol 来获取那个 key，默认是 dubbo，自己指定则获取相应的实现。</p>
<h2 id="扩展dubbo组件"><a href="#扩展dubbo组件" class="headerlink" title="扩展dubbo组件"></a>扩展dubbo组件</h2><p><strong>step1</strong><br><img src="/2021/01/31/dubbo-spi/implement.png" alt="自定义方法"></p>
<p><strong>step2</strong><br><img src="/2021/01/31/dubbo-spi/properties.png" alt="添加配置"></p>
<p><strong>step3</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class App </span><br><span class="line">&#123;</span><br><span class="line">    public static void main( String[] args )</span><br><span class="line">    &#123;</span><br><span class="line">&#x2F;&#x2F;        调用方代码</span><br><span class="line">    	Protocol protocol &#x3D; ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(&quot;myProtocol&quot;);</span><br><span class="line">    	System.out.println(protocol.getDefaultPort());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="实现原理探析"><a href="#实现原理探析" class="headerlink" title="实现原理探析"></a>实现原理探析</h2><p>getExtension方法获取一个SPI接口的扩展类实例的流程: 分为解析配置文件、加载并缓存扩展类、创建并加工(属性注入与层层包装)扩展类实例 几个步骤。</p>
<p>通过getAdaptiveExtension方法的流程可以发现，要想获得一个SPI接口的自适应扩展类实例，有2种方式：<br>1在SPI接口的配置文件中配置具有@Adaptive注解的扩展类，在执行解析SPI接口配置文件方法getExtensionClasses时，它会调用loadClass方法，该方法判断扩展类是否具有@Adaptive注解，如果有，则将该类Class缓存到ExtensionLoader的字段“cachedAdaptiveClass”中，然后直接实例化该Class的实例并进行自动装配；<br>2如果未配置@Adaptive修饰的扩展类，则Dubbo会使用字节码技术创建一个自适应扩展类，前提是SPI接口上至少有一个被@Adaptive注解的方法；</p>
<p>todo</p>
]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title>flink</title>
    <url>/2021/03/08/flink/</url>
    <content><![CDATA[<br>


<h1 id="flink"><a href="#flink" class="headerlink" title="flink"></a>flink</h1><h2 id="state"><a href="#state" class="headerlink" title="state"></a>state</h2><ul>
<li><p>场景</p>
<ul>
<li>有状态的逻辑是因为数据之间存在关联，单条数据是没有办法把所有的信息给表现出来。<a id="more"></a>
<ul>
<li>去重</li>
<li>窗口计算</li>
<li>机器学习参数</li>
<li>访问历史数据</li>
</ul>
</li>
</ul>
</li>
<li><p>为什么要管理状态</p>
<ul>
<li>内存<ul>
<li>流式作业：24 小时的数据都放到内存，可能会出现内存不足。</li>
</ul>
</li>
<li>高可用<ul>
<li>机器若出现故障或者宕机，需要考虑如何备份及从备份中去恢复，</li>
</ul>
</li>
<li>扩展性<ul>
<li>单节点无法处理全部访问数据，增加几个节点进行横向扩展，这时数据的状态如何平均分配到新增加的节点。</li>
</ul>
</li>
</ul>
</li>
<li><p>方案</p>
<ul>
<li><p>Managed State &amp; Raw State</p>
<ul>
<li>自定义operator用 raw</li>
<li>raw 必须能够转成字节数组</li>
<li>managed，flink自动存储和恢复，并进行内存优化<br>支持已知的数据结构，如 Value、List、Map</li>
</ul>
</li>
<li><p>Managed State</p>
<ul>
<li><p>Keyed State </p>
<ul>
<li><p>每个 Key 对应一个 State</p>
</li>
<li><p>整个程序中没有 keyBy 的过程就没有办法使用KeyedStream。</p>
</li>
<li><p>并发改变时状态重新分配：内置了 2 种分配方式</p>
</li>
<li><p>Keyed State 通过 RuntimeContext 访问，这需要 Operator 是一个 Rich Function。</p>
</li>
<li><p>几种 Keyed State 的差异</p>
<ul>
<li><p>ReducingState 和 AggregatingState 与 ListState 都是同一个父类，但状态数据类型上是单个值</p>
</li>
<li><p> AggregatingState 输入的 IN，输出的是 OUT。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Operator State </p>
<ul>
<li>可以用于所有算子，常用于 Source</li>
<li>一个 Operator 实例对应一个 State</li>
<li>Operator  State 需要自己实现 CheckpointedFunction 或 ListCheckpointed 接口。</li>
<li>支持的数据结构相对较少 </li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>使用示例</p>
<ul>
<li><p><a href="https://github.com/apache/flink/blob/master/flink-examples/flink-examples-streaming/src/main/java/org/apache/flink/streaming/examples/statemachine/StateMachineExample.java">写状态机是如何实现</a></p>
</li>
<li><p>实现的是：首先下订单，订单生成后状态为待付款，当再来一个事件状态付款成功，则事件的状态将会从待付款变为已付款，待发货…</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>状态的保存和恢复</p>
<ul>
<li><p>保存</p>
<ul>
<li>Checkpoint 会定时制作分布式快照</li>
</ul>
</li>
<li><p>恢复</p>
<ul>
<li><p>checkpoint</p>
<ul>
<li>数据源需要支持数据重新发送</li>
<li>两种一致性语义，一种是恰好一次，一种是至少一次</li>
<li>1、把进程或者线程移到 active 的 其他台机器上<br>2、整个作业的所有 Task 都回滚到最后一次成功 Checkpoint 中的状态</li>
</ul>
</li>
<li><p>savepoint</p>
<ul>
<li>手动调整并发，必须要重启作业并会提示 Checkpoint 已经不存在–&gt; 此时savepoint</li>
<li>比较持久，以标准格式存储</li>
<li>允许代码或配置发生改变，恢复需要启动作业手动指定一个路径恢复</li>
</ul>
</li>
</ul>
</li>
<li><p>checkpoint实现</p>
<ul>
<li>运行环境 env.enableCheckpointing 传入间隔时间。越频繁，恢复时追数据就会相对减少，IO 消耗增加。</li>
<li>设置了 Exactly_Once 语义，并且需要 Barries 对齐，这样可以保证消息不会丢失也不会重复。</li>
<li>setMinPauseBetweenCheckpoints 防止 Checkpoint 太过于频繁</li>
<li>setCheckpointTimeout 表示做 Checkpoint 多久超时</li>
<li>setMaxConcurrentCheckpoints</li>
<li>enableExternalizedCheckpoints。默认 Checkpoint 会在整个作业 Cancel 时被删除。Checkpoint 是作业级别的保存点。</li>
</ul>
</li>
<li><p>checkpoint可选的状态存储方式</p>
<ul>
<li><p>MemoryStateBackend</p>
<ul>
<li>构造方法是设置最大的 StateSize，选择是否做异步快照</li>
<li>且需要注意 maxStateSize &lt;= akka.framesize 默认 10 M</li>
<li>Checkpoint 存储在 JobManager 内存中，因此总大小不超过 JobManager 的内存。- 本地测试、几乎无状态的作业，比如 ETL、JobManager 不容易挂，或挂掉影响不大的情况。不推荐在生产场景使用。</li>
</ul>
</li>
<li><p>FsStateBackend</p>
<ul>
<li>需要传一个文件路径和是否异步快照</li>
<li>State 依然在 TaskManager 内存中- Checkpoint 存储在外部文件系统（本地或 HDFS）</li>
<li>常规使用状态的作业、例如分钟级窗口聚合或 join、需要开启 HA 的作业。</li>
</ul>
</li>
<li><p>RocksDBStateBackend</p>
<ul>
<li>key/value 的内存存储系统</li>
<li>不支持同步的 Checkpoint</li>
<li>支持增量的 Checkpoint</li>
<li>存储在外部文件系统（本地或 HDFS）</li>
<li>单个 TaskManager 上 State 总量不超过它的内存+磁盘，单 Key 最大 2G，总大小不超过配置的文件系统容量即可</li>
<li>超大状态的作业，例如天级窗口聚合、需要开启 HA 的作业、最好是对状态读写性能要求不高的作业。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="窗口"><a href="#窗口" class="headerlink" title="窗口"></a>窗口</h2><ul>
<li>todo</li>
</ul>
<h2 id="watermark"><a href="#watermark" class="headerlink" title="watermark"></a>watermark</h2><ul>
<li>todo</li>
</ul>
<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><ul>
<li>todo</li>
</ul>
<h2 id="概念-amp-角色"><a href="#概念-amp-角色" class="headerlink" title="概念&amp;角色"></a>概念&amp;角色</h2><ul>
<li>TaskManager &amp; slot<ul>
<li>每一个 TaskManager 都是一个JVM进程</li>
<li>每个task slot表示TaskManager拥有资源的一个固定大小的子集</li>
<li>将其管理的内存均分给各个slot</li>
<li>一个TaskManager一个slot时，那么每个task group运行在独立的JVM中</li>
<li>多个slot时，多个subtask可以共同享有一个JVM</li>
<li>在同一个JVM进程中的task将共享TCP连接和心跳消息，也可能共享数据集和数据结构，从而减少每个task的负载。</li>
</ul>
</li>
</ul>
<ul>
<li>todo</li>
</ul>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ul>
<li><a href="https://www.infoq.cn/article/vgkza-s9fmbgabp71pgh">状态管理及容错机制</a></li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>流处理</tag>
      </tags>
  </entry>
  <entry>
    <title>graphsage</title>
    <url>/2021/03/08/graphsage/</url>
    <content><![CDATA[<h4 id="GCN"><a href="#GCN" class="headerlink" title="GCN"></a>GCN</h4><ul>
<li>卷积<br>数学上卷积的两个例子：</li>
</ul>
<p>一个对象（吃冰淇凌）对一个系统（体重）的作用效果满足线性原理、累加原理。该对象对这个系统连续作用了一段时间后，求该系统的状态。这个时候，一个卷积就可以求出来了！</p>
<a id="more"></a>
<!-- ![卷积](卷积.jpg) -->
<br>
第二个例子：
<img src="/2021/03/08/graphsage/卷积.jpg" width="100%" height="700">

<hr>
<p>DL中的卷积：</p>
<p>CNN卷积本质是，共享参数的filter过滤器，像素点加权构成feature map 实现特征提取。<br>a）平滑滤波 b）边缘提取，很容易通过设计特定的“卷积核”，然后将其与像素矩阵的对应元素（不进行旋转）相乘得到。<br>a）就是将中心像素值与周围临近的像素进行平均，自然就能“削峰填谷”，实现平滑处理<br>b) 中心像素复制n份，减去周围n个临近的像素值。相近的则减为0，边缘才被留下。<br>卷积神经网络中“卷积”，是为了提取图像的特征，其实只借鉴了数学卷积中“加权求和”的特点。</p>
<ul>
<li><p>为什么需要GCN<br>CNN LSTM等 对非欧几里得空间数据(eg：社交网络、信息网络等)进行处理上却存在一定的局限性。<br>用GCN：拓扑图中每个node相邻的个数不同，不能用同样大小的filter进行平移提取feature。任何数据在赋范空间内都可以建立拓扑关联，如谱聚类。GCN是区别于CV NLP的任务的模型。</p>
</li>
<li><p>图学习任务<br>1、图节点分类任务：图中每个节点都有对应的特征，当我们已知一些节点的类别的时候，可以设计分类任务针对未知节点进行分类。我们接下来要介绍的 GCN、GraphSAGE、GAT模型都是对图上的节点分类。<br>2、图边结构预测任务：图中的节点和节点之间的边关系可能在输入数据中能够采集到，而有些隐藏的边需要我们挖掘出来，这类任务就是对边的预测任务，也就是对节点和节点之间关系的预测。<br>3、图的分类：对于整个图来说，我们也可以对图分类，图分类又称为图的同构问题，基本思路是将图中节点的特征聚合起来作为图的特征，再进行分类。</p>
</li>
</ul>
<p>如：<br>1、节点分类—反欺诈：因为图中每个节点都拥有自己的特征信息。通过该特征信息，我们可以构建一个风控系统，如果交易节点所关联的用户 IP 和收货地址与用户注册 IP 和注册地址不匹配，那么系统将有可能认为该用户存在欺诈风险。<br>2、边结构预测—商品推荐：图中每个节点都具有结构信息。如果用户频繁购买某种类别商品或对某种类别商品评分较高，那么系统就可以认定该用户对该类商品比较感兴趣，所以就可以向该用户推荐更多该类别的商品。</p>
<ul>
<li>拉普拉斯矩阵<br><img src="/2021/03/08/graphsage/laplacian.png" alt="laplacian"></li>
</ul>
<hr>
<ul>
<li><p>GCN主要贡献<br>这篇文章的主要贡献是为图半监督分类任务设计了一个简单并且效果好的神经网络模型，这个模型由谱图卷积(spectral graph convolution)的一阶近似推导而来，具有理论基础。</p>
</li>
<li><p>GCN学习策略</p>
</li>
</ul>
<p><img src="/2021/03/08/graphsage/GCN%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5.png" alt="GCN学习策略"></p>
<ul>
<li><p>多层图卷积网络(Graph Convolutional Network, GCN)的逐层传播公式<br><img src="/2021/03/08/graphsage/%E9%80%90%E5%B1%82%E4%BC%A0%E6%92%AD%E5%85%AC%E5%BC%8F.png" alt="逐层传播公式"></p>
</li>
<li><p>谱图卷积(Spectral Graph Convolutions)</p>
</li>
<li><p>逐层线性模型</p>
</li>
<li><p>半监督学习节点分类</p>
</li>
<li><p>传播公式解释</p>
</li>
</ul>
<p>todo</p>
<h4 id="graphsage"><a href="#graphsage" class="headerlink" title="graphsage"></a>graphsage</h4><p>1、比GCN进步之处<br>GCN的训练方式需要将邻接矩阵和特征矩阵一起放到内存或者显存里，在大规模图数据上是不可取的。其次，GCN在训练时需要知道整个图的结构信息(包括待预测的节点), 这在现实某些任务中也不能实现(比如用今天训练的图模型预测明天的数据，那么明天的节点是拿不到的)。GraphSAGE的出现就是为了解决这样的问题。</p>
<p>GraphSAGE采用了采样的机制，使得图模型可以应用到大规模的图结构数据中，是目前几乎所有工业上图模型的雏形。<br>进一步：每个节点这么多邻居，采样能否考虑到邻居的相对重要性呢，或者我们在聚合计算中能否考虑到邻居的相对重要性? </p>
<p>2、inductive 还是 transductive<br>如果训练时用到了测试集或验证集样本的信息(或者说，测试集和验证集在训练的时候是可见的), 我们把这种学习方式叫做transductive learning, 反之，称为inductive learning. 显然，我们所处理的大多数机器学习问题都是inductive learning, 因为我们刻意的将样本集分为训练/验证/测试，并且训练的时候只用训练样本。然而，在GCN中，训练节点收集邻居信息的时候，用到了测试或者验证样本，所以它是transductive的。</p>
<p>3、简单过程<br>思路一个网络里，我们知道部分点的分类，我们希望通过各种方法，知道其他未知点的属性。解决对未知节点的泛化问题。</p>
<p>GraphSAGE是一个inductive框架，在具体实现中，训练时它仅仅保留训练样本到训练样本的边。inductive learning 的优点是可以利用已知节点的信息为未知节点生成Embedding. GraphSAGE 取自 Graph SAmple and aggreGatE, SAmple指如何对邻居个数进行采样。aggreGatE指拿到邻居的embedding之后如何汇聚这些embedding以更新自己的embedding信息。<br><br></p>
<img src="/2021/03/08/graphsage/visual_graphsage.webp" width="80%" height="300">

<hr>
<p>4、具体步骤及伪代码</p>
<p>步骤：<br>1.对邻居采样<br>2.采样后的邻居embedding传到节点上来，并使用一个聚合函数聚合这些邻居信息以更新节点的embedding<br>3.根据更新后的embedding预测节点的标签</p>
<!-- ![graphsage](graphsage.png) -->
<img src="/2021/03/08/graphsage/graphsage.png" width="80%" height="300">
<br>


<p>描述：初始化各个节点emb，对每个节点emb采样邻居的emb，对邻居进行聚合，将自己的emb和聚合后的emb做一个非线性变换，更新为自己的emb。</p>
<p>5、K的解释</p>
<p>K：聚合器数量，权重矩阵数量，层数。</p>
<!-- ![k](K解释.png) -->
<img src="/2021/03/08/graphsage/K解释.png" width="70%" height="600">

<br>

<p>6、采样<br>定长抽样。定义邻居个数，进行有放回的重采样/负采样达到个数。每个node采样个数一致，为了把多个邻居拼成tensor放入gpu批量训练。</p>
<p>7、聚合器<br>平均效果最好。<br>也有用lstm聚合器和pooling聚合器，</p>
<p>8、学习过程<br>有监督：交叉熵<br>无监督：学习出来的相邻node的emb应该尽可能接近。此时的loss如下。<br><img src="/2021/03/08/graphsage/loss.png" width="70%" height="100"><br><img src="/2021/03/08/graphsage/loss解释.png" width="70%" height="400"></p>
]]></content>
      <categories>
        <category>dl</category>
      </categories>
      <tags>
        <tag>dl</tag>
      </tags>
  </entry>
  <entry>
    <title>hive</title>
    <url>/2021/03/03/hive/</url>
    <content><![CDATA[<br>


<ul>
<li><p>组件架构：<br>hiveserver2（beeline）,hive,metadb</p>
<a id="more"></a>
<blockquote>
<p>Execution Engine – The component which executes the execution plan created by the compiler. The plan is a DAG of stages. The execution engine manages the dependencies between these different stages of the plan and executes these stages on the appropriate system components.</p>
</blockquote>
</li>
<li><p>连接hiveserver2  <br>GUI CLI JDBC (beeline)</p>
</li>
<li><p>数据源<br>用kafka，sqoop等获得data，放入hdfs，这些数据各种结构都有。<br>关系数据库的表，MongoDB 或json数据，或日志</p>
</li>
<li><p>执行hql<br>背后运行的是mapreduce or Tez jobs(类似于pig latin脚本执行pig)<br><code>insert into test values(&quot;wangyuq&quot;,&quot;123&quot;);</code><br>查看tracking url</p>
</li>
<li><p>stage<br>将你的数据移到目的位置之前，将会staing 那儿一段时间。staging文件最终丢弃。</p>
</li>
<li><p>比对<br>pig是对非结构化数据处理的好的etl。<br>hive不是关系数据库，只是维护存储在HDFS的数据的metadata，使得对大数据操作就像sql操作表一样，只不过hql和sql稍有出入。使我们能用sql来执行mr。可以对hdfs数据进行query。<br>hive使用metastore存表。hive默认derby但是可自定义更换。</p>
</li>
<li><p>劣<br>hive不能承诺优化，只是简单，因此hive不能支持实时，性能差<br>index view有限制（partition bucket 弥补）<br>和sql 的datatype不完全一样</p>
</li>
<li><p>与hdfs关系<br>hdfs里有hive，data在hdfs上，schema在metastore里。<br>load语句： 将hdfs搬运到hive，hdfs不再有该数据。只是将真正的data转到了hive目录下。</p>
</li>
</ul>
<ul>
<li> Making Multiple Passes over the Same Data<blockquote>
<p>Hive has a special syntax for producing multiple aggregations from a single pass through a source of data, rather than rescanning it for each aggregation. This change can save considerable processing time for large input data sets. </p>
</blockquote>
</li>
</ul>
<p>因此如下方式更加高效,并且可开启并行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM pv_users</span><br><span class="line">    INSERT OVERWRITE TABLE pv_gender_sum</span><br><span class="line">        SELECT pv_users.gender, count_distinct(pv_users.userid)</span><br><span class="line">        GROUP BY pv_users.gender</span><br><span class="line"></span><br><span class="line">    INSERT OVERWRITE DIRECTORY &#39;&#x2F;user&#x2F;data&#x2F;tmp&#x2F;pv_age_sum&#39;</span><br><span class="line">        SELECT pv_users.age, count_distinct(pv_users.userid)</span><br><span class="line">        GROUP BY pv_users.age;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set hive.exec.parallel&#x3D;true;   &#x2F;&#x2F;打开任务并行执行</span><br><span class="line">set hive.exec.parallel.thread.number&#x3D;16; &#x2F;&#x2F;同一个sql允许最大并行度，默认为8。</span><br></pre></td></tr></table></figure>
<ul>
<li><p>日期处理<br>查看N天前的日期：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select from_unixtime(unix_timestamp(&#39;20111102&#39;,&#39;yyyyMMdd&#39;) - N*86400,&#39;yyyyMMdd&#39;) from t_lxw_test1 limit 1;  </span><br></pre></td></tr></table></figure>
<p>获取两个日期之间的天数/秒数/分钟数等等：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select ( unix_timestamp(&#39;2011-11-02&#39;,&#39;yyyy-MM-dd&#39;)-unix_timestamp(&#39;2011-11-01&#39;,&#39;yyyy-MM-dd&#39;) ) &#x2F; 86400  from t_lxw_test limit 1; </span><br></pre></td></tr></table></figure></li>
<li><p>left outer join</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--query 1</span><br><span class="line">select count(id) from  </span><br><span class="line">(select id  from   a  left outer join   b  </span><br><span class="line">on a.id&#x3D;b.id and  b.date&#x3D;&#39;2017-10-27&#39;    </span><br><span class="line">where to_date(a.adate) &gt;&#x3D; &#39;2017-10-27&#39;   and a.date&#x3D;&#39;2017-07-24&#39;  </span><br><span class="line">) a </span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--query 2</span><br><span class="line">select count(id) from  </span><br><span class="line">(select id  from   a  left outer join   b  </span><br><span class="line">on a.id&#x3D;b.id and  b.date&#x3D;&#39;2017-10-27&#39;  and a.date&#x3D;&#39;2017-07-24&#39;  </span><br><span class="line">where to_date(a.adate) &gt;&#x3D; &#39;2017-10-27&#39;  </span><br><span class="line">) a </span><br></pre></td></tr></table></figure>
<p>区别？where 后面跟的是过滤条件，query 1 中的a.date=’2017-07-24’, 在table scan之前就会Partition Pruner 过滤分区，所以只有’2017-07-24’下的数据会和b进行join。<br>而query 2中会读入所有partition下的数据，再和b join，并且根据join的关联条件只有a.date=’2017-07-24’  的时候才会真正执行join，其余情况下又由于是left outer join, 右面会留NULL</p>
</li>
<li><p><a href="http://beadooper.com/?page_id=313">配置文件</a></p>
</li>
<li><p> <a href="http://superlxw1234.iteye.com/blog/1751216">正则</a><br>java中的正则匹配即可:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">name rlike &#39;^[\\u4e00-\\u9fa5]+$&#39;</span><br><span class="line">select mobile from phone where mobile rlike &#39;^\\d+$&#39; ;  </span><br></pre></td></tr></table></figure></li>
<li><p><a href="http://superlxw1234.iteye.com/blog/1582880">控制hive任务中的map数和reduce数</a></p>
</li>
<li><p><a href="https://github.com/hbutani/SQLWindowing"> SQLWindowing</a></p>
</li>
<li><p><a href="http://blog.csdn.net/yeweiouyang/article/details/42082663">hdfs目录创建hive表,指定分区</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE EXTERNAL TABLE if not exists push_log(</span><br><span class="line">     hostid STRING, dayid STRING</span><br><span class="line">     plmn STRING)</span><br><span class="line"> COMMENT &#39; log table&#39;</span><br><span class="line"> PARTITIONED BY (hostid STRING, dayid STRING) </span><br><span class="line"> ROW FORMAT DELIMITED FIELDS TERMINATED BY &#39;\001&#39;</span><br><span class="line"> STORED AS TEXTFILE</span><br><span class="line"> LOCATION &#39;&#x2F;user&#x2F;data&#x2F;push&#39;;</span><br><span class="line">alter table push_log add partition(hostid&#x3D;&#39;$hostid&#39;, dayid&#x3D;&#39;$dayid&#39;) location &#39;&#x2F;user&#x2F;data&#x2F;push&#x2F;$hostid&#x2F;$dayid&#39;;</span><br></pre></td></tr></table></figure>
<p>testtext 数据<code>wer 46 weree   78 wer 89 rr  89</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table d_part(name string)  partitioned by(value string) row format delimited fields terminated by &#39;\t&#39;  lines terminated by &#39;\n&#39; stored as textfile;</span><br><span class="line"></span><br><span class="line">set hive.exec.dynamic.partition&#x3D;true;</span><br><span class="line">set hive.exec.dynamic.partition.mode&#x3D;nonstrick;</span><br><span class="line"></span><br><span class="line">insert overwrite table d_part partition(value) select name,addr as value from testtext;</span><br><span class="line"></span><br><span class="line">select * from d_part;</span><br><span class="line">show partitions d_part;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; create table d_part2(</span><br><span class="line">    &gt; name string</span><br><span class="line">    &gt; )</span><br><span class="line">    &gt; partitioned by(value string,dt string)</span><br><span class="line">    &gt; row format delimited fields terminated by &#39;\t&#39; </span><br><span class="line">    &gt; lines terminated by &#39;\n&#39;</span><br><span class="line">    &gt; stored as textfile;</span><br><span class="line">hive&gt; insert overwrite table d_part2 partition(value,dt)</span><br><span class="line">    &gt; select &#39;test&#39; as name,  </span><br><span class="line">    &gt; addr as value,</span><br><span class="line">    &gt; name as dt</span><br><span class="line">    &gt; from testtext;</span><br><span class="line">show partitions d_part2;</span><br></pre></td></tr></table></figure></li>
<li><p><a href="http://superlxw1234.iteye.com/blog/1568739">hive中转义特殊字符</a></p>
</li>
<li><p>schema tool<br><a href="https://www.cloudera.com/documentation/enterprise/5-4-x/topics/cdh_ig_hive_schema_tool.html">https://www.cloudera.com/documentation/enterprise/5-4-x/topics/cdh_ig_hive_schema_tool.html</a></p>
</li>
</ul>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>redis</title>
    <url>/2021/01/31/redis/</url>
    <content><![CDATA[<h2 id="相关笔记"><a href="#相关笔记" class="headerlink" title="相关笔记"></a>相关笔记</h2><p>1、从自己拉还是定期拉 还是master发<br>第一次全量复制的时候，从发命令后主发rdb和写缓存<br>续传的时候：master维护backlog里有offset、master run id,从发送offset给主，如果没有则全量<br>其他情况，master会异步发送</p>
<a id="more"></a>
<p>2、单机写 读的并发量、集群并发量<br>几万、十万qps、几十万<br>单个value 1g</p>
<p>3、哨兵没有检测到主failure， 主自动重启，导致数据清空</p>
<p>4、通信及复制：<br>启动slave时：PSYNC给master<br>第一次连接—全量复制中，两个点：1rdb快照 2写命令缓存<br>全量参数：1时间60s 2内存缓冲区持续消耗和一次性超过<br>断点续传：网络故障的部分复制，offset</p>
<p>5、哨兵+主从复制<br>不保证0丢失，保证高可用</p>
<p>6、heartbeat<br>互相发送，主每10s、从每1s</p>
<p>7、主备切换前提、选举算法、哨兵master信息同步<br>选举前提 quorum和majority,至少满足max(quorum,majority)<br>选举算法：四个参数。<br>切换后其他的哨兵更新master配置：通过监听的channel中的version号，version号是负责切换的哨兵从新的master中获得的configuration epoch</p>
<p>8、持久化方式、优缺点、实现<br>Rdb：定期地冷备数据 — fork子进程进行磁盘io，不影响高性能，但如果rdb文件特别大则会影响服务，每隔5min宕机丢数据<br>aof：每1s后台fsync，最多丢1s数据。append写入文件，无磁盘寻址时间，文件尾部破损容易修复(?)、命令基于内存的数据重新构建而不是基于旧的指令日志 – rewrite log（指令压缩、旧的仍然提供服务，新的好了后替换），灾难性误删除.</p>
<p>9、并发竞争<br>redis的cas？zookeeper分布式锁？<br>采用CAS协议，则是如下的情景。<br> •第一步，A取出数据对象X，并获取到CAS-ID1；<br>•第二步，B取出数据对象X，并获取到CAS-ID2； <br>•第三步，B修改数据对象X，在写入缓存前，检查CAS-ID与缓存空间中该数据的CAS-ID是否一致。结果是“一致”，就将修改后的带有CAS-ID2的X写入到缓存。<br> •第四步，A修改数据对象Y，在写入缓存前，检查CAS-ID与缓存空间中该数据的CAS-ID是否一致。结果是“不一致”，则拒绝写入，返回存储失败。<br>这样CAS协议就用了“版本号”的思想，解决了冲突问题。（乐观锁概念）</p>
<p>在使用redis的setnx方法和memcace的add方法时，如果指定的key已经存在，则返回false。利用这个特性，实现全局锁<br>每次生成全局id前，先检测指定的key是否存在，如果不存在则使用redis的incr方法或者memcache的increment进行加1操作。这两个方法的返回值是加1后的值，如果存在，则程序进入循环等待状态。循环过程中不断检测key是否还存在，如果key不存在就执行上面的操作。</p>
<p>10、数据恢复<br>放到指定目录，然后重启redis，redis会恢复内存中的数据然后继续提供服务</p>
<p>11、哨兵–分布式<br>监控、修改地址(确保slave连接正确的master)、主从切换（确保潜在master的slave复制了所有的数据）、故障通知<br>两个配置：quorum、majority<br>quorum是至少多少哨兵认为宕机，才是master真的宕机<br>majority是必须满足大多数的哨兵是运行，才能进行故障转移。<br>=&gt;主备切换至少满足max(quorum,majority)<br>sdown odown</p>
<p>12、丢失：<br>case1slave没有同步完master的数据，master宕机<br>case2master机器脱离了集群，但是仍然运行，哨兵又选举了新的master。但是client还是在旧的写，旧的成为slave去新的master更新数据。这部分写丢失。<br>解决：两个参数。master宕机控制在丢失数据10s内。一点超过10s的数据复制，则master停止写请求。</p>
<p>13、哨兵自动发现<br>1往自己监控的channel里发消息 ，包括： runid、master监控配置、hostip<br>2监听channel，感知其他的哨兵<br>3监控配置的同步</p>
<p>14、cluster<br>Cluster bus通信、gossip协议</p>
<p>15、集群元数据维护方式<br>集中式：zookeeper作为实现，时效性高，存储更新有压力<br>gossip：分散更新，滞后</p>
<p>16、一致性hash、hash slot<br>hash的值空间组成一个环，将master的ip进行hash，确定在环的位置。数据找到位置后，存入顺时针走的第一个遇到的master。<br>当master宕机，则master和前一个master之间的数据受到影响。<br>热点问题：master计算多个hash值，在环中增加虚拟节点<br>slot：每个key计算crc16值，然后对16384取模，对应到相应的hash slot。每个master持有部分的slot</p>
<p>17、cluster中的选举、复制和哨兵<br>大于一半的master投票给该slave则该slave可以替换为master<br>cluster直接集成了复制和哨兵功能</p>
<p>18、缓存雪崩<br>所有的请求在redis都没有命中<br>解决：<br>redis高可用(主从+哨兵)、hystrix限流+本地ehcache缓存、redis持久化<br>先查本地、再redis、再限流，未通过的请求则降级</p>
<p>19、穿透<br>没查到则写一个空值到redis</p>
<p>20、击穿<br>热点key失效时缓存被瞬时击穿<br>1不用更新则永不过期 2更新频率高或者时间长则定时线程提前主动重新构建缓存或者延后过期时间 3更新频率低或者时间短，则分布式互斥锁或者本地锁保证少量请求能重新构建缓存，其余则锁释放后再访问新的缓存</p>
<p>21、双写一致性<br>Cache aside：读-先读缓存、再读数据库、再写入缓存，更新则先更新数据库、再删除缓存<br>为什么是删除不是更新？lazy<br>删除缓存失败？–先删除缓存再更新数据库<br>先删除缓存再更新数据库–还是会有不一致，每秒并发几万：当更新没完成，一个请求来了，写入缓存的是旧数据，然后又更新了数据库。</p>
<p>解决：串行化。<br>更新的数据都附带上数据标识，如果不在缓存中，则将读和更新发到一个队列中，线程从队列中串行地拿操作执行。<br>注意：1请求操作的超时（过多的写操作积压，一般单机20个队列，qps500的写可以支持，200ms里100个写，每个队列5个，每个20ms完成，那么读请求也可以在200ms内返回。否则扩容机器） 2读并发高 3热点商品的请求倾斜 4路由到同一台机子</p>
<p>22、线上部署情况<br>cluster模式，10台机器，5台master，一主一从<br>每个master高峰的qps 5w<br>master配置：32g8core+1T，分给redis内存最多10g<br>内存中放商品数据，每条数据大概10kb，10w条则1g，一般200w条，占20g。目前的qps高峰是3500左右请求量。</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>xgboost</title>
    <url>/2021/03/11/xgboost/</url>
    <content><![CDATA[<br>

<h1 id="xgboost"><a href="#xgboost" class="headerlink" title="xgboost"></a>xgboost</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul>
<li>xgboost是Gradient Boosting的一种高效系统实现</li>
</ul>
<a id="more"></a>
<h2 id="基学习器"><a href="#基学习器" class="headerlink" title="基学习器"></a>基学习器</h2><ul>
<li>tree(gbtree)，也可用线性分类器(gblinear)。GBDT则特指梯度提升决策树算法</li>
</ul>
<h2 id="loss"><a href="#loss" class="headerlink" title="loss"></a>loss</h2><ul>
<li><p>xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数</p>
</li>
<li><p>xgboost工具支持自定义代价函数</p>
</li>
<li><p>代价函数里加入了正则项</p>
<ul>
<li>树的叶子节点个数</li>
<li>每个叶子节点上输出的score的L2模的平方和</li>
<li>正则项降低了模型的variance</li>
</ul>
</li>
<li><p>Shrinkage（xgboost中的eta）</p>
<ul>
<li>xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。</li>
<li>一般把eta设置得小一点，然后迭代次数设置得大一点</li>
</ul>
</li>
<li><p>gamma </p>
<ul>
<li>当增益大于阈值时才让节点分裂，gamma即阈值</li>
<li>它是正则项里叶子节点数T的系数，所以xgboost在优化目标函数的同时相当于做了预剪枝。</li>
</ul>
</li>
<li><p>lambda</p>
<ul>
<li>正则项里leaf score的L2模平方的系数，对leaf score做了平滑，也起到了防止过拟合的作用，这个是传统GBDT里不具备的特性。</li>
</ul>
</li>
</ul>
<h2 id="样本"><a href="#样本" class="headerlink" title="样本"></a>样本</h2><ul>
<li>缺失值<ul>
<li>对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向</li>
</ul>
</li>
<li>列抽样<ul>
<li>xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算</li>
</ul>
</li>
</ul>
<h2 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h2><ul>
<li><p>在特征粒度上</p>
</li>
<li><p>最耗时的一个步骤就是对特征的值进行排序（因为要确定最佳分割点）</p>
</li>
<li><p>预先对数据进行了排序，然后保存为block结构，后面的迭代中重复地使用这个结构</p>
</li>
<li><p>在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行。</p>
</li>
<li><p>可并行的近似直方图算法</p>
<ul>
<li>用贪心法枚举所有可能的分割点，当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低</li>
</ul>
</li>
</ul>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ul>
<li><a href="https://www.zhihu.com/question/41354392">GBDT 和 XGBOOST 的区别有哪些</a></li>
</ul>
<hr>
<p>mind:</p>
<p><img src="/2021/03/11/xgboost/xgboost.png" alt="xgboost"></p>
]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树</title>
    <url>/2021/02/21/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<br>
让我联想到博弈论中的决策树。根据多种可能地情况路径，利用概率和已知知识，进行决策判断。
<br>
<br>

<h4 id="基本问题"><a href="#基本问题" class="headerlink" title="基本问题"></a>基本问题</h4><p>Q1：如果建立一颗树，使得经过路径判断，走到叶子时候，能够得到最终样本归属的label(类别)或者y(连续值)？</p>
<ul>
<li>分析这棵树需要满足的基本性质<br>互斥、完备。即通过各条到叶子的不同路径，能够最终覆盖绝多数的样本。</li>
</ul>
<a id="more"></a>

<ul>
<li><p>生成这棵树的过程<br>1、要得到中间节点(特征)。分类能力越强的特征，越靠近根。<br>2、要找到当前特征的切分点，而进行分叉。<br>即涉及到特征选择(特征间重要性比较以及当前特征的切分点)。<br>而构建的过程，则是递归地选择特征的过程。<br>直到，没有特征可选、或者样本点已经完全覆盖(特征选择的标准达到阈值，不再分叉)。</p>
</li>
<li><p>分析回归树<br>1、回归树对特征选择和切分点选择的标准，肯定是区别于分类树的。<br>2、回归树的y如何生成？<br>分类树的label来自于多数投票。回归树则来自于，落入叶子的样本的均值。</p>
</li>
</ul>
<p>综上，<br>1、特征选择只在当前考虑选择最优，属于贪心策略，为局部最优。<br>2、本质上，是将样本空间进行直线(线性棱的空间体)切割。是概率中的条件概率。多个特征规则组合的条件下，样本所属类别的判定。<br>3、由于1，生成的树易产生过拟合。<br>4、回归树的回归结果，相比于lr等回归预测模型，结果数量是少的。</p>
<p>Q2：如何进行特征选择？</p>
<ul>
<li><p>对于分类树：<br>1、例如性别、年龄，如果已知性别能够比已知年龄，是更好的信息–即可以更大概率地判断出所属类别，那么就是更重要的特征。<br>2、其中，更大概率地判断出所属类别 – 即降低经验条件熵。<br>3、而经验条件熵的缺点是，对于取值比较多的特征，具有偏向性。其公式导致，取值多则经验条件熵值会小。可以考虑极端情况，当每个样本的该特征都取值不同，则经验条件熵为0。就有了C4.5，通过信息增益比来选择特征。<br>4、CART的gini系数本质和熵类似。越小，熵越小，确定性越高，特征越重要。</p>
</li>
<li><p>对于回归树：<br>1、cart回归树是二叉，要么是要么否。<br>2、回归树的切分选择不以熵入手考虑，而以均方误差作为判断标准。<br>3、对于当前特征，找到这样的切分点 – 使得此切分下的两个叶子样本集中，均方误差和最小。误差为：y-所有样本y的均值。<br>4、生成树过程和分类树一样。</p>
</li>
<li><p>为什么不用相关性？<br>余弦相似度是特征向量在label向量方向上的投影长度。一定程度也是特征重要的体现。<br>但是，在树模型中，由于本质是条件概率模型，熵就更能反映出概率模型的好坏。</p>
</li>
</ul>
<p>Q3：过拟合处理？</p>
<ul>
<li><p>剪枝<br>1、ID3,C4.5的剪枝是一个动态规划算法。对于某个非叶节点，计算剪去子树后的树的loss和不剪的loss。根据loss小的选择相应动作。而loss大小的比较，可以进行局部计算。因此可用动规实现。<br>2、loss为，每棵树的所有叶子上样本的熵之和，加上惩罚项(叶子数量或者节点数量)。<br>3、本质为，正则化的极大似然函数，来选择概率模型。</p>
</li>
<li><p>CART剪枝<br>1、区别于ID3&amp;C4.5，利用了递归思想，对所生成的树进行剪枝。<br>2、对于某个中间节点，找到进行剪枝动作的阈值–a的大小，a大于阈值则剪枝。即对于每一个中间节点，都有这样的阈值thre所决定的区间[thre,正无穷），剪枝后的树优于生成树。<br>3、对于所有的最优字数，交叉验证得到最终的最优树，并得到响应的a的thre。</p>
</li>
</ul>
<br>


<h4 id="扩展问题"><a href="#扩展问题" class="headerlink" title="扩展问题"></a>扩展问题</h4><p>Q4：信息增益比的缺点？<br>偏好取值少的特征。<br>C4.5不是直接选择增益比最大的特征，而是之前先把信息增益低于均值的属性剔除，然后在剩下的特征中选择而信息增益比最大的。得到兼顾。</p>
<p>Q5：预剪枝？<br>1、对当前节点在划分时，进行估计，如果不能够提升泛化能力则不进行划分。<br>2、本质是基于贪心，对当前节点进行判断是否划分。<br>3、坏处：当前虽然不能提升泛化能力，但可能划分后子树能够提升泛化能力。导致模型欠拟合。</p>
<p>Q6：对比LR和决策树？<br>1、y的结果上，决策树是固定的几个值。<br>2、LR比决策树慢，时间复杂度高。<br>3、LR无法处理缺失值，需要赋值。并且对极端值更敏感<br>4、LR对线性关系、全局拟合较好。决策树则是局部最优、局部数据探查更细致，不能更好地对多个特征同时考量。</p>
<p>Q7：CART做了哪些简化？<br>1、log函数的计算量大，而gini由图形可知，是对熵模型的很好的近似。<br>2、CART是二叉树，对每个特征进行二分而非多分，减少了特征选择时的计算。</p>
<p>Q8：测试集上缺失值的处理？<br>1、赋平均值或出现频次最高的值<br>2、走特征的常用分支<br>3、特征值专门处理的分支<br>C4.5的方式是，探查所有的分支，然后得到每个类别的概率，取最大的赋给该样本。</p>
<p>Q9：CART对于离散特征处理、连续特征处理的不同之处？<br>1、ID3&amp;C4.5都是多叉，特征只出现在一个中间节点；CART是对离散特征不断地二分。<br>2、连续特征：遍历每个特征，对某特征找到最小化均方误差(loss)的thre点，该点作为该特征的切分点。在所有特征中找到最小的loss，得到最优的(特征，特征切分点)作为中间节点。二分后，对每个孩子继续进行最优的(特征，特征切分点)的查找。同离散特征一样，连续特征可以重复出现，作为中间节点。直到达到停止条件。<br>3、CART连续特征：换种表述：对于任意划分特征A，对应的任意划分点s两边划分成的数据集D1和D2，求出使D1和D2各自集合的均方差最小，同时D1和D2的均方差之和最小所对应的特征和特征值划分点。<br>4、ID3不支持连续特征划分。C4.5的做法是，将连续值进行排序，取两个值的中间值作为划分点，然后算信息增益比，(连续和离散的)最大的信息增益比为该中间节点。当连续值较多时，计算量的大。并且和CART一样，该连续特征同样可以继续作为中间节点，而非和离线一样一次性地生成多个孩子分叉。</p>
<p>Q10：缺点或者优化？<br>1、分类决策不应该是由某一个特征决定的，而是应该由一组特征决定的。这样决策得到的决策树更加准确。这个决策树叫做多变量决策树(multi-variate decision tree)。在选择最优特征的时候，多变量决策树不是选择某一个最优特征，而是选择最优的一个特征线性组合来做决策。这个算法的代表是OC1。<br>2、如果样本发生一点点的改动，就会导致树结构的剧烈改变。这个可以通过集成学习里面的随机森林之类的方法解决。</p>
<p>其他–都可以在上述问题中找到答案：<br>如何找到切分点？</p>
]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务</title>
    <url>/2021/02/04/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-%E4%B8%8A/</url>
    <content><![CDATA[<p><strong>摘要</strong></p>
<p>1、什么是事务、分布式事务，分布式事务的场景<br>2、CAP理论，及BASE理论，柔性事务</p>
<a id="more"></a>
<p>3、分布式事务解决模型:2PC TCC （概念、区别）<br>4、2PC解决方案：XA、AT（角色、流程、实战、缺点、区别）<br>5、TCC解决方案：三种异常处理、Hmily实现</p>
<h2 id="1、事务、分布式事务及场景"><a href="#1、事务、分布式事务及场景" class="headerlink" title="1、事务、分布式事务及场景"></a>1、事务、分布式事务及场景</h2><ul>
<li><p>一般利用数据可事务特性，为数据库事务。数据库和应用在一个服务器，则为本地事务。</p>
</li>
<li><p>事务则需要有ACID性质。</p>
<ul>
<li>原子性、一致性、隔离性(一个事务不能看到其他事务的中间状态)、持久性</li>
</ul>
</li>
<li><p>而分布式事务则和分布式架构相关，当服务被拆分，并通过网络进行协作，则一个事务就涉及到多个服务以及远程调用。此时为分布式事务。</p>
</li>
<li><p>场景：</p>
<ul>
<li>微服务架构中，即需要跨JVM进程。无论是多个服务访问一个实例，还是多个服务多个实例，本地事务都无法解决。</li>
<li>单个系统访问多个数据库实例，就需要进行不同的数据库连接</li>
</ul>
</li>
</ul>
<br>

<h2 id="2、CAP"><a href="#2、CAP" class="headerlink" title="2、CAP"></a>2、CAP</h2><h3 id="分布式事务控制目标"><a href="#分布式事务控制目标" class="headerlink" title="分布式事务控制目标"></a>分布式事务控制目标</h3><p>场景：mysql一主一从，商品写主读从。</p>
<p>一致性、可用性、分区容错性</p>
<ul>
<li><p>consistency：写操作后的读(任意节点读)可以读到最近状态。</p>
<ul>
<li>在从同步数据的过程中，将从锁住，同步完再允许查询。 需要1写响应有延迟；2资源锁定与释放；3同步失败则返回错误信息而不能返回旧数据</li>
</ul>
</li>
<li><p>availability：任何事务操作都可以得到响应，且不会响应错误或超时。</p>
<ul>
<li>需要能够立即响应并非错误、非超时，可以允许旧数据。需要1同步时不能锁定；2返回旧数据或者默认值</li>
</ul>
</li>
<li><p>partitio tolerance：分布式各个节点在不同的子网，就形成了网络分区，彼此需要通过网络进行交互，当网络通信失败时，仍能够提供服务。</p>
<ul>
<li>单个节点挂了不影响其他节点，同步时不影响读写操作。需要1添加主备从备节点、避免主或从挂了；2异步进行数据从主到从的同步</li>
</ul>
</li>
</ul>
<blockquote>
<p>三个特性不能共存。一般选择AP，达到最终一致性即可。</p>
</blockquote>
<ul>
<li>AP，通常实现AP都会保证最终一致性</li>
<li>CP，zookeeper追求的就是强一致</li>
<li>CA，不进行分区，本地事务隔离级别即可。</li>
</ul>
<br>

<h2 id="BASE理论与柔性事务"><a href="#BASE理论与柔性事务" class="headerlink" title="BASE理论与柔性事务"></a>BASE理论与柔性事务</h2><p>在AP中，满足1 基本可用 2 软状态 3 最终一致。即满足base，为柔性事务。</p>
<ul>
<li>软状态: 中间状态– 当同步过程中来了查询，给出“支付中”状态，一致后再返回“成功”。</li>
</ul>
<br>

<h2 id="3、2PC"><a href="#3、2PC" class="headerlink" title="3、2PC"></a>3、2PC</h2><h3 id="3-1-2PC概念"><a href="#3-1-2PC概念" class="headerlink" title="3.1 2PC概念"></a>3.1 2PC概念</h3><ul>
<li><p>两阶段提交协议，prepare准备阶段和commit提交阶段。</p>
</li>
<li><p>包含 事务管理器和事务参与者(数据库实例)。管理器决定整个事务的提交和回滚，参与者负责本地事务的提交和回滚。</p>
</li>
<li><p>过程：</p>
<ul>
<li>prepare： 管理器向每个实例发送prepare消息，每个实例写本地的undo(修改前的数据)和redo(修改后的数据)日志。此时没有提交。</li>
<li>commit： 管理器收到参与者的失败或超时，则向每个参与者发送rollback消息。否则向每个实例发送commit。每个参与者进行执行指令并释放锁。</li>
</ul>
</li>
</ul>
<br>

<h3 id="3-2-2PC解决方案"><a href="#3-2-2PC解决方案" class="headerlink" title="3.2 2PC解决方案"></a>3.2 2PC解决方案</h3><h4 id="3-2-1-XA方案"><a href="#3-2-1-XA方案" class="headerlink" title="3.2.1 XA方案"></a>3.2.1 XA方案</h4><p>规范数据库实现2pc协议的分布式事务处理模型DTP。<br>定义了角色：AP RM TM,TM 和 RM 通讯接口为XA。即数据库提供的2pc接口协议，基于该协议的2pc实现为xa方案。</p>
<p>缺点：<br>1、资源锁需要事务的两个阶段结束才能释放<br>2、本地数据库需要支持XA协议<br><br></p>
<h4 id="3-2-2-Seata方案"><a href="#3-2-2-Seata方案" class="headerlink" title="3.2.2 Seata方案"></a>3.2.2 Seata方案</h4><p>Seata是提供AT和TCC模式的分布式事务解决方案。</p>
<ul>
<li><p>与XA区别：</p>
<ul>
<li>1、XA是两阶段后释放锁，而AT模式(2pc)第一阶段则提交释放锁</li>
<li>2、AT是应用层的中间件，对业务0侵入。</li>
</ul>
</li>
<li><p>实现：</p>
<ul>
<li>三个角色，TC TM RM。</li>
<li>TC负责，接收TM的全局事务提交或回滚指令，和RM通信协调分支事务。</li>
<li>TM，开启全局事务，向TC发出提交或回滚指令。</li>
<li>RM，分支注册、状态汇报、接收TC指令、驱动本地事务提交或回滚的执行。</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>具体的执行流程如下:</li>
</ul>
<ol>
<li>用户服务的 TM 向 TC 申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的XID。</li>
<li>用户服务的 RM 向 TC 注册 分支事务，该分支事务在用户服务执行新增用户逻辑，并将其纳入 XID 对应全局<br>事务的管辖。</li>
<li>用户服务执行分支事务，向用户表插入一条记录。</li>
<li>逻辑执行到远程调用积分服务时(XID 在微服务调用链路的上下文中传播)。积分服务的RM 向 TC 注册分支事<br>务，该分支事务执行增加积分的逻辑，并将其纳入 XID 对应全局事务的管辖。</li>
<li>积分服务执行分支事务，向积分记录表插入一条记录，执行完毕后，返回用户服务。</li>
<li>用户服务分支事务执行完毕。</li>
<li>TM 向 TC 发起针对 XID 的全局提交或回滚决议。</li>
<li>TC 调度 XID 下管辖的全部分支事务完成提交或回滚请求。</li>
</ol>
<hr>
<ul>
<li>详解流程：<ul>
<li>每个RM使用DataSourceProxy连接数据库，其目的是使用ConnectionProxy，使用数据源和数据连接代理的目 的就是在第一阶段将undo_log和业务数据放在一个本地事务提交，这样就保存了只要有业务操作就一定有 undo_log。</li>
<li>在第一阶段undo_log中存放了数据修改前和修改后的值，为事务回滚作好准备，所以第一阶段完成就已经将分 支事务提交，也就释放了锁资源。</li>
<li>TM开启全局事务开始，将XID全局事务id放在事务上下文中，通过feign调用也将XID传入下游分支事务，每个 分支事务将自己的Branch ID分支事务ID与XID关联。</li>
<li>第二阶段全局事务提交，TC会通知各各分支参与者提交分支事务，在第一阶段就已经提交了分支事务，这里各各参与者只需要删除undo_log即可，并且可以异步执行，第二阶段很快可以完成。</li>
<li>第二阶段全局事务回滚，TC会通知各各分支参与者回滚分支事务，通过 XID 和 Branch ID 找到相应的回滚日志，通过回滚日志生成反向的 SQL 并执行，以完成分支事务回滚到之前的状态，如果回滚失败则会重试回滚操作。</li>
</ul>
</li>
</ul>
<ul>
<li><p>实战step：</p>
<ul>
<li>下载，解压并启动seata服务器 /bin/seata-server.bat -p 8888 -m file 。端口和文件方式存储信息。(TC)</li>
<li>添加discover-server子模块，discover-server基于Eureka实现。</li>
<li>添加微服务子模块，子模块pom中引入spring-cloud-alibaba-seata（包含了RM TM），并配置TC的地址：registry.conf、file.conf中：</li>
</ul>
<blockquote>
<p>在file.conf中更改service.vgroup_mapping.[springcloud服务名]-fescar-service-group = “default”，并修改 service.default.grouplist =[seata服务端地址]</p>
</blockquote>
<ul>
<li>创建代理数据源（配置mysql连接）</li>
</ul>
<blockquote>
<p>Seata的RM通过DataSourceProxy才能在业务代码的事务提交时，通过这个切<br>  入点，与TC进行通信交互、记录undo_log等。每个RM使用DataSourceProxy连接数据库，其目的是使用ConnectionProxy，使用数据源和数据连接代理的目 的就是在第一阶段将undo_log和业务数据放在一个本地事务提交，这样就保存了只要有业务操作就一定有 undo_log。</p>
</blockquote>
<ul>
<li>代码部分细节：<code>FeignClient</code>、<code>@GlobalTransactional</code>、<code>@Transactional</code></li>
</ul>
<blockquote>
<p>将@GlobalTransactional注解标注在全局事务发起的Service实现方法上，开启全局事务: GlobalTransactionalInterceptor会拦截@GlobalTransactional注解的方法，生成全局事务ID(XID)，XID会在整个分布式事务中传递。 在远程调用时，spring-cloud-alibaba-seata会拦截Feign调用将XID传递到下游服务。</p>
</blockquote>
</li>
</ul>
<br>

<h3 id="4、TCC"><a href="#4、TCC" class="headerlink" title="4、TCC"></a>4、TCC</h3><h4 id="4-1-TCC相关解决方案"><a href="#4-1-TCC相关解决方案" class="headerlink" title="4.1 TCC相关解决方案"></a>4.1 TCC相关解决方案</h4><p>tcc-transaction、<br>Hmily、<br>ByteTcc、<br>EasyTransaction</p>
<br>

<h4 id="4-2-TCC的三种异常处理"><a href="#4-2-TCC的三种异常处理" class="headerlink" title="4.2 TCC的三种异常处理"></a>4.2 TCC的三种异常处理</h4><ol>
<li><strong>空回滚</strong><br> 没有执行try就执行了cancel</li>
<li><strong>幂等</strong><br> cancel和commit会重试</li>
<li><strong>悬挂</strong><br> RPC 调用分支事务try时，先注册分支事务，再执行RPC调用，如果此时 RPC 调用的网络发生拥堵， 通常 RPC 调用是有超时时间的，RPC 超时以后，TM就会通知RM回滚该分布式事务，可能回滚完成后，RPC 请求 才到达参与者真正执行，而一个 Try 方法预留的业务资源，只有该分布式事务才能使用，该分布式事务第一阶段预 留的业务资源就再也没有人能够处理了，对于这种情况，我们就称为悬挂，即业务资源预留后没法继续处理。</li>
</ol>
<p>转账最终方案：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;A</span><br><span class="line">try: </span><br><span class="line">	try幂等校验</span><br><span class="line">	try悬挂处理 </span><br><span class="line">	检查余额是否够30元 </span><br><span class="line">	扣减30元</span><br><span class="line">confirm: </span><br><span class="line">	空</span><br><span class="line">cancel: </span><br><span class="line">	cancel幂等校验</span><br><span class="line">	cancel空回滚处理 </span><br><span class="line">	增加可用余额30元</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;B</span><br><span class="line">try: </span><br><span class="line">	空</span><br><span class="line">confirm: </span><br><span class="line">	confirm幂等校验</span><br><span class="line">	正式增加30元 </span><br><span class="line">cancel:</span><br><span class="line">	空</span><br></pre></td></tr></table></figure>
<h4 id="4-3-Hmily实现TCC事务"><a href="#4-3-Hmily实现TCC事务" class="headerlink" title="4.3 Hmily实现TCC事务"></a>4.3 Hmily实现TCC事务</h4><ul>
<li><p>新增配置类接收application.yml中的Hmily配置信息，并创建HmilyTransactionBootstrap Bean</p>
</li>
<li><p>A账户</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;DAO 略</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;service </span><br><span class="line"></span><br><span class="line">	@Override</span><br><span class="line">    @Transactional</span><br><span class="line">    @Hmily(confirmMethod &#x3D; &quot;commit&quot;, cancelMethod &#x3D; &quot;rollback&quot;)</span><br><span class="line">	public  void updateAccountBalance(String accountNo, Double amount) &#123;</span><br><span class="line">		&#x2F;&#x2F;事务id</span><br><span class="line">		&#x2F;&#x2F;try幂等校验</span><br><span class="line">		&#x2F;&#x2F;try悬挂处理</span><br><span class="line">		&#x2F;&#x2F;从账户扣减及扣减失败</span><br><span class="line">		&#x2F;&#x2F;增加本地事务try成功记录，用于幂等性控制标识 accountInfoDao.addTry(transId);</span><br><span class="line">		&#x2F;&#x2F;远程调用bank2</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;feign</span><br><span class="line"></span><br><span class="line">	@FeignClient(value &#x3D; &quot;seata‐demo‐bank2&quot;, fallback &#x3D; Bank2Fallback.class)</span><br><span class="line">	public interface Bank2Client &#123;</span><br><span class="line">		@GetMapping(&quot;&#x2F;bank2&#x2F;transfer&quot;)</span><br><span class="line">		@Hmily</span><br><span class="line">		Boolean transfer(@RequestParam(&quot;amount&quot;) Double amount);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;controller 略</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>B账户 略</li>
</ul>
<h4 id="4-4-TCC与2PC对比"><a href="#4-4-TCC与2PC对比" class="headerlink" title="4.4 TCC与2PC对比"></a>4.4 TCC与2PC对比</h4><ol>
<li>2PC通常在DB层面，TCC在应用层面</li>
<li>2PC无侵入性，TCC自定义数据操作粒度，锁冲突降低，提高吞吐，但业务逻辑每个分支都需要实现TCC三个方法，且需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。</li>
</ol>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务-下</title>
    <url>/2021/02/04/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-%E4%B8%8B/</url>
    <content><![CDATA[<p><br> <br></p>
<p><strong>摘要</strong></p>
<p>1、可靠消息最终一致性，概念特点、问题、针对问题的方案(本地消息表、Rocketmq)<br>2、本地消息表流程图<br>3、Rocketmq流程、实战<br>4、最大努力通知，流程、</p>
<a id="more"></a>

<h2 id="可靠消息最终一致性"><a href="#可靠消息最终一致性" class="headerlink" title="可靠消息最终一致性"></a>可靠消息最终一致性</h2><p>当事务发起方执行完成本地事务后并发出一条消息，事务参与方(消息消费者)一定能 够接收消息并处理事务成功，此方案强调的是只要消息发给事务参与方最终事务要达到一致。</p>
<ul>
<li><p>特点</p>
<ul>
<li>适合执行周期长且实时性要求不高的场景</li>
<li>引入消息机制后，同步的事务操作变为基于消 息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦。</li>
</ul>
</li>
<li><p>网络通信的不确定性会导致分布式事务问题：</p>
</li>
</ul>
<ol>
<li>事务发起方(消息生产方)将消息发给消息中间件</li>
<li>事务参与方从消息中间件接收消息</li>
</ol>
<h3 id="可靠消息最终一致性的问题"><a href="#可靠消息最终一致性的问题" class="headerlink" title="可靠消息最终一致性的问题"></a>可靠消息最终一致性的问题</h3><p>1、本地事务与消息发送的原子性问题</p>
<ul>
<li>发送消息成功，数据库操作失败  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">begin transaction; </span><br><span class="line">		&#x2F;&#x2F;1.发送MQ</span><br><span class="line">		&#x2F;&#x2F;2.数据库操作 </span><br><span class="line">commit transation;</span><br></pre></td></tr></table></figure></li>
<li>如果发送MQ消息失败，就会抛出异常，导致数据库事务回滚。但如果是超时异常，数 据库回滚，但MQ其实已经正常发送了，同样会导致不一致。  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">begin transaction; </span><br><span class="line">	&#x2F;&#x2F;1.数据库操作</span><br><span class="line">	&#x2F;&#x2F;2.发送MQ </span><br><span class="line">commit transation;</span><br></pre></td></tr></table></figure>
2、事务参与方接收消息的可靠性，需要如果接收消息失败可以重复接收消息</li>
</ul>
<p>3、消息重复消费的问题，要解决消息重复消费的问题就要实现事务参与方的方法幂等性。 </p>
<h2 id="本地消息表方案"><a href="#本地消息表方案" class="headerlink" title="本地消息表方案"></a>本地消息表方案</h2><p><img src="/2021/02/04/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-%E4%B8%8B/bendixiaoxibiao.png" alt="本地消息表方案"></p>
<ul>
<li>交互流程规范</li>
</ul>
<ol>
<li>用户服务在本地事务新增用户和增加 ”积分消息日志“。(用户表和消息表通过本地事务保证一致)</li>
<li>定时任务扫描日志–&gt;保证将消息发送给消息队列。启动独立的线程，定时对消息日志表中的消息进行扫描并发送至消息中间件，在消息中间件反馈发送成功后删除该消息日志，否则等待定时任务下一周期重试。</li>
<li>MQ的ack(即消息确认)机制–&gt;幂等，收到ack，MQ将不再向消费者推送消息，否则消费者会不断重 试向消费者来发送消息。</li>
</ol>
<h2 id="RocketMQ事务消息方案"><a href="#RocketMQ事务消息方案" class="headerlink" title="RocketMQ事务消息方案"></a>RocketMQ事务消息方案</h2><ul>
<li>交互流程实现</li>
</ul>
<ol>
<li>Producer (MQ发送方)发送事务消息至MQ Server，MQ Server将消息状态标记为Prepared(预备状态)，注意此时这条消息消费者(MQ订阅方)是无法消费到的。</li>
<li>MQ Server接收到Producer 发送给的消息则回应发送成功表示MQ已接收到消息。</li>
<li>Producer 端执行业务代码逻辑，通过本地数据库事务控制。</li>
<li>若Producer 本地事务执行成功则自动向MQServer发送commit消息，MQ Server接收到commit消息后将状态标记为可消费，此时MQ订阅方(积分服务)即正常消费消息。若Producer 本地事务执行失败则自动向MQServer发送rollback消息，MQ Server接收到rollback消息后 将删除消息。</li>
<li>如果执行Producer端本地事务过程中，执行端挂掉或者超时，MQ Server将会不停的询问同组的其他 Producer来获取事务执行状态，这个过程叫事务回查。MQ Server会根据事务回查结果来决定是否投递消息。 </li>
</ol>
<br>

<ul>
<li>以上主干流程已由RocketMQ实现，对用户侧来说，用户需要：</li>
</ul>
<ol>
<li>实现本地事务执行</li>
<li>本地事务回查方法，因此关注本地事务的执行状态</li>
</ol>
<h3 id="RocketMq事务"><a href="#RocketMq事务" class="headerlink" title="RocketMq事务"></a>RocketMq事务</h3><p>RocketMQ主要解决了两个功能:<br>1、本地事务与消息发送的原子性问题。<br>2、事务参与方接收消息的可靠性。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;回调</span><br><span class="line"></span><br><span class="line"> public interface RocketMQLocalTransactionListener &#123;</span><br><span class="line">      &#x2F;**</span><br><span class="line">		‐ 发送prepare消息成功此方法被回调，该方法用于执行本地事务</span><br><span class="line">		‐ @param msg 回传的消息，利用transactionId即可获取到该消息的唯一Id</span><br><span class="line">		‐ @param arg 调用send方法时传递的参数，当send时候若有额外的参数可以传递到send方法中，这里能获取到</span><br><span class="line">		‐ @return 返回事务状态，COMMIT:提交 ROLLBACK:回滚 UNKNOW:回调</span><br><span class="line">		*&#x2F;</span><br><span class="line">          RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg);</span><br><span class="line"></span><br><span class="line">      	&#x2F;**</span><br><span class="line">		‐ @param msg 通过获取transactionId来判断这条消息的本地事务执行状态</span><br><span class="line">		‐ @return 返回事务状态，COMMIT:提交 ROLLBACK:回滚 UNKNOW:回调</span><br><span class="line">		*&#x2F;</span><br><span class="line">          RocketMQLocalTransactionState checkLocalTransaction(Message msg);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> &#x2F;&#x2F; 发送事务消息API  </span><br><span class="line">TransactionMQProducer producer &#x3D; new TransactionMQProducer(&quot;ProducerGroup&quot;); producer.setNamesrvAddr(&quot;127.0.0.1:9876&quot;);</span><br><span class="line">producer.start();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;设置TransactionListener实现 producer.setTransactionListener(transactionListener);</span><br><span class="line">&#x2F;&#x2F;发送事务消息</span><br><span class="line">SendResult sendResult &#x3D; producer.sendMessageInTransaction(msg, null);  </span><br></pre></td></tr></table></figure>

<ul>
<li><p>实践：</p>
<ul>
<li>在application-local.propertis中配置rocketMQ nameServer地址及生产组</li>
<li>service</li>
</ul>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;从event构建消息体</span><br><span class="line">	public void sendUpdateAccountBalance(AccountChangeEvent accountChangeEvent) </span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;发送消息并收到回应后执行本地事务</span><br><span class="line">public void doUpdateAccountBalance(AccountChangeEvent accountChangeEvent)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;实现执行本地事务和事务回查两个方法</span><br><span class="line"> 	@RocketMQTransactionListener(txProducerGroup &#x3D; &quot;producer_group_txmsg_bank1&quot;)</span><br><span class="line"> 	public class ProducerTxmsgListener implements RocketMQLocalTransactionListener </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>controller 略</li>
<li>B账户的MQ 监听类</li>
</ul>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;需要实现幂等</span><br><span class="line">@RocketMQMessageListener(topic &#x3D; &quot;topic_txmsg&quot;,consumerGroup &#x3D; &quot;consumer_txmsg_group_bank2&quot;)</span><br><span class="line">public class TxmsgConsumer implements RocketMQListener&lt;String&gt; </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="最大努力通知"><a href="#最大努力通知" class="headerlink" title="最大努力通知"></a>最大努力通知</h2></li>
<li><p>流程</p>
</li>
</ul>
<ol>
<li></li>
</ol>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>学习模型的模式</title>
    <url>/2021/02/21/%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%A8%A1%E5%BC%8F/</url>
    <content><![CDATA[<p>伪代码的算法流程 + 数学逻辑 –&gt;才能真的掌握住这个模型的本质。<br>而其他都是表象。所以数学肯定是要啃的。矩阵论和概率统计，微积分，必然是需要的。<br>更多的应用和实践，会深化对于模型的认知。</p>
<a id="more"></a>

<p>基本要求：<br>1、历史背景及演进：解决什么问题而生<br>2、伪代码表述流程<br>3、前提、局限、适用场景<br>4、演化和可优化之处、优化思路<br>5、和其他模型对比</p>
<p>进阶要求：<br>1、根据伪代码思路，看具体实现<br>2、为什么会有这样的前提和局限–&gt;数学证明：唯一性证明、误差上界证明、loss函数证明、模型参数的迭代公式证明</p>
<p>炉火纯青：<br>1、当我问你某个公式，你能够给出，并给出推导过程<br>2、和其他模型相似问题下的解决方案(公式)对比</p>
]]></content>
      <categories>
        <category>模型方法论</category>
      </categories>
      <tags>
        <tag>方法论</tag>
      </tags>
  </entry>
  <entry>
    <title>对偶</title>
    <url>/2021/03/11/%E5%AF%B9%E5%81%B6/</url>
    <content><![CDATA[<br>


<ul>
<li>对于凸形<br>结论1：凸形可行域只有1个峰，只要达到那个峰，我们就达到了最优，是全局最优。<br>结论2：至少有一个顶点是峰。</li>
</ul>
<a id="more"></a>
<ul>
<li><p>单纯形法：</p>
<ol>
<li>单纯形是什么？数学上可以写成一堆线性不等式限制出来的区域。</li>
<li>单纯形法，仅适用于求解线性规划，线性规划又是凸优化的一种。因为线性规划的定义域是单纯形，单纯形是凸的，即线性规划是定义域为凸、目标函数为线性的问题。</li>
<li>先找到一个顶点，然后从这个顶点，沿着某条边线，走到下一个顶点，直到最优。方向的选择可以有很多种，最多使用的是比较短视的方法：沿着最陡峭的那一条，追求当前步上升最快。</li>
<li>单纯形法寻找路线优化目标函数，直至达到一个峰，而该峰就是全局最优。</li>
</ol>
</li>
<li><p>Slater’s condition 根据wiki， </p>
<blockquote>
<p>Slater’s condition (or Slater condition) is a sufficient condition for strong duality to hold for a convex optimization problem, named after Morton L. Slater. Informally, Slater’s condition states that the <strong>feasible region must have an interior point</strong>.<br>即在对偶问题中gap为0要满足的条件，即可行域中必须有内点的条件。</p>
</blockquote>
</li>
<li><p>线性规划的对偶理论没出现的时候，线性规划是不知道能不能解的。也就是说，对偶理论能够证明一个线性规划问题<strong>不</strong>存在解。思路是找到一个跟原问题的对偶问题密切相关的问题，如果这个问题有解，原问题就没解。</p>
</li>
<li><p><strong>那么证明便归为两个主要部分，1 如何转化为对偶问题 2 为什么两个问题的解相关？</strong></p>
</li>
<li><p>首先[问题要满足是凸优化]。对于凸优化来说，在满足constraint qualifications(如上文的slater condition为其中一种，满足该条件，这里涉及到仿射函数即可表示为f=A*w+b 。仿射函数其实就是线性变换liner。)情况下，gap=0，为强对偶。</p>
</li>
<li><p>其次[在求解凸优化时引入乘子以及最优解需要满足的条件]。在凸优化中的非线性优化问题下，该问题满足一些constraint qualifications，当存在不等式约束时(只有等式约束时，即拉格朗日function求偏导(也就是KKT turns into the Lagrange conditions))，我们用KKT引进 <a href="https://en.wikipedia.org/wiki/Lagrange_multipliers" title="Lagrange multipliers">Lagrange multipliers</a>，这些乘子需要满足KKT 的四个条件。注意到这里的目标函数与约束函数一定是<a href="https://en.wikipedia.org/wiki/Smooth_function" title="Smooth function">continuously differentiable</a> at a point x(local optimum点)，如果functions are non-differentiable,<a href="https://en.wikipedia.org/wiki/Subderivative" title="Subderivative">subdifferential</a><br>versions of Karush–Kuhn–Tucker (KKT) conditions are available.</p>
</li>
<li><p>对偶问题， 这里代表Lagrangian dual problem，还有其他对偶问题 <a href="https://en.wikipedia.org/wiki/Wolfe_dual_problem" title="Wolfe dual problem">Wolfe dual problem</a> and the <a href="https://en.wikipedia.org/wiki/Fenchel%27s_duality_theorem" title="Fenchel&#39;s duality theorem">Fenchel dual problem</a>。</p>
</li>
<li><p>Lagrangian dual problem 需要先形成一个L函数，这个原问题的解是，</p>
</li>
</ul>
<ul>
<li>todo</li>
</ul>
<ul>
<li> 用数学表达：</li>
</ul>
<p>凸优化问题：</p>
<p><img src="http://upload-images.jianshu.io/upload_images/8716089-0c145b1194ca5146.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="standard form for convex minimization problem.jpg"></p>
<p>reference:<br>[1]<a href="https://cowles.yale.edu/sites/default/files/files/pub/d00/d0080.pdf">https://cowles.yale.edu/sites/default/files/files/pub/d00/d0080.pdf</a><br>[2]<a href="https://en.wikipedia.org/wiki/Convex_optimization">https://en.wikipedia.org/wiki/Convex_optimization</a></p>
]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>庄家</title>
    <url>/2021/02/22/%E5%BA%84%E5%AE%B6/</url>
    <content><![CDATA[<br>
<br>

<p>Q1：庄家坐庄步骤？<br>1吸货 2拉升 3洗盘 4出货✅<br>1吸货 2洗盘 3拉升 4出货❎</p>
<a id="more"></a>
<p>需要先拉升，在于底部吸货不足，卖家少。<br>拉升2倍左右，开始洗盘，洗盘过程中获利盘出货，给庄家吸货机会。这同时也抬高了吸货成本。<br>洗盘时间视情况而定，有时一个月左右。</p>
<p>Q2：庄家吸货方法？<br>跌停板吸货 （亿安科技）<br>熊市顺势低吸（底部但是爆量）<br>抬升吸货 （洗盘但是无量）</p>
<p>Q3：洗盘？<br>洗盘的目的：洗掉大户和集中的持股人。避免在高位卖出砸盘。<br>大户：几万、几十万都不是大户，几百万、上千万股的”人“。这样的人，属于对手。（主力和老庄家(被套的)–对手）</p>
<p>Q4：主力和庄家？</p>
<p>Q5：出货？<br>拉高出货，以变现锁定的获利。<br>成本区在之前的拉升和吸货之间的位置。<br>填权再拉。<br>然后高位震荡也能出货。<br>之前的拉升，净吃入。拉高出货不能吃，要卖。拉两三天，做个平台，拉两三天再做个平台，别人就会认为每次到平台就突破，就会买入。如果大盘面差，要跑的时候，向下钓鱼出货法–开始砸、跌停板打下来，然后巨大买盘，买盘巨大，不停再往上推，就会有买盘跟进，卖盘都是庄的，择机再砸掉买盘，又往上推，再砸，再推。1天可以卖掉好几千万资金。利用追涨杀跌。</p>
<p>Q6：大波段操作<br>胆大心细。有胆量入场，指定止损–买入后预计涨结果跌了、或者预计强势结果未强势–&gt;改错择机出来。<br>买错即卖。<br>国家政策–&gt;板块和强势股(股票强度、涨停板)–&gt;龙头、二三龙头、补涨股等<br>–&gt;F10基本面符合–&gt;看技术面，平台突破点找买点</p>
<p>Q7：二龙头补涨<br>二龙头的突破(某一天放量、十几分钟拉了3%-5%、分时线k线高于原来的平台)时加仓。补涨等不到回调机会。<br>卖出点只和技术面有关。<br>跌破五日线，先卖1/3。五日线十日线高位死叉卖1/3。死叉后又跌则全出。</p>
<br>
<br>

<div align="center">    
<img src="/2021/02/22/%E5%BA%84%E5%AE%B6/yakj.png" width="700" height="500" alt="亿安科技" align="center">
</div>

]]></content>
      <categories>
        <category>股市理论</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>股市理论</tag>
      </tags>
  </entry>
  <entry>
    <title>微信的GraphTR模型</title>
    <url>/2021/03/08/%E5%BE%AE%E4%BF%A1%E7%9A%84GraphTR%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h4 id="提出背景"><a href="#提出背景" class="headerlink" title="提出背景"></a>提出背景</h4><p>“迁移学习+多任务”的场景<br>通过将不同领域的节点、关系都建模在一幅图中，通过图卷积，完成知识从数据丰富的领域向数据稀疏领域的迁移，并兼顾两个领域的指标。</p>
<a id="more"></a>

<p>多 域信息的异构图上完成图卷积，每个节点要聚合来自多个领域的异构消息。之前传统的聚合方式，如mean/max pooling，矩阵相乘，可能带来异构消息相互抵销而引入信息损失。</p>
<p>为此微信团队采用了GraphSAGE+FM+Transformer多种手段，从不同粒度来交叉、聚合消息，极大提升了模型的表示能力，这种新的消息聚合方式值得借鉴。</p>
<h4 id="场景及难点"><a href="#场景及难点" class="headerlink" title="场景及难点"></a>场景及难点</h4><p>1、微信团队面临的场景是：</p>
<p>每个视频都打有若干tag（人工标注或由内容理解算法打上的）<br>用户观看视频时，需要有算法从这个视频自带的tag中挑选出与当前用户最相关的若干个tag，展示在视频的下方。<br>用户点击某个tag，会进入一个沉浸式频道，其中展现的全部是与该tag相关的视频</p>
<p>2、难点在于：用户点击视频的行为比较丰富，但是用户点击tag的行为比较稀疏，训练数据不足。</p>
<h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p>方案一：<br>训练一个模型，输入视频的多模态信息(标题、封面图、关键帧)，输出是与这个视频最match的tag。训练时，拿人工打标的结果作为label。线上serving时，将预测出来的top-K个标签，展示在视频的下方。</p>
<p>这个方案可行，但是其只利用了视频的静态属性，没有用户的信息，所以推荐出来的tag只有与视频在语义上的相关性，完全没有针对当前用户的个性化，不满足业务需求。</p>
<p>方案二：<br>1、tag embedding用tag的word embedding。<br>2、用户的embedding是其过去有过”正交互”的tag embedding的pooling<br>所谓“正交互”，可以是用户过去一段时间内点击过的tag<br>但是考虑到user-tag的交互太稀疏，因此可以选用户过去点击过视频所携带的tag<br>pooling时，也可以考虑进播放完成度、时间衰减等因素，进行加权平均。<br>3、线上serving时，拿user embedding在当前视频所携带的tag embedding中寻找Top-K近邻，展示在视频下方。</p>
<p>怎么评价这一方案：</p>
<p>1、该方案，考虑了用户的历史，有更强的个性化。<br>2、但是拿word embedding做tag embedding，仍然只考虑了tag的语义信息。用户行为蕴含的信息，要比语义信息更加重要。<br>3、用户与tag的交互行为太少了，很难在“用户点击tag的序列”上套用word2vec来学习到tag embedding</p>
<p>方案三：微信的GraphTR模型</p>
<hr>
<h4 id="优化点"><a href="#优化点" class="headerlink" title="优化点"></a>优化点</h4><p>GraphTR是为了要<em>学习优质tag embedding</em>，为此要注重利用用户的行为信息<br>但是由于user-tag的行为太稀疏，因此GraphTR需要<em>通过user-video的行为学习到tag embedding</em><br>要达成以上目标，也有多种作法。而GraphTR的做法是：</p>
<p>1、将user, video, tag（还加上video的来源media）都放入一个大的异构图<br>通过图卷积，学习到video embedding</p>
<p>2、再建模video与video之间的相关性（比如在同一个session中播放过）</p>
<p>3、因为video embedding融合了tag embedding，因此在优化目标达成之后，一个优质的副产品就是得到tag embedding</p>
<h4 id="GraphTR是如何构建这个异构图的？"><a href="#GraphTR是如何构建这个异构图的？" class="headerlink" title="GraphTR是如何构建这个异构图的？"></a>GraphTR是如何构建这个异构图的？</h4><p>1、node：</p>
<p>图上要包括：user, video, tag, media (视频来源)这 4类节点。<br>因为用户数目太多，而每个用户的行为相对稀疏，GraphTR将用户按照gender-age-location分成84000组，用user group替代user，在图中建模。</p>
<p>2、edge：<br>video-video：同属一个观看session中的两video之间有边<br>user-video：某视频被某user group一周观看超过3次<br>video-tag：video和其携带的tag<br>video-media：video和其来源<br>tag-tag：两个 tag属于同一个视频</p>
<h4 id="如何传递、融合图上异构节点的信息？"><a href="#如何传递、融合图上异构节点的信息？" class="headerlink" title="如何传递、融合图上异构节点的信息？"></a>如何传递、融合图上异构节点的信息？</h4><p>1、为了完成user, video, tag, media这四类节点的信息融合，GraphTR设计了3层卷积结构，称为Heterogeneous field interaction network (HFIN)。</p>
<p>2、最底层Heterogeneous Feature Layer：<br>3-hop的embdding是lookup获得的，分别有四个域(user/video/tag/media域的特征)，相加得到2-hop邻居的embedding。</p>
<p>3、中间层：Multi-field Interaction Layer：<br>这一层的任务是由2-hop邻居的embedding，聚合生成1-hop邻居的embedding。<br>而HFIN采用了GraphSAGE+FM+Transformer三种方式，粒度上从由粗到细，完成聚合。</p>
<h4 id="三种聚合方式"><a href="#三种聚合方式" class="headerlink" title="三种聚合方式"></a>三种聚合方式</h4><p>1、GraphSAGE聚合<br>graphsage聚合<br><img src="/2021/03/08/%E5%BE%AE%E4%BF%A1%E7%9A%84GraphTR%E6%A8%A1%E5%9E%8B/graphsage聚合.png" width="60%" height="370"></p>
<p>这里的hGraph就是1-hop的最终embding。</p>
<p>2、FM 聚合<br>FM聚合，区分各域，因此粒度更细一些。<br><img src="/2021/03/08/%E5%BE%AE%E4%BF%A1%E7%9A%84GraphTR%E6%A8%A1%E5%9E%8B/fm聚合.png" width="60%" height="300"></p>
<p>hFM2就是1-hop的最终embding。</p>
<p>3、Multi-field transformer aggregator</p>
<p>GraphTR觉得FM聚合时，各域节点（即各域特征）交叉得还不够：1:FM聚合，只有在第2步才做域与域之间的交叉。2:在一个域内部，这n+1个特征之间，只有简单pooling，不存在交叉。3:FM聚合的第1步，每个域average pooling的是，这1+n个节点的原始特征。</p>
<p>Transformer聚合，希望增强各域节点（即各域特征）的交叉。步骤如下：</p>
<p>S1:Transformer决定在第1步引入交叉。具体方式就是，在一个域的1+n个节点之间进行Transformer变换，重新生成1+n个向量，每个新向量是老向量的加权平均，权重是当前老向量相对于其他老向量的attention score。(一套attention恐怕没有代表性，还引入多头机制)</p>
<img src="/2021/03/08/%E5%BE%AE%E4%BF%A1%E7%9A%84GraphTR%E6%A8%A1%E5%9E%8B/transformer聚合.png" width="60%" height="500">

<p>S2:再拿生成的1+n个新向量，做average pooling。</p>
<p>S3:最后将“域间交叉结果”与”域内交叉结果”拼接在一起返回，作为由Transformer聚合得到的1-hop邻居的embedding。论文的实验结果证明，这个最复杂、最细粒度的聚合，对于模型性能的提升也最大。</p>
<p>4、通过三种聚合方式，我们就可以得到1-hop邻居的最终embedding，是这三种聚合结果的concat。</p>
<p>5、最上层：The Second Aggregation Layer<br>这一层负责由1-hop邻居节点（1个target node自身，m个邻居节点，一共1+m个）的embedding(下边公式中的矩阵H)，生成target node上的embedding。聚合方式也是基于Transformer的。</p>
<p>根据1+m个原向量，生成1+m个新向量，每个新向量是所有老向量的加权平均，权重是当前原向量与其他原向量的attention score<br>再拿这1+m个新向量，取平均，得到target node上的最终向量表示。</p>
<h4 id="如何定义loss"><a href="#如何定义loss" class="headerlink" title="如何定义loss?"></a>如何定义loss?</h4><p>通过以上三层卷积，就能够给图上所有类型的所有节点，都产生一个embedding。接下来的问题就是，如何定义优化目标，使这些节点的embedding得到优化？</p>
<p>这一部分的解决方案比较常规，无非就是建模节点之间的相关性，可以有选择是:</p>
<p>建模user-tag之间的相关性，user与点击过的tag之间的距离要尽可能小。但是user-tag之间交互的数据太少；建模user-video之间的相关性，user与点击过的视频之间，距离应该较近。但是图上建模的不是单个user而是user group，一个user group包含的用户兴趣太复杂，拿user-goup与video训练，可能噪声比较大；建模video-video之间的相关性，在同一个session被观看的视频之间，距离要尽可能小。因为video的点击行为比较多，这方面的数据比较丰富，文中采用的是这种方案。</p>
<img src="/2021/03/08/%E5%BE%AE%E4%BF%A1%E7%9A%84GraphTR%E6%A8%A1%E5%9E%8B/loss.png" width="60%" height="250">

<h4 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h4><p>将这些tag emedding代入上文的”第二个方案”，即拿用户观看过视频携带的tag的embedding加权平均得到user embedding，再拿这个user embedding在当前视频所携带的tag的embedding中寻找出距离最近的top-k个tag，作为推荐结果显示在视频的下方。因为这些tag embedding蕴含了丰富的user-video行为信息，不仅有助于提升用户对tag的点击率，也有助于提升进入沉浸式tag频道后的观看时长。</p>
<h4 id="借鉴"><a href="#借鉴" class="headerlink" title="借鉴"></a>借鉴</h4><p>1、数据少的领域如何借力于数据多的领域，同时要兼顾两个领域的优化目标：<br>通过将不同领域的不同节点、关系建立在一张异构图上，通过图卷积，使得每个节点的embedding都浓缩了多个领域的知识，达成了“知识迁移+目标兼顾”。</p>
<p>2、GraphTR采用了GraphSAGE+FM+Transformer多种手段，粒度上从粗到细，交叉、聚合来自不同领域的异构消息，相比于mean/max pooling、浅层FC等传统聚合方式，极大提升了模型的表达能力。</p>
]]></content>
      <categories>
        <category>模型框架</category>
        <category>dl</category>
      </categories>
      <tags>
        <tag>dl</tag>
        <tag>模型框架</tag>
      </tags>
  </entry>
  <entry>
    <title>思想深度</title>
    <url>/2021/02/22/%E6%80%9D%E6%83%B3%E6%B7%B1%E5%BA%A6/</url>
    <content><![CDATA[<br>
<br>

<h4 id="观点"><a href="#观点" class="headerlink" title="观点"></a>观点</h4><ul>
<li><p>计划经济是狂妄、愚蠢。</p>
<a id="more"></a></li>
<li><p>小波动基本是没意义的，一个现象进入分析的视野，已经承认这现象不属于小的波动，这点是必须明确的。</p>
</li>
<li><p>有领涨的并不一定都能最终走出行情，即使是上涨的趋势，行情还可以分大、中、小。</p>
</li>
<li><p>一个股票中的常见现象，就是当前一段领涨个股和大盘走势相背离的时候，往往意味着一个结构性震荡的来临，这一点至少在股票中是通用的，而76年的改变其实也是很符合这一点的。 </p>
</li>
<li><p>汉奸，当然可以有很高的的艺术造诣。所谓坏人就不能有优点了？无所谓好坏吧。</p>
</li>
<li><p>真正的你又何曾生死，生死又与你何干？。而你的心究竟又是哪个心？</p>
</li>
<li><p>所有的现代战争，从根本意义上就是货币战争。</p>
</li>
<li><p>和庄股一样，目前的关键是不能让资本大量逃离，否则就会连续崩盘跳水。</p>
</li>
</ul>
<br>

<h4 id="民族复兴周期与世界经济周期历史性共振下的国家地缘与货币战略"><a href="#民族复兴周期与世界经济周期历史性共振下的国家地缘与货币战略" class="headerlink" title="民族复兴周期与世界经济周期历史性共振下的国家地缘与货币战略"></a>民族复兴周期与世界经济周期历史性共振下的国家地缘与货币战略</h4><p>框架：</p>
<p>1、从历史大现象规律出发，得到–&gt;当前为强盛时期。</p>
<p>2、由马克思的”五阶段论”，得到–&gt;列宁的社会主义本质是公有制，斯大林的社会主义是资本主义–因此苏东突变后权力或权力资本迅速转为资本主义(本来就同源)，毛泽东的文革，重点放在了人与人的关系而非人与自然，而不能真的实现反资。邓小平的中国特色社会主义和社会主义初级阶段策略同样也应该是一个民族主义的策略。</p>
<blockquote>
<p>社会中一部分人对另一部分人不再存在依附关系，而是全社会的人都毫不例外地依附于一个非自然的身外之物：资本，就叫做资本主义社会。<br>因此人与自然的关系被打破，不再依附自然。</p>
</blockquote>
<p>3、文革的必然失败–&gt;使得面对资本全球化成了无可逃避的现实</p>
<p>4、1得到中国处于强盛期 + 23得到世界资本全球化–&gt;机遇<br>为什么是力量在中国？：从霸业的人口上得到的。大不列颠王国以5000万，美国和苏联在2亿5千万，下一个12亿5千万。<br>时间推定：1929英德老的5千万级别主导循环结束；美苏90年的循环在一半1974年形成了石油危机的中型调整，美苏这两个不同类型的资本主义之间的同级别竞争以美国的胜利结束；然后到2000年美国出现高点，开始调整；2019年中国开始。</p>
<p>5、地缘战略：以环渤海湾地区、珠江三角洲地区、秦川地区建构大的战略三角，成为亚洲之王，其领土（或附庸性质的影响）应该从乌拉尔山往东直到大海与美洲对望，从北冰洋直到太平洋俯视澳洲，形成世界的中轴，让欧洲和美洲成为其两翼</p>
<p>6、货币：<br>最有竞争力的货币将是美元、欧元、卢比和人民币。<br>在目前阶段一定要坚持对美元采取一种不挂钩的挂钩政策，坚决长期地维持人民币对美元的币值稳定。<br>逐步扩大对亚洲区的影响，取代日元的地位，逐步成为实质亚洲货币。<br>利用第一个阶段形成的对美元的极大落差，配合世界经济大循环周期，选择时机释放，将美元在一次精心策划的战役中一次性击毁。最后在一个长期反复、拉锯的过程中，利用新的12亿5千万级别世界经济大循环周期确立中国对美国的领先地位。</p>
<p>7、分析美国：<br>美国操纵汇率–&gt;为了其总体利益服务的。<br>美国危机–&gt;泡沫化，0以下的储蓄率<br>2000年的下跌速度极快–&gt;大规模的资本逃离还没有出现<br>目前的大级别反弹–&gt;构成资本逃离的机会，一旦反弹到位，出现大资本逃离。<br>为了避免大资本逃离–&gt; 大反弹到位前把货币贬值到一个相应的地位，这样才使得美圆资本套现后不能以一个较高的汇率出逃</p>
<p>但，如果有一个容量极大的货币紧贴美圆，则美圆贬值的所有如意算盘将打不响，而人民币正好就是这种货币。人民币与美圆的挂钩使得美圆资产变现以后有了一个顺畅的逃跑渠道。</p>
<p>这也是以前帖子里面预测2019年90年大周期世界经济大危机的现实基础，正确的人民币战略将加快、加深这个进程。</p>
<hr>
<p>综上，</p>
<p>1、够有想象力，三角洲和攻击美元的策略也能想得出，而且还自圆其说<br>2、对社与资(列林斯大林)的理解，我闻所未闻<br>3、历史的宏观视角，让我有大历史之感，得到一些规律，证明论点<br>4、美国现象到本质的精辟概括</p>
<h4 id="我的观点"><a href="#我的观点" class="headerlink" title="我的观点"></a>我的观点</h4><p>1、出得了方案<br>2、给得了完备解释<br>3、理解深刻性或者说独到处，一语成谶<br>4、精辟</p>
<p>=&gt;想象力、知识沉淀、思考本质 =&gt;精辟且自洽</p>
]]></content>
      <categories>
        <category>历史</category>
        <category>金融经济</category>
      </categories>
      <tags>
        <tag>历史</tag>
      </tags>
  </entry>
  <entry>
    <title>提升方法</title>
    <url>/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<br>

<h4 id="bagging和boosting"><a href="#bagging和boosting" class="headerlink" title="bagging和boosting"></a>bagging和boosting</h4><p>1、区别？<br>采样：随机采样(Bootstrap sampling–有放回)、加大错误样本权重<br>特征的采样</p>
<a id="more"></a>
<p>并行计算上<br>弱学习器的权重</p>
<p>2、从偏差和方差的角度解释bagging和boosting的原理？<br>bagging：<br>重采样、权重也相同–模型的区别性不大，bias小。<br>但如果假设各个子模型独立，则显著降低variance。如果完全相同的子模型，则var和单个模型一样。bagging属于两者之间，一定程度降低了var。RF特征上随机选择，进一步降低了模型的相关性，从而进一步降低了var。</p>
<p>boosting:<br>前向分步学习算法，是sequencial地减少损失函数，loss是逐步地下降的，bias也随之逐步下降。但由于是这种sequence、adaptive地，模型相关性较高，不能显著减少var。</p>
<h4 id="结合策略"><a href="#结合策略" class="headerlink" title="结合策略"></a>结合策略</h4><p>1平均法；2投票法：多数投票、绝对多数投票、加权投票；3学习法。<br>学习法，代表方法是stacking。stacking是再加上一层学习器，我们将训练集弱学习器的学习结果作为输入，将训练集的输出作为输出，重新训练一个学习器来得到最终结果。</p>
<h4 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h4><p>1、Adaboost是模型为加法模型，学习算法为前向分步学习算法，损失函数为指数函数的分类问题。</p>
<p><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/%E5%8A%A0%E6%B3%95%E5%89%8D%E5%90%91.png" alt="加法前向"></p>
<p><strong>为什么loss是指数函数？证明如下：</strong></p>
<p>————————————————————————————————————————————————————————————<br><br><br><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/exp%E8%AF%81%E6%98%8E1.png" alt="exp证明1"><br><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/exp%E8%AF%81%E6%98%8E2.png" alt="exp证明2"><br><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/exp%E8%AF%81%E6%98%8E3.png" alt="exp证明3"></p>
<!-- <img src=exp证明1.png width=80% height=450>
<img src=exp证明2.png width=80% height=700>
<img src=exp证明3.png width=80% height=300> -->
<br>
——————————————————————————————————————————————————————————--

<p>2、分类器结合时的权重？<br>由于Adaboost中若干个分类器的关系是第N个分类器更可能分对第N-1个分类器没分对的数据，而不能保证以前分对的数据也能同时分对。所以在Adaboost中，每个弱分类器都有各自最关注的点，每个弱分类器都只关注整个数据集的中一部分数据，所以它们必然是共同组合在一起才能发挥出作用。所以最终投票表决时，需要根据弱分类器的权重来进行加权投票，权重大小是根据弱分类器的分类错误率计算得出的，总的规律就是弱分类器错误率越低，其权重就越高。</p>
<p>计算公式：</p>
<p>1 误差<br><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/%E8%AF%AF%E5%B7%AE.png" alt="误差"></p>
<!-- <img src=误差.png width=60% height=150>
 -->
<p>2 权重系数<br><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/%E5%BC%B1%E5%88%86%E7%B1%BB%E5%99%A8%E6%9D%83%E9%87%8D%E7%B3%BB%E6%95%B0.png" alt="弱分类器权重系数"></p>
<!-- <img src=弱分类器权重系数.png width=60% height=100> -->

<p>3 样本权重<br><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/%E6%A0%B7%E6%9C%AC%E6%9D%83%E9%87%8D.png" alt="样本权重"></p>
<!-- <img src=样本权重.png width=80% height=300> -->

<p>4 分类器结合及最终分类器<br><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/%E5%88%86%E7%B1%BB%E5%99%A8%E7%BB%93%E5%90%88.png" alt="分类器结合"></p>
<!-- <img src=分类器结合.png width=80% height=230> -->


<p>由上面的公式，可得到：<br>每次新增加一个弱分类器的时候，前面的弱分类器分错的样本的权重占总样本权重的0.5，前面弱分类器分对的样本等权重也占总样本权重的0.5。</p>
<p>3、正则化</p>
<p>fn = fn-1 + θ * a * G<br>θ 为正则化项</p>
<p>4、评价</p>
<p>可解释性<br>参数个数<br>performance<br>异常点敏感<br>弱分类器选择<br>可用于特征选择</p>
<h4 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h4><p>1、区别于adaboost</p>
<p>Adaboost是通过提高错分样本的权重来定位模型的不足，GBDT是通过负梯度来定位模型的不足，因此GBDT可以使用更多种类的损失函数。由于loss可以选择更鲁棒的，对于adaboost存在异常点敏感的问题,gbdt更健壮。</p>
<p>可以灵活处理离散和连续值。</p>
<p>分类的GBDT：是用指数损失函数，此时GBDT退化为Adaboost算法。<br>另一种方法是用类似于逻辑回归的对数似然损失函数的方法。</p>
<p>使用了前向分布算法，但是弱学习器限定了只能使用CART回归树模型，同时迭代思路和Adaboost也有所不同。有很多人对GBDT算法进行了开源代码的开发，比较火的是陈天奇的XGBoost和微软的LightGBM。</p>
<p>2、为什么只能分类树</p>
<p>GBDT的核心在于累加所有树的结果作为最终结果，而分类树的结果显然是没办法累加的，所以GBDT中的树都是回归树，不是分类树。</p>
<p>3、损失函数有哪些？</p>
<p>1指数损失；2对数损失；3均方差(如果我们选择平方损失函数，那么这个差值其实就是我们平常所说的残差。)；4绝对损失；5Huber损失(它是均方差和绝对损失的折衷产物，对于远离中心的异常点，采用绝对损失，而中心附近的点采用均方差。这个界限一般用分位数点度量。)；6分位数损失。56主要用于健壮回归，也就是减少异常点对损失函数的影响。</p>
<p>4、例子</p>
<p><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/gbdt%E4%BE%8B%E5%AD%90.png" alt="gbdt例子"></p>
<p>5、SGBDT</p>
<p>子采样比例（subsample）。取值为(0,1]。注意这里的子采样和随机森林不一样，随机森林使用的是放回抽样，而这里是不放回抽样。如果取值为1，则全部样本都使用，等于没有使用子采样。如果取值小于1，则只有一部分样本会去做GBDT的决策树拟合。选择小于1的比例可以减少方差，即防止过拟合，但是会增加样本拟合的偏差，因此取值不能太低。推荐在[0.5, 0.8]之间。使用了子采样的GBDT有时也称作随机梯度提升树(Stochastic Gradient Boosting Tree, SGBT)。由于使用了子采样，程序可以通过采样分发到不同的任务去做boosting的迭代过程，最后形成新树，从而减少弱学习器难以并行学习的弱点。</p>
<p>6、构造特征输入LR<br>如果我们想让逻辑回归处理非线性的数据，其中一种方式便是组合不同特征，增强逻辑回归对非线性分布的拟合能力。Facebook 在2014年 发表的一篇论文便是这种尝试下的产物，利用gbdt去产生有效的特征组合，以便用于逻辑回归的训练，提升模型最终的效果。如我们 使用 GBDT 生成了两棵树，两颗树一共有五个叶子节点。我们将样本 X 输入到两颗树当中去，样本X 落在了第一棵树的第二个叶子节点，第二颗树的第一个叶子节点，于是我们便可以依次构建一个五纬的特征向量，每一个纬度代表了一个叶子节点，样本落在这个叶子节点上面的话那么值为1，没有落在该叶子节点的话，那么值为 0。于是对于该样本，我们可以得到一个向量[0,1,0,1,0] 作为该样本的组合特征，和原来的特征一起输入到逻辑回归当中进行训练。实验证明这样会得到比较显著的效果提升。</p>
<p>7、CART分类树过程<br><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/cart%E5%88%86%E7%B1%BB%E8%BF%87%E7%A8%8B.png" alt="cart分类过程"></p>
<p>8、相比于传统的LR，SVM效果为什么好一些</p>
<ul>
<li><p>GBDT基于树模型，继承了树模型的优点 [对异常点鲁棒、不相关的特征干扰性低（LR需要加正则）、可以很好地处理缺失值、受噪音的干扰小]</p>
</li>
<li><p>处理 missing feature</p>
</li>
<li><p>数据规模影响不大，因为我们对弱分类器的要求不高，作为弱分类器的决策树的深 度一般设的比较小，即使是大数据量，也可以方便处理。像 SVM 这种数据规模大的时候训练会比较麻烦。</p>
</li>
<li><p> 通常在给定的不带噪音的问题上，他能达到的最佳分类效果还是不如 SVM，逻辑回归之类的。<br>实际问题中，往往有很大的噪音，使得 Decision Tree 这个弱势就不那么明显了。</p>
</li>
</ul>
<p>9、加速训练？<br>是否预排序,预排序可以加速查找最佳分裂点（不确定）.在样本规模上的并行计算。</p>
<p>10、参数</p>
<ul>
<li><p>第一类Miscellaneous Parameters </p>
</li>
<li><p>第二类：Boosting Parameters:<br>n_estimators 最大弱学习器的个数，太小欠拟合，太大过拟合<br>learning_rate 学习率，太大过拟合，一般很小0.1，和n_estimators一起调<br>subsample 子采样，防止过拟合，太小欠拟合。GBDT中是不放回采样</p>
</li>
<li><p>第三类：Tree-Specific Parameters<br>max_features 最大特征数<br>max_depth 最大树深，太大过拟合<br>min_samples_split 内部节点再划分所需最小样本数，越大越防过拟合<br>min_weight_fraction_leaf 叶子节点最小的样本权重和。如果存在较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。越大越防过拟合<br>max_leaf_nodes:最大叶子节点数 ，太大过拟合<br>min_impurity_split:节点划分最小不纯度<br>presort:是否对数据进行预分类，以加快拟合中最佳分裂点的发现。默认False。非稀疏数据则预排序，若稀疏数据则不预排序。小规模数据预排序。</p>
</li>
</ul>
<p>11、调参思路</p>
<p>1、首先使用默认的参数，进行数据拟合；<br>2、从步长(learning rate)和迭代次数(n_estimators)入手；一般来说,开始选择一个较小的步长来网格搜索最好的迭代次数。这里，可以将步长初始值设置为0.1。对于迭代次数进行网格搜索；<br>3、接下来对决策树的参数进行寻优<br>4、首先我们对决策树最大深度max_depth和内部节点再划分所需最小样本数min_samples_split进行网格搜索。【min_samples_split暂时不能一起定下来，因为这个还和决策树其他的参数存在关联】<br>5、接着再对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参；做到这里，min_samples_split要做两次网格寻优，一次是树的最大深度max_depth，一次是叶子节点最少样本数min_samples_leaf。<br>【具体观察min_samples_split的值是否落在边界上，如果是可以进一步寻优】<br>6、继续对最大特征数max_features进行网格搜索。做完这一步可以看看寻找出的最优参数组合给出的分类器的效果。<br>7、可以进一步考虑对子采样的比例进行网格搜索，得到subsample的寻优参数<br>8、回归到第2步调整设定的步长(learning rate)和迭代次数(n_estimators)，注意两者的乘积保持不变，这里可以分析得到：通过减小步长可以提高泛化能力，但是步长设定过小，也会导致拟合效果反而变差，也就是说，步长不能设置的过小。</p>
<hr>
<p>mind:</p>
<p><img src="/2021/02/21/%E6%8F%90%E5%8D%87%E6%96%B9%E6%B3%95/%E6%8F%90%E5%8D%87.png" alt="提升"></p>
]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度</title>
    <url>/2021/02/04/%E6%A2%AF%E5%BA%A6/</url>
    <content><![CDATA[<h2 id="梯度消失和爆炸"><a href="#梯度消失和爆炸" class="headerlink" title="梯度消失和爆炸"></a>梯度消失和爆炸</h2><ul>
<li><p>deep后带来的信息传递/梯度传递问题</p>
<ul>
<li><p>层数过多导致？sigmoid和tanh为什么会导致梯度消失？</p>
<ol>
<li>直观解释：从深层网络角度来讲，不同的层学习的速度差异很大，表现为网络中靠近输出的层学习的情况很好，靠近输入的层学习的很慢，有时甚至训练了很久，前几层的权值和刚开始随机初始化的值差不多。</li>
<li>反向传播角度解释：由于反向传播过程中，前面网络权重的偏导数的计算是逐渐从后往前累乘的，如果使用激活函数如sigmoid，导数小于一，因此累乘会逐渐变小，导致梯度消失，前面的网络层权重更新变慢；如果权重 本身比较大，累乘会导致前面网络的参数偏导数变大，产生数值上溢。<br>    </li>
</ol>
</li>
<li><p>梯度消失</p>
<ol>
<li>原因：层数过多，学习率的大小，网络参数的初始化，激活函数的边缘效应</li>
<li>在深层神经网络中，每一个神经元计算得到的梯度都会传递给前一层，较浅层的神经元接收到的梯度受到之前所有层梯度的影响。如果计算得到的梯度值非常小，随着层数增多，求出的梯度更新信息将会以指数形式衰减，就会发生梯度消失。<br>
<a id="more"></a></li>
</ol>
</li>
<li><p>梯度爆炸</p>
<ol>
<li>原因：1）隐藏层的层数过多；2）<strong>权重的初始化值过大</strong></li>
<li>在深度网络或循环神经网络（Recurrent Neural Network, RNN）等网络结构中，梯度可在网络更新的过程中不断累积，变成非常大的梯度，导致网络权重值的大幅更新，使得网络不稳定；在极端情况下，权重值甚至会溢出，变为$NaN$值，再也无法更新。</li>
<li>解决：1）用ReLU、Leaky-ReLU、P-ReLU、R-ReLU、Maxout等替代sigmoid函数。（2）用Batch Normalization。（3）<strong>LSTM的结构设计也可以改善RNN中的梯度消失问题。</strong>（4）进行梯度裁剪(clip), 如果梯度值大于某个阈值，我们就进行梯度裁剪，限制在一个范围内.（5）使用正则化，这样会限制参数 的大小，从而防止梯度爆炸。（6）设计网络层数更少的网络进行模型训练</li>
</ol>
</li>
</ul>
</li>
</ul>
<h4 id="LSTM为什么有助于解决梯度消失和爆炸问题？"><a href="#LSTM为什么有助于解决梯度消失和爆炸问题？" class="headerlink" title="LSTM为什么有助于解决梯度消失和爆炸问题？"></a>LSTM为什么有助于解决梯度消失和爆炸问题？</h4><p><a href="https://www.zhihu.com/question/34878706">https://www.zhihu.com/question/34878706</a></p>
<p>RNN 中总的梯度是不会消失的。即便梯度越传越弱，那也只是远距离的梯度消失，由于近距离的梯度不会消失，所有梯度之和便不会消失。RNN 所谓梯度消失的真正含义是，梯度被近距离梯度主导，导致模型难以学到远距离的依赖关系。</p>
<p>其一是遗忘门接近 1（例如模型初始化时会把 forget bias 设置成较大的正数，让遗忘门饱和），这时候远距离梯度不消失；其二是遗忘门接近 0，但这时模型是故意阻断梯度流的，这不是 bug 而是 feature（例如情感分析任务中有一条样本 “A，但是 B”，模型读到“但是”后选择把遗忘门设置成 0，遗忘掉内容 A，这是合理的）。当然，常常也存在 f 介于 [0, 1] 之间的情况，在这种情况下只能说 LSTM 改善（而非解决）了梯度消失的状况。</p>
]]></content>
      <categories>
        <category>dl</category>
      </categories>
      <tags>
        <tag>dl</tag>
      </tags>
  </entry>
  <entry>
    <title>统计角度看ml</title>
    <url>/2021/03/11/%E7%BB%9F%E8%AE%A1%E8%A7%92%E5%BA%A6%E7%9C%8Bml/</url>
    <content><![CDATA[<p>一些思考，不太严谨，从整体上看模型的思路，进行比较。</p>
<p>极大似然？就是后验、大量样本的整体出现概率值最大。样本之间独立。可应用乘法原理。</p>
<p>条件概率，即某(些)条件下某(些)事件出现的概率。</p>
<p>决策树则是求其极大值，局部选择当前条件概率最大。条件概率越大，不确定性越低，条件熵越小。整体熵未必减小。考虑整体熵值的是最大熵模型和logistics模型。logistics是可以通过假设先验概率，转化为这样的问题：推导出满足极大似然极值而得到的w参数。都可以通过拉格朗日将问题转化为无约束求极值，偏导为0，算法里有迭代尺度、梯度下降、牛顿插值。牛顿插值迭代收敛快些。</p>
<p>特征选择无论是熵、增益(比)还是基尼系数都体现出不确定性的思想。增益大则说明特征对结果的影响力大，因为说明条件熵越小，即条件概率越大，该条件下不确定性越低。增益或比越大，而基尼越小越好。因为前者都有-号，类似相反数的关系。本质还条件概率的问题。</p>
<p>决策生成树可以用动归提高算法效率。</p>
<p>感知器从loss func出发，求最小。距离如何定义还要看具体应用场景。主要算法里有<a href="https://blog.csdn.net/greenyang5277/article/details/104270803">Gram矩阵</a>，对偶算法。</p>
<p>k邻很简单，经验风险最小，就是多数为胜，即最简单的频率派概率最大思路，k不一样结果可能瞬间不同了，参数也少。</p>
<p>朴素贝叶斯主要是独立性假设，在类确定下特征条件独立，才能将公式分子简化，否则不那么容易求最大值，后验概率最大，还是极大似然思路，后验概率这是可用简单的乘法原理表达。如果有0，这里提出可以平滑的思想。</p>
<p>无论是熵、条件熵、基尼系数，还是贝叶斯、条件概率，还是感知器的loss func，还是c4.5里的loss(在剪枝时通过熵建立的loss，加入了模型复杂度因子，通过比较剪枝前后大小来判断是否剪枝)，还是logistics(初始分布进行求对数几率，求极大似然最大的参数)、最大熵(公式也化为求极大似然最大)两个对数线性模型的经验分布推导出来的无约束最优化公式，都是对初始概率进行包装，要么转为极大似然问题或者说转为条件概率问题，要么转为loss最小问题。概率问题则为监督学习中的两种，生成和判别。非概率则自定义的一些代数loss。</p>
<p>对给定输入判别输出，判别要么是f(x),要么是P(Y|X)。前者会出现loss func，定义距离如感知器、LDA，后者则决策树、k邻、贝叶斯、GMM。对数线性模型也是P(Y|X)概率分布公式表达的分类模型。都可以说是在对这两种函数求最优的问题。但如决策树、k邻，没有什么公式，也就没有什么参数需要调整，大多重点在算法，如决策树里主要是三个算法里剪枝过程应用到熵之类问题，而kmeans主要kd树解决高维搜索问题。理论框架虽然可以和统计通过加条件等方式相关联，但是更多是另一种思路。</p>
<p>生成模型，由学习数据得到原始分布，再来求P(Y|X)，如贝叶斯。判别模型，学习数据不从分布入手，而直接对条件概率进行假设，如LR。</p>
<p>具体细节，如收敛性证明，拉格朗日转化，最大熵的约束公式，包括泛化误差利用切比雪夫求上界的前提条件，感知器中正负，logistics里对数几率特征空间是n+1维，都需落在数学上去一步步转化推证。</p>
]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>编辑距离</title>
    <url>/2021/03/11/%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/</url>
    <content><![CDATA[<br>
<br>


<h2 id="编辑距离"><a href="#编辑距离" class="headerlink" title="编辑距离"></a>编辑距离</h2><a id="more"></a>

<br>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static int editDist(String str1 , String str2 , int m ,int n)&#123;</span><br><span class="line"></span><br><span class="line">    if (str1.charAt(m-1) &#x3D;&#x3D; str2.charAt(n-1))</span><br><span class="line">        return editDist(str1, str2, m-1, n-1);</span><br><span class="line"></span><br><span class="line">    return 1 + min ( editDist(str1,  str2, m, n-1),    &#x2F;&#x2F; Insert</span><br><span class="line">                     editDist(str1,  str2, m-1, n),   &#x2F;&#x2F; Remove</span><br><span class="line">                     editDist(str1,  str2, m-1, n-1) &#x2F;&#x2F; Replace                     </span><br><span class="line">                   ); &#x2F;&#x2F;三个子问题</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;s: beforeediting,length&#x3D;n  t: afterediting,length&#x3D;m</span><br><span class="line">&#x2F;&#x2F;d: recording the distance</span><br><span class="line">        d &#x3D; new int[n + 1][m + 1];  </span><br><span class="line">              </span><br><span class="line">        for (i &#x3D; 0; i &lt;&#x3D; n; i++) &#123;  </span><br><span class="line">            d[i][0] &#x3D; i;  </span><br><span class="line">        &#125;  </span><br><span class="line">        for (j &#x3D; 0; j &lt;&#x3D; m; j++) &#123;  </span><br><span class="line">            d[0][j] &#x3D; j;  </span><br><span class="line">        &#125;  </span><br><span class="line">          </span><br><span class="line">         </span><br><span class="line">        for (i &#x3D; 1; i &lt;&#x3D; n; i++) &#123;  </span><br><span class="line">            s_i &#x3D; s.charAt(i - 1);  </span><br><span class="line">              </span><br><span class="line">            for (j &#x3D; 1; j &lt;&#x3D; m; j++) &#123;  </span><br><span class="line">                t_j &#x3D; t.charAt(j - 1);  </span><br><span class="line">                 </span><br><span class="line">                cost &#x3D; (s_i &#x3D;&#x3D; t_j) ? 0 : 1;  </span><br><span class="line">                 </span><br><span class="line">                d[i][j] &#x3D; min(d[i - 1][j] + 1, d[i][j - 1] + 1,  </span><br><span class="line">                        d[i - 1][j - 1] + cost);  </span><br><span class="line">            &#125;  </span><br><span class="line">        &#125;  </span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if x &#x3D;&#x3D; y, then d[i][j] &#x3D;&#x3D; d[i-1][j-1]</span><br><span class="line">if x !&#x3D; y, 插入y则 d[i][j] &#x3D; d[i][j-1] + 1</span><br><span class="line">if x !&#x3D; y, 删除x则 d[i][j] &#x3D; d[i-1][j] + 1</span><br><span class="line">if x !&#x3D; y, x改变为y则 d[i][j] &#x3D; d[i-1][j-1] + 1</span><br><span class="line">When x!&#x3D;y, d[i][j] 取三中编辑方式最小代价。</span><br><span class="line">初始化条件 ： d[i][0] &#x3D; i, d[0][j] &#x3D; j</span><br></pre></td></tr></table></figure>
<ul>
<li><p>为什么不同操作就是对应与d的左移上移或左上移？<br>这个问题递归角度较易理解。<br>DP角度，d记录的是目前最小编辑距离。左、上、左上为子问题，即儿子。若为插入，则j需+1得到t的下一个字符，而x继续与此字符比较，i不变。</p>
</li>
<li><p>由递归到DP，实质就是找到递归中子问题。<br>找到后，将子问题结果记录在数组即可。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>贝叶斯网络</title>
    <url>/2021/03/13/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<br>

<h2 id="概率图"><a href="#概率图" class="headerlink" title="概率图"></a>概率图</h2><ul>
<li><p>概率图模型分为贝叶斯网络（Bayesian Network）和马尔可夫网络（Markov Network）两大类。</p>
<a id="more"></a></li>
<li><p>贝叶斯网络可以用一个有向图结构表示，马尔可夫网络可以表示成一个无向图的网络结构。</p>
</li>
<li><p>更详细地说，概率图模型包括了朴素贝叶斯模型、最大熵模型、隐马尔可夫模型、条件随机场、主题模型等，在机器学习的诸多场景中都有着广泛的应用。</p>
</li>
</ul>
<h2 id="频率派与贝叶斯派"><a href="#频率派与贝叶斯派" class="headerlink" title="频率派与贝叶斯派"></a>频率派与贝叶斯派</h2><p>频率派与贝叶斯派各自不同的思考方式：</p>
<p>频率派把需要推断的参数θ看做是固定的未知常数，即概率虽然是未知的，但最起码是确定的一个值，同时，样本X 是随机的，所以频率派重点研究样本空间，大部分的概率计算都是针对样本X 的分布；</p>
<p>而贝叶斯派的观点则截然相反，他们认为参数是随机变量，而样本X 是固定的，由于样本是固定的，所以他们重点研究的是参数的分布。</p>
<p>贝叶斯派既然把概率看做是一个随机变量，所以要计算概率的分布，便得事先知道的无条件分布，即在有样本之前（或观察到X之前），有着怎样的分布呢？这种在实验之前定下的属于基本前提性质的分布称为先验分布，或着无条件分布。</p>
<p>其中，先验信息一般来源于经验跟历史资料。而后验分布π（θ|X）一般也认为是在给定样本X的情况下的θ条件分布，而使π（θ|X）达到最大的值，称为最大后验估计，类似于经典统计学中的极大似然估计。</p>
<h2 id="贝叶斯网络"><a href="#贝叶斯网络" class="headerlink" title="贝叶斯网络"></a>贝叶斯网络</h2><p>贝叶斯网络(Bayesian network)，又称信念网络(Belief Network)，或有向无环图模型(directed acyclic graphical model)</p>
<h3 id="结构形式"><a href="#结构形式" class="headerlink" title="结构形式"></a>结构形式</h3><p>1、 a-&gt;c b-&gt;c</p>
<p>P(a,b,c) = P(a)P(b)P(c|a,b)成立，即在c未知的条件下，a、b被阻断(blocked)，是独立的，称之为head-to-head条件独立。</p>
<p>2、c-&gt;a c-&gt;b</p>
<p>考虑c未知，跟c已知这两种情况：</p>
<p>在c未知的时候，有：P(a,b,c)=P(c)P(a|c)P(b|c)，此时，没法得出P(a,b) = P(a)P(b)，即c未知时，a、b不独立。</p>
<p>在c已知的时候，有：P(a,b|c)=P(a,b,c)/P(c)，然后将P(a,b,c)=P(c)P(a|c)P(b|c)带入式子中，得到：P(a,b|c)= P(a|c)*P(b|c)，即c已知时，a、b独立。</p>
<p>3、a-&gt;c-&gt;b</p>
<p>还是分c未知跟c已知这两种情况：</p>
<p>c未知时，有：P(a,b,c)=P(a)P(c|a)P(b|c)，但无法推出P(a,b) = P(a)P(b)，即c未知时，a、b不独立。</p>
<p>c已知时，有：P(a,b|c)=P(a,b,c)/P(c)，且根据P(a,c) = P(a)P(c|a) = P(c)P(a|c)，可化简得到：</p>
<h3 id><a href="#" class="headerlink" title></a></h3>]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>通货膨胀-下</title>
    <url>/2021/02/21/%E9%80%9A%E8%B4%A7%E8%86%A8%E8%83%80-%E4%B8%8B/</url>
    <content><![CDATA[<p><strong>摘要</strong></p>
<p>定义、相关概念及现象、分类、成因、影响、相应政策。</p>
<h2 id="货币幻觉"><a href="#货币幻觉" class="headerlink" title="货币幻觉"></a>货币幻觉</h2><a id="more"></a>
<ul>
<li><p>货币幻觉是新凯恩斯主义的代表人物之一阿克洛夫再次提出的。<br>简单说是100元的钱，被认为有100元的购买力。但实际只有50，另一半则为“铸币税”被征收。<br>而幻觉的存在，因为我们不能够完全理性，价格的传导存在时滞，我们私心喜欢虚幻的“富裕”。</p>
</li>
<li><p>货币本质<br>一般等价物？资产？负债？债券？税票？<br>一般等价物是在交换中起的作用。并不能表现出货币的真实所值，或者说购买力。<br>劳动或资产所得的个人财富，通过货币形式，用于购置资产则为资产。而借来的货币，用以购置资产则为债务。<br>对国家而言，可以将美元看做债券，人民币看做税票，这样的视角更能看出货币所值的变化。</p>
</li>
<li><p>成本<br>借贷的利息，意味着货币资源的机会成本。</p>
</li>
<li><p>货币是一种符号。意味着涨涨跌跌的可能性。货币的乘数效应既能放大资产，也能放大负债。能熬得住，承受得了时间成本，则货币将沉淀为资产。</p>
</li>
</ul>
<h2 id="影响"><a href="#影响" class="headerlink" title="影响"></a>影响</h2><ul>
<li>微观</li>
</ul>
<p>1、货币幻觉导致财富再分配：银行存款名义利率往往不能随通胀充分调整以保证实际利率不变，短期内会出现挤兑， 长期内会造成负储蓄、负投资、负就业、负产出。<br>2、实体企业投资:由长期投资转向短期投资，由生产性投资转向非生产性投资<br>3、累进税制下税收扭曲:通胀税<br>4、商品之间相对价格的变动，价格信号配置资源的效率下降– 模糊了工作效果和报酬的关系、使得投机赌博盛行。</p>
<ul>
<li>宏观<br>1、对于产出的影响<ul>
<li>促进论:凯恩斯名义工资刚性理论、新凯恩斯粘性工资价格模型;弗里德曼和卢卡斯的预 期错误模型;</li>
<li>促退论:通胀造成微观效率损失;</li>
<li>中性论:“二分法”</li>
</ul>
</li>
</ul>
<p>2、对于就业的影响:菲利普斯曲线，附加预期菲利普斯曲线的运动 &amp; 长期垂直的菲利普斯曲线<br>货币政策的短期有效性及长期无效性、中央银行通胀预期管理的重要性;</p>
<p>3、对利率、汇率等重要经济变量的影响</p>
<h2 id="成因"><a href="#成因" class="headerlink" title="成因"></a>成因</h2><ul>
<li>需求拉上：大量的货币发行，导致过多的货币和商品供给的增长不平衡，供给弹性不高不能及时地跟上货币发行。</li>
<li>成本推动：劳动力市场的不完全或产品市场的不完全等造成的，主要包括工资推动型、利润推动型、进口成本推动型。如70s两次石油价格上涨和次贷危机后的大宗商品价格上涨。</li>
<li>预期：当期高通胀率带来市场主体的高通胀预期，进而导致下期高通胀。</li>
<li>结构：在供求总量基本相同的情况下，由于某些结构性因素，如本国产业结构老化，资源流动效率较低等造成的通胀–本质是新部门的供给未能及时跟上。</li>
</ul>
<br>
而各种政策环境，如金本位下的铸币成色、白银涌入、转型为纸币制、战争等历史聚变、计划经济、金融秩序等都通过间接影响到以上四个成因因素而导致通胀。



<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1、货币在流通过程中的乘数效应导致的通胀是几何级数的，与通常讲的CPI所标示的通胀不是一个概念。CPI是有欺骗性的，最真实的通胀就是M2与GDP的比值。</p>
<p>2、对偏离正常现象的分析，会带来更深刻的认知。</p>
<p>3、价格的绝对值无意义，房价回不到过去。</p>
<p>4、一般来说，批发价上涨幅度高于零售。</p>
]]></content>
      <categories>
        <category>货银</category>
        <category>货币政策</category>
      </categories>
      <tags>
        <tag>货银</tag>
        <tag>货币政策</tag>
      </tags>
  </entry>
  <entry>
    <title>通货膨胀</title>
    <url>/2021/02/17/%E9%80%9A%E8%B4%A7%E8%86%A8%E8%83%80/</url>
    <content><![CDATA[<p><br> <br></p>
<p><strong>摘要</strong></p>
<p>通胀的基础知识、历史</p>
<h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><h4 id="古罗马的铸币成色下降"><a href="#古罗马的铸币成色下降" class="headerlink" title="古罗马的铸币成色下降"></a>古罗马的铸币成色下降</h4><p>当铸币被减少成色时，首先感知的是发行者，最终才是到物价上。最终感知的人的财富被转移到发行者手里。在刚减少、甚至未减少前感知到时，购入资产–窖藏黄金。此时流通的多为劣币。随着铸币数量增多，价值越跌。而执政者采取的冻结物价的措施，结果却是，规则越来越细、维护规则而设立的官员数量越来越多，触犯规则而死亡的人越来越多，市场越发萧条、充斥恐惧。</p>
<a id="more"></a>
<p>=&gt;<br>无法用立法(价格控制)取代经济规律。通胀是更深问题的表象。</p>
<h4 id="西班牙的白银涌入"><a href="#西班牙的白银涌入" class="headerlink" title="西班牙的白银涌入"></a>西班牙的白银涌入</h4><p>特殊的是，大量涌入没有带来恶性通胀。</p>
<p>1白银涌入<br>2西班牙物资缺乏，多进口<br>3白银官价低于真实价值<br>4人们没有认识到价格上涨的原因在于白银本身供给</p>
<p>=&gt;<br>物价上涨，人们窖藏白银，市场中白银少，流通的为劣币。拥有白银的人以为富有、白银价值不变，不进行生产投资。在舶来品和军事冒险上消耗白银，却未能将白银投入促进生产。流通货币成色降低导致物价进一步上涨。但因为滞后的工资上涨、军事冒险、皇室奢靡、文艺的黄金时代，西班牙一度凭借美洲白银输入和通胀，而使得其王室贵族强极一时。富有者的财富得到巩固，农奴制进一步加强。北欧的革命、宗教革命都未能影响西班牙。</p>
<p>而当美洲白银输入回落，西班牙落后。</p>
<p>=&gt;<br>货币更多不等于财富更多；西班牙最终并未能将货币转为资产、留住涌入的白银的价值；白银收入减缓了制度变革的压力，但并非一件好事；通胀具有传导性，通过贸易传导到其他国家；温和的通胀有助于短期繁荣；虽然金属货币铸造需要成本和受采矿影响，但同样会产生通胀，而纸币受发行者–中央政府官员的良心影响，与通胀的结合就更为天然。</p>
<p>=&gt;<br>工资上浮，并不意味这购买力增加，需要警惕货币幻觉；<br>财富如果不投资、自己不进行变革成长，则长期自然落后，受货币幻觉影响而躺在舒适里，并非好事。<br>大水漫灌的虚假繁荣。</p>
<h4 id="约翰劳的纸币"><a href="#约翰劳的纸币" class="headerlink" title="约翰劳的纸币"></a>约翰劳的纸币</h4><p>法国政府财政赤字重,政府用纸币支付、削减债务<br>1716/05，通用银行成立<br>10月，银行券可支付税收</p>
<p>1717/8，西印度公司成立</p>
<p>开始疯狂:</p>
<blockquote>
<p>1718/12，承诺12%-40%股息回报，垄断烟草业，获得铸币权，接手包税公司(交税给国家、从民众手里征税)，银行大量发行纸币，将国债成功转为股票。<br>出售更多的股票来支付股息。高于市场价33%购入自己公司股票期货。向原始股东限售股票。继续发行大量纸币。</p>
</blockquote>
<blockquote>
<p>1720/1，投放一年前9倍的纸币，新股发行价为40倍，保证金交易出现。</p>
</blockquote>
<p>开始破灭:</p>
<blockquote>
<p>1720上半年，亲王要求兑成硬通货。和东印度合并、高股价回购都不能挽回局势。<br>1720/05，发布规定6个月内纸币贬值，股票降价各50%。</p>
</blockquote>
<p>工薪和小店主受打击小–物价和工资同步地涨跌、且幅度不算太高，投机者有的丧失了所有财富。<br>疯狂到破灭，也就一年时间。</p>
<h4 id="大陆币"><a href="#大陆币" class="headerlink" title="大陆币"></a>大陆币</h4><p>1、战争时期，货币发行来获得物资，导致事后的物价抬升、货币贬值。通过通胀转移私人财富资源用以战备。多种手段，通胀是其一。<br>2、战后的纸币贬值，此时纸币退出流通，或者限制物价，导致通货紧缩。则债务人负担被动加重、物价骤降、经济萧条，价格秩序又被流动性减少而打破。因此，更好的策略是维持战时的物价水平，并保证流动性，促进经济复苏。<br>3、工薪阶层希望价格恢复到战前水平，但是价格本身就是相对的，之前价格的绝对值并不具有意义。战后的价格本应是绝对值高于战前的，而和货币发行相适应。</p>
<p>=&gt;<br>如果流动性和通胀不断地上升或者继续，房价水涨船高，并不会跌回十年前。除非极大萧条，利率极高，央行官员不热爱财富、国家不追求GDP。价格的绝对值，无意义。</p>
<h4 id="法国大革命和分配券"><a href="#法国大革命和分配券" class="headerlink" title="法国大革命和分配券"></a>法国大革命和分配券</h4><p>1788，旱灾导致物价上涨<br>1789，法国政府严重赤字<br>1789/07，攻占巴士底监狱<br>1790/04，革命者没收教会财产，发行分配券，首次利率3%<br>1792，反革命战争爆发<br>1793，路易十六上断头台，9月价格管制出台，开始了恐怖统治；没收有钱人的不动产<br>1794，罗伯斯庇尔遇害，开始了白色恐怖，直到1799拿破仑掌权<br>1795，限价法被废，通胀、经济复苏，粮食价格飞涨，开始了反革命行动 – 烧纸币，恢复铸币，经济秩序(价格)迅速恢复稳定<br>1796，距离首次发行分配券6年不到，分配券面值已经为最为保证的教会财产的20倍。</p>
<p>1770-1787通缩；89-1796通胀；97-1870通缩。</p>
<blockquote>
<p>发行分配券后很快开始贬值，金银开始窖藏，劣币再次驱逐良币。<br>当政府宣布废弃分配券时，大量的分配券沉淀在普通公民手中，他们没有将财富及时转换为永久价值的物品。<br>而工资滞后于物价上涨，工薪和固定收入者丧失了购买力。<br>社会里都是暴发户、投机者、穷人。<br>民众抢掠商人。商业活动萧条，易货贸易、违法交易层出不穷。</p>
</blockquote>
<blockquote>
<p>起初，企业主和大众即布尔乔亚和工人，联合起来对付王室。王室倒台后，开始内斗。最高限价法标志这个马克思阶级斗争的开始。企业主获得了胜利，管制被解除。</p>
</blockquote>
<p>=&gt;<br>历史再度重演。和当初古罗马的通胀没什么区别，都是价格管制来控制，结果无效。和大陆币也区别不大，通胀都是在战争时的手段(通过抬升物价，降低人民生活水平而获得资源，人物力投入到战争)，并以管制解决，然后无效。战争和革命，虽然让社会进步，但不止以士兵生命为代价，还有穷人和富人们。投机者却大发横财。</p>
<p>而人们却没有察觉。</p>
<h4 id="美国内战时期北方"><a href="#美国内战时期北方" class="headerlink" title="美国内战时期北方"></a>美国内战时期北方</h4><p>1836，各州私立银行涌现<br>1861的联邦开支占GDP2%，1865则为26%。联邦政府债务高达28亿美元，33倍于战前，占GDP一半<br>1861年底，纸币不再兑付黄金，18年后才恢复兑换<br>1862，纽交所开设黄金交易</p>
<p>1860-1864，<br>教师工资上涨20-30%，物价上涨到两倍多。则实际工资下降了40%。</p>
<p>1864-1896，<br>由于铸币拥护者的政策导致的绿币升值(与黄金的比对由61%上升到战前的100%)+贸易里其他国家物价下跌，导致物价下跌。最大跌幅65%。30年物价回到世界平均水平。<br>其他国家物价下跌，由于黄金增长低于商品增长。</p>
<blockquote>
<p>白银黄金比价：1867，16：1；1896，31：1；1989，71：1。<br>如果在1867年实行白银本位，则劣币驱良。黄金被窖藏。而流通的白银(因其贬值)，反而可能会促使价格回升。</p>
</blockquote>
<p>=&gt;<br>温和通胀有效，而通缩不利于经济。<br>一国货币贬值，则物价相对于其他货币稳定的国家是上涨的。<br>硬通货的拥护者占了上风，要求按照战前水平兑付黄金，使得货币升值，通缩产生。</p>
<h4 id="德国马克"><a href="#德国马克" class="headerlink" title="德国马克"></a>德国马克</h4><p><strong>1、事实：</strong></p>
<p>每月价格上涨50%–&gt;恶性通胀；马克的恶通胀认为导致了希特勒。</p>
<ul>
<li><p>通胀从小跑进入狂奔<br>一战后的德国，物价是战前的2.5倍，一年后上涨3倍，一年后又上涨2倍多，后来的几个月停顿了下。<br>1921年11月，为战前的40倍。<br>1922年11月开始进一步加速。23年年中开始恐怖狂奔。年末停止。<br>算下爬行阶段耗时2年多，小跑1年半多，狂奔半年多。最高能一个月涨二十多倍。小跑中间也有几个月算温和。<br>23年1月，法国进入鲁尔盆地，8月政府宣布征税，11月与法国战败。此种种不满终于带来了希特勒发动的啤酒馆暴动。</p>
</li>
<li><p>现象<br>民间的借贷利息是政府的120倍。<br>政府和企业主精英重建了工厂，巩固了权力，而对各个家庭生活或者不同经济部门，何等不平等不公正。<br>低利息时大肆借贷购入不动产和商品，马克贬值再用马克归还，产生了新富。<br>政府注销了所有内债。<br>农民享受了高的粮食卖出价格，抵押贷款偿债压力减弱。<br>实际工资下降，真实工资已经低于维持生活的需要。<br>工会要求工资同生活费用指数挂钩，但是消费在一周后进行，当前的指数仍然无法避免手里的钱一周后失去价值。<br>死亡、移民、犯罪上升。<br>耐用品的价格不再取决于需求，而是取决于一周后获得的成本，一周后可能需要双倍的当前价格。<br>汇率贬值-&gt; 国内物价上升-&gt; 增发纸币-&gt; 进一步贬值-&gt; 物价进一步上升  的恶性循环。<br>但，<br>20-23年间国GDP表现不错。钢铁产量稳定。</p>
</li>
<li><p>1923年<br>通胀狂奔后，马克失去信用。11月，失业23%，煤产量44%等经济毁灭。<br>对策：财政部领导人变更，确定结束通胀的新方案，严格削减开支、建立新的税种，德国回复了预算平衡。引入新马克作为临时货币。</p>
</li>
</ul>
<p>=&gt;<br>通胀到了极限，就停顿了。</p>
<p><strong>2、原因探究：</strong></p>
<ul>
<li><p>赔款<br>巨额赔款需要金马克支付，国际市场美元升值高于国内，外国银行购入马克，而使得德国免费获得大量的食品和原材料。但22年7月停止以外汇支付赔款，通胀却加速了。</p>
</li>
<li><p>国际收支<br>出口商品以支付赔款的压力(需要大量出口来获得用以赔偿的外汇，主动性地贬值来刺激出口) 导致马克贬值，国内物价上涨，为维持国内商贸不得不继续印发纸币。</p>
</li>
<li><p>马克投机<br>卖空马克者</p>
</li>
<li><p>避免革命<br>失业和商品短缺会带来俄国一样革命。通胀至少有表面的繁荣。</p>
</li>
<li><p>通胀获利团体的助力<br>马克贬值，外国人希望用马克购买德国艺术品(马克需求增多、而增发的马克进一步大于需求？)；担心受损，资产纷纷被转移到国外。这些都进一步导致货币进一步超发。</p>
</li>
<li><p>政府赤字</p>
</li>
</ul>
<p>=&gt;美元升值和出口压力，为超发找到了借口。本质是巨额赔款成为超发货币的借口。而且政府是通胀获利的最大团体，政府不想看到革命，而马克投机者里，更多是否是政府中人呢。经济现象的解释里，很多结果会反作用于现象，造成现象的强化，而这样的结果被认为成”原因”。这并非根因。</p>
<p><strong>3、问题</strong></p>
<ul>
<li>如果是超发，那么当时真的减少发行，又会出现什么样子呢，会不会紧缩–失业和短缺呢。会不会赔款付不了呢。受害的会否比这样的通胀好？为什么这样的恶性通胀，竟然伴随着就业和GDP的稳定甚至增长呢？</li>
</ul>
<p>(减少发行，如果控制得好能够不会恶性通胀，但是亦不能因此通缩。需要把握节奏。并且，大量的赔款如果不发行足够的货币，除非经济的增长速度快，能够产生相应的流动性需要，否则赔款就是突发的流动性需求。会付不了，或者时间很长。就业和GDP稳定因为，也是算温和的。23年狂奔后导致了大量失业和降产，失业大幅增多现象比通胀发生地慢一些。也可能是失业统计的数据，发生在通胀之后。)</p>
<ul>
<li>新马克和分配券有什么不同呢，都是以土地作为抵押保证。新马克的背景：赔款和政治经济都还是老样子，而新马克却使得恶性通胀恢复地惊人。劣币无法流通后良币取而代之。–海温斯坦为啥能取得稳定货币的成就？</li>
</ul>
<p>(本质是，新马克保证了其价值、控制了发行；而分配券还是超发。似乎根本不在于表面的这些相似，而在于对欲望的态度。)</p>
<ul>
<li>为什么通胀是旧价格的延续而通缩不是？</li>
</ul>
<p>(如果货币价值✖️价格 = 商品劳务价值，那么通胀不改变商品劳务价值，则旧的价格是由于货币价值而反向变动。通缩则是流动性不足，当人们不愿意拿钱买、不愿意出钱投资，认为商品都不值得买，并不是因为觉得货币更值钱，更多可能出于谨慎因素，回报低或者对未来悲观。商品也会慢慢退出市场。由于悲观，影响到投资和产出，变化来自等式右边。)</p>
<ul>
<li>为什么会小跑到狂奔？</li>
</ul>
<p>=&gt;<br>惊人的数字让人记忆犹新。德国现在仍会谨慎。</p>
<h4 id="俄国计划经济"><a href="#俄国计划经济" class="headerlink" title="俄国计划经济"></a>俄国计划经济</h4><p>todo                    </p>
<br>
]]></content>
      <categories>
        <category>货银</category>
        <category>货币政策</category>
      </categories>
      <tags>
        <tag>货银</tag>
        <tag>货币政策</tag>
      </tags>
  </entry>
  <entry>
    <title>银行拨备</title>
    <url>/2021/02/17/%E9%93%B6%E8%A1%8C%E6%8B%A8%E5%A4%87/</url>
    <content><![CDATA[<p><br> <br></p>
<p>拨备有一个重要的功能，就是“以丰补歉”，以平滑利润。</p>
<a id="more"></a>

<blockquote>
<p>为什么要平滑利润？<br><br>如果银行全部股东一直没有变动，那么其实要不要以丰补歉都是一样的，反正赚和亏都是这些股东的。但是，因为股东每个交易日有进有出，所以得考虑利润跨期平滑问题。<br><br>假设有一家银行，过去每年盈利100元，非常稳定地持续了5年以上。突然有一年，发生了一笔不良资产，当年会亏损200元。如果这家银行没有以丰补歉，而是前5年把利润全分红了，然后有股票换手，有新股东进来，然后到了第6年亏损200元，那么新股东怎么都不会开心的。他们会觉得，前面的股东赚走了贷款的利息，而这笔贷款发生违约时，亏损让自己承担，这太不公平了。<br><br>这跟信用债交易有点类似。有些信用债在违约发生前发生交易，新买入的投资者成了接盘侠……</p>
</blockquote>
<p>如果按照要求计提拨备，也很做到平滑利润（不良太多，把超额拨备消耗完毕之后还不够）。那么，还有一个方法，就是在不良贷款的确认上动手脚。因为不良资产和非不良资产之间，并没有清晰、客观的边界，边界划分在哪，是有一定的主观性的。</p>
<p>基于拨备覆盖率指标，我们可以有这样一个假设（确实存在例外的情况）：<code>银行不太可能一边宽松认定不良（甚至隐藏不良），一边又计提大量超额拨备，保持很高的拨备覆盖率。</code></p>
<blockquote>
<p>（1）如果一家银行拨备覆盖率远超监管标准（比如150%），并且还在持续提升，那么很明显是处于丰的阶段。很显然，市场上，这样的银行股，估值一般不低，而且主升浪是从它们拨备覆盖率开始显著上升开始的。<br><br>（2）如果一家银行拨备覆盖率在较长时期内仅维持在监管标准附近，那么有可能是：每年的营业收入用于消化存量不良之后，无能力留存额外的拨备。甚至，它是每年收入能消化多少不良就确认多少不良，并且还有存量不良还未消化完毕（存量不良有可能还未确认到报表中），还在补欠。<br><br>（3）如果一家银行拨备覆盖率高位回落，可能也是处于补欠的阶段，即每年收入已经不足以消化新发生不良，而是需要拿过去的超额拨备去消化新发生的不良。<br><br>（4）一家银行的拨备覆盖率从监管标准开始起飞，则有可能是存量不良处置完毕了，开始进入丰的阶段，积累超额拨备。</p>
</blockquote>
]]></content>
      <categories>
        <category>货银</category>
        <category>商业银行</category>
      </categories>
      <tags>
        <tag>货银</tag>
        <tag>商业银行</tag>
      </tags>
  </entry>
  <entry>
    <title>笛卡尔积</title>
    <url>/2021/03/11/%E9%9B%86%E5%90%88%E7%9A%84%E7%AC%9B%E5%8D%A1%E5%B0%94%E7%A7%AF/</url>
    <content><![CDATA[<br>
<br>


<h2 id="笛卡尔积"><a href="#笛卡尔积" class="headerlink" title="笛卡尔积"></a>笛卡尔积</h2><a id="more"></a>

<br>


<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public static String cartesianProduct(final String[][] inputs) &#123;</span><br><span class="line">        if (inputs &#x3D;&#x3D; null) &#123;</span><br><span class="line">            return null;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        final StringBuilder sb &#x3D; new StringBuilder();</span><br><span class="line">        </span><br><span class="line">        product(&quot;&quot;, 0, inputs, sb);</span><br><span class="line">        </span><br><span class="line">        return sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line">public void product(String prefix,int index, String[][] input,StringBuilder sb)&#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; input[index].length; i++) &#123;</span><br><span class="line">            if (index &gt;&#x3D; input.length - 1) &#123;</span><br><span class="line">                sb.append(prefix + input[index][i]);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                product(prefix + input[index][i], index + 1, input, sb);</span><br><span class="line">            &#125;</span><br><span class="line">            if (i &lt; input[index].length - 1) &#123;</span><br><span class="line">                sb.append(&quot;, &quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>两个变量关键prefix和index，作为递归方法的参数时进行变化<code>prefix + input[index][i]</code>和<code>index+1</code>。</p>
<p>从数列角度看，sb(j) = sb(j-1) + charAt(i) ,charAt(i)需要一个for循环即<code>for (int i = 0; i &lt; input[index].length; i++)</code>。sb(j-1)为<code>prefix</code>，下一步需要<code>prefix + input[index][i]</code>；其中<code>j-1</code>为<code>index</code>，进入下一步需要<code>index+1</code>。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM</title>
    <url>/2021/02/04/SVM/</url>
    <content><![CDATA[<br>


<ul>
<li><p>reference：[非常好的两本书。再加上libsvm的源码与调参的论文。]<br>[1]<a href="http://files2.syncfusion.com/Downloads/Ebooks/support_vector_machines_succinctly.pdf">http://files2.syncfusion.com/Downloads/Ebooks/support_vector_machines_succinctly.pdf</a><br>[2]An Introduction to Support Vector Machines and Other Kernel-based Learning Methods<br>[3]<a href="https://pan.baidu.com/share/link?shareid=262520779&amp;uk=1378138793">https://pan.baidu.com/share/link?shareid=262520779&amp;uk=1378138793</a></p>
</li>
<li><p>干货</p>
</li>
<li><p>首先，SVM是解决supervised learning 中classification问题。有两种情况，看是否linearly separable。线性不可分则引入kernel，想法为先做transformation到其他空间进而转为可分问题。</p>
</li>
<li><p>对于线性可分的监督分类问题，SVM的目标是什么呢? find  the optimal separating hyperplane which maximizes the margin of the training data</p>
</li>
<li><p>为什么以最大化间隔为目标？因为it correctly classifies the training data and because it is the one which will generalize better with unseen data</p>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p>这里的 间隔 指？关于间隔涉及到两种分类，一种分类为几何间隔与函数间隔；一种为软、硬间隔。几何间隔在二维则为点线距离，三维空间就是我们学习的点面距离。函数间隔二维中可以理解为<em>几个</em>点没有在线上，三维则为<em>几个</em>点没有在面上；或者结合几何间隔可理解为，是将几何间隔求解的分母去掉了，没有归一化(也因此SVM中不能选择以函数间隔衡量，否则maximizes是没有意义的)。关于软硬，是看噪声，There will never be any data point inside the margin.  If data is noisy, we need soft margin classifier.</p>
</li>
<li><p>继上面的目标，假设该超平面的公式为W*X=0，这里会有疑惑：</p>
<ul>
<li>Why do we use the hyperplane equation W<em>X instead of   Y=a</em>x+b? –&gt; the vector W will always be normal to the hyperplane</li>
</ul>
</li>
<li><p>澄清下要做的步骤：<br>  1 数据集<br>  2 选择两个超平面能够分类数据并在两平面间没有其他点<br>  3 最大化超平面间隔</p>
</li>
<li><p>将步骤整理成数学过程</p>
<ul>
<li><p>设两个超平面， W<em>X+b = -θ  和  W</em>X+b = +θ。这里，为什么我们需要两个超平面？我们设想的是，假定最佳的超平面在这两个超平面的中间。我们求得两个超平面即可求得最佳分类超平面。</p>
</li>
<li><p>θ取值无关，直接设为1。 即得W<em>X+b = -1  和  W</em>X+b = +1。这里要想明白W与b到底是什么关系？b依赖还是独立于W？显然，是独立的，可以想象为，我们需要求得W与b两个变量，能够最大化间隔。</p>
</li>
<li><p>需要满足两个约束: 1. 任何&gt;=1的为class 1 2.任何&lt;=-1的为class -1 –&gt;这个限制使在两平面间没有其他点</p>
</li>
<li><p>将两个约束写为一个式子即： y*(w*x+b)&gt;=1</p>
</li>
<li><p>最大化间隔 ？对于这个问题，目前我们已知条件是两个。一个是两个平面 W<em>X+b = -1  和  W</em>X+b = +1。一个是有一个点x在平面  W<em>X+b = -1 上</em>。得：<br><code>w*(x + m*w/||w||)+b=1</code><br>化简得 <code> m = 2/||w||</code></p>
</li>
<li><p>得到的公式意味着：如果||w||没有限制，那么m我们可以取得任意大的值。</p>
</li>
<li><p>现在自然就面临optimization problem。所有的点subject to  y*(w*x+b)&gt;=1, 在此条件下如何minimize ||w||?先引入<strong>理论1</strong>，该理论为两个条件，在两个条件满足的情况下，可以说我们得到了一个scalar function的local minimum。</p>
</li>
</ul>
</li>
</ul>
<p><img src="/2021/02/04/SVM/theorem1.png" alt="theorem1"></p>
<ul>
<li>f为从集合σ(其元素为vector)到实数集(其元素为值)的映射，且在x处 连续、可二阶导。这里涉及到两个的概念：<ol>
<li>**gradient ：a generalization of the usual concept of derivative of  a function in one dimension to a function in several dimensions  ( the gradient of a function is a vector containing each of its partial derivatives.)**注意符号为 nabla,图中倒三角。 </li>
<li><strong>scalar function：A scalar valued function is a function that takes one or more values but returns a single value. In our case f is a scalar valued function.</strong></li>
</ol>
</li>
<li>positive definite：<br>A symmetric matrix A  is called positive definite if x.T<em>A</em>x&gt;0 , for all n维的实数向量x。</li>
<li><strong>theorem 2</strong>中的四个条件是等价的。因此可以通过其他三种情况来判断是否为正定。这里选择主子式来判断Hessian正定，涉及到三个概念：</li>
</ul>
<p><img src="/2021/02/04/SVM/theorem2.png" alt="theorem2"></p>
<ol>
<li>Minors： 删除某行和某列的所有值再计算行列式。remove the ith line and the jth column</li>
<li>Principal minors ：删除的行、列号一致。remove the ith line and the jth column and i=j</li>
<li>Leading principal minor ：The leading principal minor of A of order k is the minor of order k obtained by <strong>deleting the last n−k rows and columns</strong>.（这里包含一个正三角符号，标注删除哪些行列）栗子看图Leading principal minor</li>
</ol>
<p><img src="http://upload-images.jianshu.io/upload_images/8716089-42fb025afc8f45d5.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="leading principal minor.jpg"></p>
<ul>
<li>得到了local minimum，How can we find a global minimum?两步走， 1. Find all the local minima 2. Take the smallest one; it is the global minimum. 另一个思路是看我们的f是否是<strong>convex</strong> ,是then we are sure its local minimum is a global minimum.</li>
</ul>
<p><strong>Theorem: A local minimum of a convex function is a global minimum</strong> 这里又涉及到convex function, convex set的定义。</p>
<ul>
<li>What is a <a href="http://mathworld.wolfram.com/ConvexFunction.html">convex function</a>? A function is convex if you can trace a line between two of its points without crossing the function line.<br><img src="http://upload-images.jianshu.io/upload_images/8716089-fd9cfea722d77a1d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="convex  0&lt;λ&lt;1.jpg"><blockquote>
<p>A function is convex if its epigraph (the set of points on or above the graph of the function) is a convex set. In Euclidean space, a convex set is the region such that, for every pair of points within the region, every point on the straight line segment that joins the pair of points is also within the region. </p>
</blockquote>
</li>
</ul>
<p>栗子看图convex set</p>
<p><img src="http://upload-images.jianshu.io/upload_images/8716089-b484ebf0cfdf222d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="convex set.jpg"></p>
<ul>
<li>同样根据Hessian判断是否convex，这里需要看是否是<strong>positive semidefinite</strong>,而semi有对应三个条件是与之等价。看 theorem 3<blockquote>
<p>**More generally, a continuous, twice differentiable function of several variables is convex on a convex set if and only if its Hessian matrix is positive semidefinite on the interior of the convex set.**The difference here is that we need to check all the principal minors, not only the leading principal minors. </p>
</blockquote>
</li>
</ul>
<p>  <img src="http://upload-images.jianshu.io/upload_images/8716089-744d4e22dac7d5aa.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="theorem 3.jpg"></p>
<ul>
<li>其中on the interior of the convex set是什么意思呢？定义：the domain of a convex function is a convex set，那么 a function is convex on a convex set意思就是在domain上是convex function，而interior只是意味着为两边开区间。</li>
<li><a href="http://www.math.cmu.edu/~ploh/docs/math/mop2013/convexity-soln.pdf">其他证明是convex function的方法</a></li>
<li>这里就谈convex function的optimization问题求解。涉及对偶概念，根据wiki，<blockquote>
<p>Duality :duality means that optimization problems may be viewed from either of two perspectives, the primal problem or the dual problem (the duality principle). The solution to the dual problem <strong>provides a lower bound</strong> to the solution of the primal (minimization) problem. </p>
</blockquote>
</li>
</ul>
<p>  给最小值以下限。lower bound中有一个值为<strong>infimum</strong> (即 greatest lower bound)。补充，相对而言</p>
<blockquote>
<p>The same logic apply with the relation “greater than or equal” and we have the concept of upper-bound and supremum.</p>
</blockquote>
<ul>
<li>对偶，在求最小值时求对应的最大值，求出的最大值将是=&lt;最小值，两者之差即为<strong>duality gap**。对应来说，在求最大值时求对应最小值，求出的最小值将是&gt;=最大值即upper bound。</strong>duality gap<strong>为正，我们称之</strong>weak duality holds<strong>，为0则为</strong>strong duality holds**。</li>
<li>拉格朗日乘子 ： <blockquote>
<p>In mathematical optimization, the method of Lagrange multipliers is a strategy for finding the local maxima and minima of a function subject to <strong>equality</strong> constraints. </p>
</blockquote>
</li>
</ul>
<p>  <img src="http://upload-images.jianshu.io/upload_images/8716089-59b1f2660a4869b6.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="Lagrange_portrait.jpg"></p>
<ul>
<li><p>如何将3D图在2D平面表示：Contour lines  两个要点：1. 线上的点z值不变，for each point on a line, the function returns the same value 2. 颜色扮演标识，the darker the area is, the smallest the value of the function is<br><img src="http://upload-images.jianshu.io/upload_images/8716089-271a7e44b55a0424.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="contours.png"></p>
</li>
<li><p>那么梯度就可以用<strong>向量场</strong>进行可视化。箭头指向函数增长的方向。与Contour lines 图有什么关系呢？在Contour lines 图中，gradient vectors非常容易画出，1 垂直于Contour lines 2.指向增加的方向。<img src="http://upload-images.jianshu.io/upload_images/8716089-8ee3efb4b3646c71.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="gradient_and_contour.png"></p>
</li>
<li><p>将约束函数和优化目标函数以contour lines 画在一幅图中，并画出两者的gradient vector。可得到最优点。图中的优化目标函数为x^2+y^2, 约束函数为 y=1-x。 <img src="http://upload-images.jianshu.io/upload_images/8716089-fc1f3051bbf27c8a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="function_and_constraint.png"></p>
</li>
<li><p>▽f(x,y) = λ ▽g(x,y)<br>λ 这就是拉格朗日乘子。根据图中，当两个gradient vector平行时，我们得到最优解。无论是否同向。更无论是否等长。乘以λ 即意味着不必等长。即求▽L(x,y,λ )=0时的x，y。现在我们需要列出L并求解。</p>
</li>
<li><p>由于我们需要求f(w)=1/2*||w||^2的最小值，将每个约束函数乘以的 λ需要取正数。<img src="http://upload-images.jianshu.io/upload_images/8716089-76c3fc3fc413375d.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="L.jpg"></p>
</li>
<li><p>又面临一个问题，求L(x,y,λ )=0， the problem can only be solved <strong>analytically when the number of examples is small</strong> (Tyson Smith, 2004 即只有当约束函数数量比较小的时候，λ 个数不多，我们才能用分析的方法求解). So we will once again rewrite the problem using the duality principle–&gt;we need to minimize with respect to w and b, and to maximize with respect to a at the same time.我们在上一步需要最小化<br><img src="http://upload-images.jianshu.io/upload_images/8716089-4ca65da333340058.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="duality_after_L.jpg"></p>
</li>
<li><p>这里需要讲清楚三个问题。1. 拉格朗日是对约束函数是等式的情况，那么我们在这里是不等式约束的问题，也用拉格朗日乘子解决，需要满足什么条件吗？(KKT)2.之前说了，对偶问题有强与弱，只有当强时，gap才为0，我们才能将对偶问题的最大值作为原问题的最小值。那么，这里是否满足是strong duality holds? （强对偶 即下文Slater’s condition）3.或许你对为什么能够是对w b求min，对a求max还是留有疑问。(拉格朗日到对偶问题这两个之间的转化过程)</p>
</li>
<li><p>仍需要引入两个理论。1.  duality principle 2.Slater’s condition 3.KKT<br>首先，L对w与b求偏导，令为0(这里两个等式)，再将这两个等式带入到L中，消去了w、b，只剩下变量a，即得L(a)。于是将问题转化为 Wolfe dual Problem<br><img src="http://upload-images.jianshu.io/upload_images/8716089-67cdfbf09b820630.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="wolfe dual.jpg"></p>
</li>
<li><p>慢着，这里又出现一个问题。</p>
<blockquote>
<p>Traditionally the Wolfe dual Lagrangian problem is constrained by the gradients being equal to zero. In theory, we should add the constraints θL/θw=0  and  θL/θb=0 . However, we only added the latter, because it is necessary for removing   b from the function. However, we can solve the problem without the constraint   θL/θw=0.</p>
</blockquote>
<p>这里就会不明白为什么不需要加上θL/θw=0约束仍能够solve the problem？暂且保留疑问。</p>
</li>
<li><p>Karush-Kuhn-Tucker conditions :<strong>first-order necessary conditions</strong> for a solution of an optimization problem to be optimal<br>除了KKT还需要满足一些regularity conditions，其中之一为Slater’s condition。</p>
<blockquote>
<p>Because the primal problem we are trying to solve is a convex problem, the KKT conditions are also sufficient for the point to be primal and dual optimal, and there is zero duality gap.</p>
</blockquote>
<p>这里说的，即只要为convex问题，KKT也满足，即可说得出的结果是原问题或对偶问题的最优解，因为Slater’s condition是一定满足了的，gap=0。对于SVM，如果结果满足KKT，那么即可说是最优解。(详细证明过程[2] ch5)</p>
<p>   <img src="http://upload-images.jianshu.io/upload_images/8716089-62f19539ba8a88bc.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="KKT.jpg"></p>
</li>
<li><p>可见，1. stationary 即为偏导为0即为驻点,若无约束函数则直接gradient是0，有了约束则gradient of the Lagrangian为0。2. primal feasibility为原问题约束函数  3. dual feasibility 为我们对L求解时使用对偶理论时的约束函数  4.complementary slackness含义是，要么a=0，要么y*(w*x+b)-1=0.这里与<strong>Support vectors</strong>相关，</p>
<blockquote>
<p>Support vectors are examples having a positive Lagrange multiplier. They are the ones for which the constraint y*(w<em>x+b)-1&gt;=0  is active. (We say the constraint is active when y</em>(w*x+b)-1=0 )</p>
</blockquote>
<p>这里，是否会疑惑为什么不能同时为0？为什么multiplier一定是正数？在KKT中，我们只选取支持向量，即将不等号约束改为等号约束，其他的点不考虑。</p>
<blockquote>
<p>Solving the SVM problem is equivalent to finding a solution to the KKT conditions.” (Burges, 1988)</p>
</blockquote>
</li>
<li><p>现在有了L(a),求导即可。得到了a。再根据偏导为0的公式回代得到w 。再根据prime problem中的约束函数y*(w*x+b)-1&gt;=0，计算b</p>
</li>
<li><p>用QP solver来解对偶问题。用python CVXOPT包。将wolfe dual.jpg中我们需要求解的公式转化到下面CVXOPT支持的形式。这里引入了一个Gram matrix - The matrix of all possible inner products of X.</p>
</li>
</ul>
<p><img src="http://upload-images.jianshu.io/upload_images/8716089-907dcfe22f62860e.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="CVXOPT.jpg"></p>
<p><img src="http://upload-images.jianshu.io/upload_images/8716089-ac41318c2c79efb1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="转化过程.jpg"></p>
<p>这个图里有问题，minimize部分最后一项需要<code>q.T*a</code>, 详见代码部分，需要q = cvxopt.matrix(-1 * np.ones(m))。</p>
<ul>
<li>code部分：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import cvxopt.solvers</span><br><span class="line">X, y &#x3D; 这里获取到数据</span><br><span class="line">m &#x3D; X.shape[0]  #data有多少</span><br><span class="line"># Gram </span><br><span class="line">K &#x3D; np.array([np.dot(X[i], X[j]) for j in range(m) for i in range(m)]).reshape((m, m)) </span><br><span class="line">P &#x3D; cvxopt.matrix(np.outer(y, y) * K)</span><br><span class="line">q &#x3D; cvxopt.matrix(-1 * np.ones(m))</span><br><span class="line"># 等式约束</span><br><span class="line">A &#x3D; cvxopt.matrix(y, (1, m))</span><br><span class="line">b &#x3D; cvxopt.matrix(0.0)</span><br><span class="line"># 不等式约束</span><br><span class="line">G &#x3D; cvxopt.matrix(np.diag(-1 * np.ones(m))) h &#x3D; cvxopt.matrix(np.zeros(m))</span><br><span class="line"># 求解</span><br><span class="line">solution &#x3D; cvxopt.solvers.qp(P, q, G, h, A, b)</span><br><span class="line"># 拉格朗日乘子</span><br><span class="line">multipliers &#x3D; np.ravel(solution[&#39;x&#39;])</span><br><span class="line"># 支持向量</span><br><span class="line">has_positive_multiplier &#x3D; multipliers &gt; 1e-7 </span><br><span class="line">sv_multipliers &#x3D; multipliers[has_positive_multiplier]</span><br><span class="line">support_vectors &#x3D; X[has_positive_multiplier] </span><br><span class="line">support_vectors_y &#x3D; y[has_positive_multiplier]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#计算w，b</span><br><span class="line">def compute_w(multipliers, X, y):</span><br><span class="line">    return np.sum(multipliers[i] * y[i] * X[i]  for i in range(len(y)))</span><br><span class="line">def compute_b(w, X, y):</span><br><span class="line">    return np.sum([y[i] - np.dot(w, X[i]) for i in range(len(X))])&#x2F;len(X)</span><br><span class="line"></span><br><span class="line">w &#x3D; compute_w(multipliers, X, y)</span><br><span class="line">w_from_sv &#x3D; compute_w(sv_multipliers, support_vectors, support_vect</span><br><span class="line">b &#x3D; compute_b(w, support_vectors, support_vectors_y)</span><br><span class="line"> </span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>We saw that the original optimization problem can be rewritten using a Lagrangian function. Then, thanks to duality theory, we transformed the Lagrangian problem into the Wolfe dual problem. We eventually used the package CVXOPT to solve the Wolfe dual.</p>
</blockquote>
<ul>
<li>为什么需要将拉格朗日函数转化为对偶问题到wolfe dual？<br>这里还差对偶原则及Slater’s condition 概念。</li>
</ul>
]]></content>
      <categories>
        <category>ml</category>
      </categories>
      <tags>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>股市整体价值理论</title>
    <url>/2021/02/22/%E8%82%A1%E5%B8%82%E6%95%B4%E4%BD%93%E4%BB%B7%E5%80%BC%E7%90%86%E8%AE%BA/</url>
    <content><![CDATA[<br>
<br>

<h4 id="大牛股"><a href="#大牛股" class="headerlink" title="大牛股"></a>大牛股</h4><ul>
<li>现在没涨，一年内会涨；<code>现在涨了，预计继续上涨（至少在未来3个月内）</code>；曾经大涨，但现在已经停止上涨或者开始下跌或者已经大跌，且在短期内股价不存在大涨（创新高）的可能性。</li>
<li>“买大牛股，抓主升浪”，这两句话是不可分的。</li>
<li>高确定性的操作与盈利模式</li>
<li>只关注那9～10类强势股</li>
<li>股票投资要记住两句话：第一句话是不要赔钱，第二句话是记住第一句。<a id="more"></a></li>
<li>绝大多数赔钱者，其赔钱的主要原因是缘于<code>选股问题——选错了股票，或者选中了非牛股，甚至是大熊股</code>，而操作技巧方面的不当只占赔钱的次要因素。</li>
<li>短期暴涨型主升浪：<code>在短期内股价涨幅达到80%～100%的上涨波段，或者是股价涨幅能够在一年内至少翻倍的股票</code>。<br>
<br></li>
</ul>
<p><img src="/2021/02/22/%E8%82%A1%E5%B8%82%E6%95%B4%E4%BD%93%E4%BB%B7%E5%80%BC%E7%90%86%E8%AE%BA/tqly.png" alt="63.28/19.42=3.26倍"><br>63.28/19.42=3.26倍，11/06-01/09，<br>10年50.22-&gt;488.57，年收益0.8729<br>PEG=[44.7 79]/87=[0.506 0.908]</p>
<br>

<ul>
<li>上涨动力：一是内在价值低估–&gt;估值修复力，二是内在价值成长–&gt;内在增长力，三是投机价值增长–&gt;投机价值增长力。</li>
<li><code>从低估值股票挖掘，再看其成长性，最后看其有无热门概念，这就是选股的逻辑。</code></li>
<li>一是信息系统，包括信息搜集、整理、归类与处理；二是分析系统，分析信息对于股价的作用，特别是对于主升浪的作用，这需要在事前建立相关的评价标准；三是操作系统，在“五面整体顺势”的情况下加仓，在“五面整体逆市”的情况下减仓，即，在判断正确的情况下持仓或者加仓，在判断错误的情况下不增仓或者减仓止损。</li>
<li>一个运动的物体受到的力可以分为四种：一是原动力，二是持续推动力，三是阻力，四是运动过程中新加入的作用力。</li>
<li>炮射导弹可以利用大炮而获得极高的初速度与相当远的运动距离，可以大量节省火箭发动机的燃料，这对于降低导弹成本、提高导弹射程是很重要的。</li>
<li>洲际导弹的变轨技术</li>
<li>主升浪是十分罕见的，主升浪所占的时间一般不到该股票的整体交易时间的30%。也就是说，大多数股票在**70%**以上的时间里是处于非主升浪状态，其中的多数又是处于振荡状态，或者说无明显的趋势状态。无趋势状态，是很难预测的，故可以归为随机波动范畴。</li>
<li>小市值低价股现在被公告注入热门资产后，这是一个巨大的利好题材，该利好题材带来“一字涨停板”方式暴涨，我们经常看到这类股票会以<strong>连续5～6个甚至是十几个“一字涨停板”暴涨</strong>。这样的暴涨过程，就是一个惯性运动，即，以巨大的初速去克服股价上涨的所有阻力，当股价运动速度无法抵消阻力的反作用时，股价的向上运动就会停止，甚至会因前期的过度上涨而发生走势逆转，导致短期大跌，最终形成暴涨暴跌之态。</li>
<li>股价原动力的爆发力度：估值法，就是对股票进行估值，看看股价是否被低估。绝对估值法，就是评估股票的绝对投资价值。相对估值法。</li>
</ul>
<br>

<p>综上，<br>1、不能选错股票、不能赔钱，核心：大牛股的主升浪，核心：低估值股票挖掘，再看其成长性，最后看其有无热门概念。<br>2、短期暴涨型主升浪<br>3、连续5～6个甚至是十几个“一字涨停板”暴涨<br>4、一是原动力，二是持续推动力，三是阻力，四是运动过程中新加入的作用力。<br>5、股价原动力的爆发力度：估值法</p>
<br>
<br>

<h4 id="绝对估值法"><a href="#绝对估值法" class="headerlink" title="绝对估值法"></a>绝对估值法</h4><p>评估股票的内在价值与股价的差值，当内在价值与股价的比值越大，则股价的上涨潜力越大，这种潜力一旦遇到合适的市场时机，就有可能爆发出来，转变为引发股价暴涨的原动力。</p>
<ul>
<li><p>投资价值估值法<br>1、目标股票的长期投资收益率与长期国债收益率进行比较，两者差值越大，则长期投资价值越高，这里的长期应该是指5～10年以上。巴菲特的标准更高一些，他的长期价值投资收益率基本定在10年内的年均复合收益率达到10%以上。<br>2、在考虑到风险溢价的情况下，择股标准应该趋于保守，所选择的长期价值股应该是低市盈率的成长股。按照价值投资的基本标准，对于长期成长股来说，其合理的股价范围应该满足PEG＜1（PEG=市盈率/收益增长率），且越低越好。当PEG＜0.5时，股票就存在足够的安全边际。<br>3、若一只股票未来的5～10年的年均复合收益增长率能够达到20%，则当该股的市盈率跌到10倍时，就具有极好的投资价值。应该注意的是，此时的股价虽然不高估，但也不是<strong>明显低估</strong>，还难以产生爆发性很强的估值修复力。假若此时，股市暴跌，该股股价随着股市暴跌而意外地跌到5倍市盈率，那么，此时该股股价就被明显低估了。</p>
</li>
<li><p>资产价值估值法<br>1、比较股票净资产值与总市值的比值，比值越大，则股价低估越多，股价上涨空间越大。<br>2、这类股票主要体现在隐蔽资产股上面。自2006年来，隐蔽资产股经常走出大牛股。<br>3、一隐蔽资产的大幅升值不被知晓，二隐蔽资产的增值过程是公开的、渐进式的，但隐蔽资产股的股价涨幅在起初滞后于隐蔽资产的增值幅度，最终股价会出现报复性补涨，使得隐蔽资产增值的这一事实成为了股价暴涨的原动力。</p>
<blockquote>
<p>2012年7月的罗顿发展：当《二十一世纪经济报道》披露该股在10年前曾花了2亿元在博鳌的黄金地段买下了1800亩土地，这些土地现值100多亿元，以罗顿发展总股本4.4亿股计算，仅这些土地价值就足以支撑该股股价到达15～20元。在该信息公告时，罗顿发展的股价只有3.9元。该信息公告后，罗顿发展的股价就出现了连续涨停板，不到一个月股价涨幅达到170%！在此期间，上证指数还是下跌的。<br><br>2013年1月28日至2月6日的西水股份就属此例。西水股份持有1.3亿股兴业银行，当兴业银行股价暴涨后，西水股份持有的兴业银行价值大幅增值，几乎等于西水股份的总市值，由于西水股份还持有未上市的天安保险11亿股，以及其它资产，这等于说除去兴业银行外，西水股份持有的其它资产被忽略不计了，这是明显不合理的，于是，在2013年1月28日至2月6日，该股就出现报复性的补涨，股价从6.6元涨到了11.8元，几乎翻倍。</p>
</blockquote>
</li>
<li><p>绝对套利估值法<br>1、上市公司被以高出市场价一大截全额要约收购时，其要约收购价格就是股票的真实内在价值，这个内在价值与现价的差值就是股价的无风险套利空间。假若市场是有效的，那么，股价就会几乎一步到位地涨到那个要约收购价格，于是，这个要约收购公告就是造成股价暴涨的原动力。<br>2、前几年被要约收购退市的石油大明、辽河股份等，就属此例。<br>3、当然，在有些时候，要约收购并非是全额的，而是部分的，如去年的重庆啤酒，那么，这类股票的上涨就可能不是一步到位的，而是渐进式的，二级市场就存在套利空间。在渐进式的情况下，要约收购公告虽然还是股价上涨的原动力，但它却会受到当时的市场运行状态、该股同板块股票运行状态等因素的影响，因此，股价运行就不仅受到原动力的作用，还受到其它新的作用力的作用。<br>3、这种情况还出现在某些上市公司大股东回购公司部分股票时，回购部分股票的股价并非是股票的真实内在价值，该价格只是大股东认可的价格而已，不能与完全要约收购价格相提并论，这是需要搞清楚的。</p>
</li>
</ul>
<p>综上，<br>1、按照逻辑，估值存在潜力时，股价未能反应的原因为，存在其他阻力，如市场运行状态、同版股票运行状态等。<br>2、概括，三个绝对估值方法为，PEG&lt;0.5的长期投资、隐蔽资产(所持股票或投资的公司或土地等)、全额要约收购与部分要约收购。</p>
<br>

<h4 id="相对估值法"><a href="#相对估值法" class="headerlink" title="相对估值法"></a>相对估值法</h4><p>一是基本面预期类，二是市场面预期类，三是技术面预期类，四是大盘面预期类。</p>
<p>1、就是领涨的市场、板块或者个股，它们是那些拥有比价效应、等待补涨的市场、板块或者个股的追赶的目标。<br>2、在补涨者开始补涨时，领涨者可以暂时停止上涨；在补涨者开始补涨时，领涨者还可以继续上涨，这对补涨者的领涨作用更大。<br>3、随着价格等自变量的变化，心理预期这个因变量也会随之变化。可见，若用一句话表述心理预期类投机价值，那就是–&gt;一切处于变化之中。<br>4、戴维斯双击，是指因股票收益持续成长，投资者会对股票未来的收益增长产生更高的预期，在未来收益还未实现的情况下，就以未来的高收益定位其市盈率，从而提升其市盈率定位水平，最终导致股价过度上涨。<br>5、<code>提升了股票的市盈率，也就是提升了股票的估值，这相当于产生了新的投机价值</code><br>6、戴维斯双击原理： 由于 <code>股价=每股收益*市盈率</code> ，当每股收益持续增长时，即使市盈率保持不变，股价也会同比上涨，这属于戴维斯双击中的第一击；当每股收益持续增长时，若还提升市盈率，则股价会更上一层楼，涨幅会更大，这属于戴维斯双击中的第二击。戴维斯双击能够导致乘数效应，使得股价涨幅加倍。由于戴维斯双击提升了股票的市盈率，也就是提升了股票的估值，这相当于产生了新的投机价值。戴维斯双击效应产生的根源，就是投资者依据历史数据的惯性，顺势推导、过度预期的结果。<br>7、更重要的是<code>因比价关系引发的股价跟涨而造成的股价虚高</code>，但这并不妨碍我们得出因基本面过度预期而产生新的投机价值的结论。<br>8、主流热点是市场热钱追逐的对象，处于热点中的板块与股票一定是短期内最牛的，基本上属于短线暴涨型品种。<br>9、市场面预期，就是对于市场未来炒作热点的预判。一旦判断某个板块或者个股刚刚成为或者在未来会成为市场炒作热点，那么，该板块或者个股就具有新的投机价值，股价就具有投机价值所赋予的上涨空间。<br>10、比价关系是领涨者已经给出了方向，给出了大致的投机价值空间，但市场面预期是市场才刚刚开始启动热点，或者还未开始热点，但投机者只是预见到了炒作热点将出现，但投机者一般还难以确定投机价值到底有多大，上涨空间有多大，这要走一步看一步。<br>11、在2012年12月中旬，当媒体披露北斗系统将投入商业应用时，超级主力立即抢进了北斗星通等龙头股，造成北斗概念股暴涨。我认为，这次对于北斗概念股的炒作，属于市场面预期主导下的“自我增强”型炒作模式。其基本逻辑是：超级主力判断北斗概念也许会成为市场热点，但到底能形成多大的热点，他们也许并没有很大把握，因为北斗概念是一个全新的概念，人们很陌生，超级主力担心投资者不认同；但超级主力知道，要让投资者认识且认同北斗概念，最佳的方法就是让北斗概念股暴涨，因为股票暴涨一定会吸引全市场的眼光，所有人都会好好研究的，这就是一种“胡干胡有理，越干越有理”的江湖思维。当然，平心而论，毕竟北斗导航属于国家级的概念，超级主力知道，即使胡干的风险也不大，最终，他们成功了。<br>12、赚钱的境界是这样的：最低的境界是打工，用自己的身体赚钱；次低的境界是做实业，让别人的身体为自己赚钱；较高的境界是玩钱（做金融），让钱生钱；而最高的境界是玩规则，让所有的人与所有的钱为自己赚钱。这就是赚钱的金字塔模型。<br>13、以二级市场来论，也存在一个投资者的金字塔模型：<br>最低的境界是交易，次低的境界是跟庄，较高的境界是坐庄（单只股票），而最高的境界是引领市场、发动行情（玩板块甚至玩整个市场）。北斗概念主力就属于最高境界的，不仅是北斗概念，去年市场的几乎所有的市场热点——3D打印、手游、传媒等，都是不同的超级主力们发动的行情。这些主力们“敢为天下先”的底气何在？有人可能认为是他们的资金实力雄厚，此言谬矣，你若有钱，去发动钢铁板块、水泥板块试一试？我认为，这些超级主力的过人之处，还是<strong>对于未来市场主流热点的预期、研判的功力深厚</strong>，任何人要是有这个本事，就一定会走在市场曲线的前面。<br>14、价量时空。<br>15、基本面分析公司未来价值，关注的是现在的股价，以及未来的股价定位，不太关心过去股价。<br>16、基本面分析的核心就是定价理论，即，对于现在股价是否合理进行评判——若低估了就可以买进。公司未来价值的预测，以期判断股价的上涨空间。巴菲特的办公室里是没有电脑的，但他非常关心现在的股票报价与其内在价值的关系，至于股票过去是什么价格或者什么走势，他也从来不看股价走势图。<br>17、市场面分析是通过比价关系来推测股价定位。所以，市场面分析主要是看现在股价与未来股价，对于过去股价也不是太关心。这很容易理解，若某个板块因热门概念而出现暴涨时，在依据比价关系挖掘该板块内的补涨股时，看绝对价格要比看历史走势重要得多，只要股价被低估，任何形态的股价走势都可以出现补涨。<br>18、技术分析的目的是为了预测股价未来走势，侧重于研究过去价格。它将股价走势图从基本面、市场面中抽提出来，让股价走势图完全独立了。走势图一旦独立，技术分析也就自成一统。技术分析将股价走势图看成一个活物留下的足迹，通过研究这些历史足迹，去预测这个活物下一步或者未来将走向何处。技术分析就是分析与预测<strong>这三种趋势的产生、持续与转换关系</strong>。<br>19、首先，技术分析要研究<strong>趋势的产生</strong>。<strong>一个新趋势的产生，一定是原有的其它两类趋势中的某一个终结的结果。</strong>如，一个新的上涨趋势的产生，就一定意味着一个原有的下跌趋势，或者横盘趋势的结束。所以，研究新趋势的产生，意味着要同时研究旧趋势的结束，两个相关趋势要同时研究。<br>20、其次，技术分析要研究趋势的持续。<strong>一个趋势一旦产生后，就会持续</strong>，这种持续就相当于趋势产生了顺势发展的惯性。很显然，假若能够认识到一个上涨趋势是处于持续发展中，或者惯性上涨中，那么，投资或者投机就变成了很简单的事情——买入持有，随着趋势惯性上涨就可以了；假若…<br>21、再次，技术分析还要研究趋势的结束。与研究趋势产生，本质上是一回事，只是研究的对象不同罢了<br>22、所有的技术分析方法，万变不离其宗，就是<strong>为了揭示趋势的产生、持续与结束</strong>，或者简言之，就是为了揭示趋势惯性。投机价值就是预期价值，而趋势惯性本身就具有预期性质，所以，趋势惯性能够提升或者降低投机价值。<br>23、波浪理论有某一浪的预期上涨高度、形态理论有形态突破后的预期量度涨幅、量价理论有放量突破后的惯性上涨高度，等等。224、股市有谚：横有多长，竖有多长。说的是一只股票若长期做底或者横盘，股价一旦启动向上突破，那么，涨幅机会十分惊人。这个惊人的涨幅，就是技术面预期类赋予的投机价值，因为这个投机价值的存在，使得股价最终具有了预期中的上涨空间。这是一个自我实现的预言——因为技术面给出了预期涨幅，那么，买方就会在涨幅到顶之前持续买入，以获取预期中的那个投机价值收益。<br>25、技术面预期类投机价值对于短线交易，特别是对于挖掘主升浪启动点或者启动阶段、主跌浪的启动点与启动阶段都是至关重要的。<br>26、对于短线交易来说，趋势、形态、量价关系是最重要的三个因素，而均线、指标等，就属于次级重要的因素了。<br>27、“济安金信价值分析系统”，该系统的主开发人杨健教授，说<strong>均线系统属于滞后指标</strong>，对于操作意义不大，而该系统运用了许多自创的新指标。<br>28、巴菲特说：“投资只需要学习两门课程就可以了，一门是如何评估企业价值，一门是如何看待股市波动。” </p>
<p>综上，<br>1、基本面预期<br>2、热点等市场面预期研判<br>3、戴维斯双击<br>4、领涨、补涨、跟涨虚高</p>
<br>

<h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>大体说的，也是已知的，但是给了个分析框架。<br>基本面向好，为什么不能反映在股价。为什么8个月涨了4倍多。涨停的逻辑在哪。等问题在框架内还是有一定程度解释力。</p>
<p>框架基本操作思路是牛股的大波段，选股思路为低估值+成长+题材。<br>并由力学中四种力，四种力的不同合力模式构成物体运动。<br>股市中不同合力模式构成股价上涨，主要三方面估值修复+价值成长+投机价值。<br>转而对原动力进行估值法定量衡量。<br>绝对估值法包含：PEG、隐蔽资产、要约收购。<br>比价效应带来领涨、补涨、跟涨虚高。而预期无参照物，不同于比价，即一切处于变化之中。<br>相对估值法包含：基本面预期、市场面预期(热点)、技术面预期、大盘面预期。</p>
<p>再统一，即为投资价值和投机价值。</p>
<p>补充：<br>基本面的信息主要包括政策性信息、行业性信息、经营信息（产品价格信息、重大合同信息、新项目与新产品信息）、财务信息（营收信息、净利润增减信息）等。<br>技术面信息主要包括价格图表、技术指标与交易信息，其中，价格图表是技术分析的核心要件，不同的交易者关注不同的图表；技术指标更是五花八门，多达数百种，只能是各取所需了；而交易信息主要是各种交易数据的排行榜，包括涨幅榜、换手率榜、成交量榜、量比榜、成交金额榜等。</p>
]]></content>
      <categories>
        <category>股市理论</category>
        <category>数女-谷</category>
      </categories>
      <tags>
        <tag>股市理论</tag>
      </tags>
  </entry>
  <entry>
    <title>面试题积累</title>
    <url>/2021/03/03/%E9%9D%A2%E8%AF%95%E9%A2%98%E7%A7%AF%E7%B4%AF/</url>
    <content><![CDATA[<h4 id="java"><a href="#java" class="headerlink" title="java"></a>java</h4><p>1、线程安全地使用list<br>Collections.SynchronizedList能把所有 List 接口的实现类转换成线程安全的List，比 Vector 有更好的扩展性和兼容性<br>java.util.concurrent.CopyOnWriteArrayList，读不加锁，写加锁、复制后写，读多写少的场景合适，写多的场景要复制，不合适。</p>
<a id="more"></a>

<p>2、异常类<br>javap -verbose看athrow<br>Error\Exception都是Throwable，Exception又分为检查和非检查。<br>JVM 规定继承自 RuntimeException 的异常都是 UncheckedException.<br>JVM 规定，每个函数必须对自己要抛出的异常心中有数，在函数声明时通过 throws 语句将该函数可能会抛出的异常声明出来。<br>finally的return会把其他的return给覆盖。</p>
<hr>
<p>3、HashMap、ConcurrentHashMap</p>
<ul>
<li><p>Node对象内部的hash字段，这个hash值是怎么得到呢？hash字段为什么采用高低位异或？</p>
<blockquote>
<p>当数组的长度很短时，只有低位数的hashcode值能参与运算。而让高16位参与运算可以更好的均匀散列，减少碰撞，进一步降低hash冲突的几率。并且使得高16位和低16位的信息都被保留了。</p>
</blockquote>
</li>
<li><p>填入table的数组的脚标怎么算的？<br>hash ^ (hash&gt;&gt;&gt; 16) (&gt;&gt;&gt;:无符号右移、高位补0)<br>(len-1) &amp; hash</p>
</li>
<li><p>put数据的过程？<br>分四种情况。无数据则直接放入，有链且key同则替换，有链且key不同则尾插(再判断大小看是否树化)，红黑树则红黑树插入。</p>
</li>
<li><p>红黑树的写入操作，是怎么找到父节点的，找父节点流程？</p>
</li>
<li><p>TreeNode数据结构。</p>
</li>
</ul>
<p>TreeNode继承了LinkedHashMap内部类LinkedHashMap.Entry，LinkedHashMap.Entry又继承自HashMap.Node。这些字段跟Entry，Node中的字段一样，是使用默认访问权限的，所以子类可以直接使用父类的属性。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123;</span><br><span class="line">    TreeNode&lt;K,V&gt; parent;  &#x2F;&#x2F; 红黑树父节点</span><br><span class="line">    TreeNode&lt;K,V&gt; left;    &#x2F;&#x2F;左子节点</span><br><span class="line">    TreeNode&lt;K,V&gt; right;   &#x2F;&#x2F;右子节点	</span><br><span class="line">    TreeNode&lt;K,V&gt; prev;    &#x2F;&#x2F; 删除后需要取消链接，指向前一个节点（原链表中的前一个节点）</span><br><span class="line">    boolean red;		   &#x2F;&#x2F;红黑树精髓 red</span><br><span class="line">    TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        super(hash, key, val, next);</span><br><span class="line">    &#125;　　　　 &#x2F;&#x2F;省略后续代码</span><br><span class="line"></span><br><span class="line">static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123;</span><br><span class="line">    Entry&lt;K,V&gt; before, after;</span><br><span class="line">    Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">        super(hash, key, value, next);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><p>红黑树的原则有哪些呢？<br>root、叶子为黑；黑高相同；红色孩子为黑</p>
</li>
<li><p>JDK8 hashmap为什么引入红黑树？解决什么问题？<br>hash冲突较多时，查询和插入、删除的性能。保证查询效率（O(logn)）</p>
</li>
<li><p>hashmap扩容后，老表的数据怎么迁移到扩容后的表的呢？hashmap扩容后，迁移数据发现该slot是颗红黑树，怎么处理呢？<br>数组翻倍扩容，将旧数据每个key都按照脚标公式重新计算。红黑树则进行insert操作。</p>
</li>
<li><p>为什么hashmap大小要为2的幂次方数<br>一个key的hashCode是一个int整数，而int在内存中是以二进制数存储，位运算比运算符运算更高效。当长度为2的幂次方数时，hash &amp; (length -1) = hash % length</p>
</li>
</ul>
<hr>
<p>4、ConcurrentHashMap</p>
<ul>
<li><p>多线程下的hashmap替代<br>Collections.synchronizedMap(Map)创建线程安全的map集合；Hashtable；ConcurrentHashMap</p>
</li>
<li><p>Collections.synchronizedMap是怎么实现线程安全<br>在SynchronizedMap内部维护了一个普通对象Map，还有排斥锁mute。<code>Collections.synchronizedMap(new HashMap&lt;&gt;(16));</code>将对象排斥锁赋值为this。创建出synchronizedMap之后，再操作map的时候，就会对方法上锁。</p>
</li>
<li><p>HashTable？</p>
</li>
</ul>
<p>1.实现：Hashtable 继承了 Dictionary类，而 HashMap 继承的是 AbstractMap 类。<br>2.并发：HashMap相比Hashtable是线程安全的，但是是synchronized效率不高。<br>3.异常：Hashtable 是不允许键或值为 null 的，HashMap 的键值则都可以为 null。即为Hashtable在我们put 空值的时候会直接抛空指针异常，但是HashMap做了特殊处理。<br>Hashtable使用的是安全失败机制（fail-safe），这种机制会使你此次读到的数据不一定是最新的数据。如果你使用null值，就会使得其无法判断对应的key是不存在还是为空，因为你无法再调用一次contain(key）来对key是否存在进行判断，ConcurrentHashMap同理。<br>4.初始化、扩容不同<br>5.迭代器不同：HashMap 中的 Iterator 迭代器是 fail-fast 的，而 Hashtable 的 Enumerator 不是 fail-fast 的。所以，当其他线程改变了HashMap 的结构，如：增加、删除元素，将会抛出ConcurrentModificationException 异常，而 Hashtable 则不会。</p>
<ul>
<li><p>concurrenthashmap并发度设计？<br>ConcurrentHashMap 采用了分段锁技术，其中 Segment 继承于 ReentrantLock。理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。1.8采用了 CAS + synchronized 来保证并发安全性。</p>
</li>
<li><p>1.7如何解决HahsMap闭环问题<br>Segment 对象是一把锁，所以在 rehash 的过程中，其他线程无法对segment 的 hash 表做操作</p>
</li>
<li><p>put?</p>
</li>
</ul>
<p>1.7时：<br>根据key的hash值，在Segment数组中找到相应的位置，如果相应位置的Segment还未初始化，则通过CAS进行赋值。首先第一步的时候会尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁。尝试自旋获取锁。如果重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取，保证能获取成功。如果已经初始化，则执行Segment对象的put方法通过加锁机制插入数据。</p>
<p>1.8时：<br>key val必须不为空。根据 key 计算出 hashcode 。判断是否需要进行初始化–initTable 方法初始化。<br>初始化流程：使用了 CAS ，1、判断 sizeCtl 值是否小于 0，如果小于 0 则表示 ConcurrentHashMap 正在执行初始化操作，所以需要先等待一会，如果其它线程初始化失败还可以顶替上去。2、如果 sizeCtl 值大于等于 0，则基于 CAS 策略抢占标记 sizeCtl 为 -1，表示ConcurrentHashMap 正在执行初始化，然后构造 table，并更新 sizeCtl 的值<br>即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。如果当前位置的 hashcode == MOVED == -1,则需要进行扩容。如果都不满足，则利用 synchronized 锁把头节点被锁住了，保证了同时只有一个线程修改链表，防止出现链表成环。写入数据后，如果数量大于 TREEIFY_THRESHOLD 则要转换为红黑树。</p>
<ul>
<li>size？</li>
</ul>
<p>1.7：<br>先采用不加锁的方式，连续计算元素的个数，最多计算3次：如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数；</p>
<p>1.8：<br>1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount1.8中的size实现比1.7简单多，因为元素个数保存baseCount中，部分元素的变化个数保存在CounterCell数组。累加baseCount和CounterCell数组中的数量，即可得到元素的总个数</p>
<ul>
<li>transfer、helper（并发扩容）</li>
</ul>
<hr>
<p>5、fail-fast？<br>1.原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变modCount的值。每当迭代器使用hashNext()/next()遍历下一个元素之前，都会检测modCount变量是否为expectedmodCount值，是的话就返回遍历；否则抛出异常，终止遍历。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。<br>2.java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改<br>3.安全失败（fail—safe）：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。</p>
<p>6、volatile<br>保证了不同线程对这个变量进行操作时的可见性；禁止进行指令重排序（实现有序性）；volatile 只能保证对单次读/写的原子性。i++ 这种操作不能保证原子性。</p>
<p>7、cas<br>CAS 只能保证一个共享变量的原子操作。<br>是乐观锁的一种实现方式，是一种轻量级锁。在准备写回数据时，比较原值是否修改，若未被其他线程修改则写回，若已被修改，则重新执行读取流程。这是一种乐观策略，认为并发操作并不总会发生。<br>ABA问题，CAS就无法判断了。用版本号 时间戳去保证。<br>自旋，cpu消耗大，不适合高并发。</p>
<p>8、锁升级<br>针对 synchronized 获取锁的方式，JVM 使用了锁升级的优化方式，就是先使用偏向锁优先同一线程然后再次获取锁，如果失败，就升级为 CAS 轻量级锁，如果失败就会短暂自旋，防止线程被系统挂起。最后如果以上都失败就升级为重量级锁。</p>
<hr>
<p>9、synchronized<br>monitorenter和monitorexit – 挂起或者唤醒一个线程都需要操作系统 –用户和内核切换<br>对象锁锁的计算器-阻塞<br>自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。<br>修饰实例方法–对象实例的锁<br>修饰静态方法–当前类对象的锁<br>不要使用 synchronized(String a) – 字符串常量池 缓冲功能<br>JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。</p>
<p>10、ReentrantLock<br>放弃等待，避免出现死锁<br>申请锁的时间顺序获得，默认非公平。<br>内部类Sync管理锁， 有两个实现，分别为 NonfairSync（非公平锁）和 FairSync（公平锁）<br>基于AQS<br>同时绑定对个对象</p>
<p>11、java 中断机制</p>
<p>12、condition状态</p>
<p>13、AQS<br>AQS 中采用了 LockSupport.park(thread) 来挂起线程，用 unpark 来唤醒线程</p>
<p>每个线程被封装成一个Node，包含waitstatus(该线程的status)：不抢了、唤醒下一个、停在某个condition上、propagate。每个 node 在入队的时候，都会把前驱节点的状态改为 SIGNAL，然后阻塞，等待被前驱唤醒。这里涉及的是两个问题：有线程取消了排队、唤醒操作。</p>
<p>AQS中包含state(锁的status)：0代表没有被占用，大于 0 代表有线程持有当前锁，这个值可以大于 1，是因为锁可以重入，每次重入都加上 1</p>
<p>公平锁：<code>if (!tryAcquire(arg) &amp;&amp;  &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) </code>先try，没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。</p>
<p>tryAcquire(arg)</p>
<blockquote>
<p>1如果队列每人，cas获取，没获取到，说明刚有人获取了，获取到的人标记下自己获取了。<br>2如果是重入的情况，计数+1。<br>3都不是则获取失败<br>返回true：1.没有线程在等待锁且CAS获取成功；2.重入锁，线程本来就持有锁，也就可以理所当然可以直接获取</p>
</blockquote>
<p>acquireQueued(addWaiter(Node.EXCLUSIVE), arg)</p>
<blockquote>
<p>1队列不空则CAS加入队尾2队列空或者CAS失败，则进入enq(node);<br>通过上面的操作已经入队了。在判断，自己是否是队头，再tryAcquire，获得了返回false。<br>否则不是队头、也没try成功，就shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()。</p>
</blockquote>
<p>enq(node)</p>
<blockquote>
<p>for (;;) 自旋入队，CAS竞争一次竞争不到，就多次竞争，总会排到的</p>
</blockquote>
<p>14、常见函数</p>
<ul>
<li><p>sleep()<br>不释放对象锁;要捕捉异常;可以使低优先级的线程得到执行的机会<br>在一个运行系统中，如果较高优先级的线程没有调用sleep方法，也没有受到I/O阻塞，那么较低优先级线程只能等待所有较高优先级的线程运行结束。</p>
</li>
<li><p>join()<br>等待该方法的线程执行完毕后再往下继续;要捕捉异常</p>
</li>
<li><p>yield()<br>与sleep()类似，只是不能由用户指定暂停多长时间。使当前线程让出CPU占有权，但让出的时间是不可设定;只能让同优先级的线程有执行的机会;不释放锁标志</p>
</li>
<li><p>wait()和notify()、notifyAll()</p>
</li>
</ul>
<ol>
<li>协调多个线程对共享数据的存取，所以必须在synchronized语句块内使用。否则能编译通过，但在运行时会IllegalMonitorStateException的异常。</li>
<li>能在当前线程还没退出synchronized数据块时让其他线程也有机会访问共享数据</li>
<li>wait()当前线程暂停执行并释放对象锁标示，让其他线程可以进入synchronized数据块 &amp;&amp;当前线程被放入对象等待池中</li>
<li>当调用notify()方法后，将从对象的等待池中移走一个任意的线程并放到锁标志等待池中，只有锁标志等待池中线程能够获取锁标志；如果锁标志等待池中没有线程，则notify()不起作用。notifyAll()则从对象等待池中移走所有等待那个对象的线程并放到锁标志等待池中。</li>
<li>这三个方法都是java.lang.Object的方法。<br>sleep()和yield()是Thread类的方法。</li>
</ol>
<p>15、中断两种情况<br>一种是当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位，另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码(其实就是结束run方法体的代码)。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public void run()&#123;</span><br><span class="line">    try &#123;</span><br><span class="line">    &#x2F;&#x2F;判断当前线程是否已中断,注意interrupted方法是静态的,执行后会对中断状态进行复位</span><br><span class="line">    while (!Thread.interrupted()) &#123;</span><br><span class="line">        TimeUnit.SECONDS.sleep(2);</span><br><span class="line">    &#125;</span><br><span class="line">    &#125; catch (InterruptedException e) &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>16、</p>
<ul>
<li>应用</li>
</ul>
<ol>
<li><p>修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁</p>
</li>
<li><p>修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁</p>
</li>
<li><p>修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。</p>
</li>
</ol>
<ul>
<li>知识</li>
</ul>
<ol>
<li>JVM中，对象在堆内存中的布局分为三块区域：<strong>对象头</strong>、<strong>实例数据</strong>（类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对）和<strong>对齐填充</strong>（虚拟机要求对象起始地址必须是8字节的整数倍）。</li>
<li>jvm中采用2个字来存储对象头(如果对象是数组则会分配3个字，多出来的1个字记录的是数组长度)，其主要结构是由<strong>Mark Word 和 Class Metadata Address</strong>组成</li>
<li>重量级锁也就是通常说synchronized的对象锁，<strong>锁标识位为10，其中指针指向的是 <em>monitor对象（也称为管程或监视器锁）</em> 的起始地址</strong>。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的（位于HotSpot虚拟机源码ObjectMonitor.hpp）</li>
<li>Monitor中有两个队列，_WaitSet 和 _EntryList，用来保存ObjectWaiter对象列表( 每个等待锁的线程都会被封装成<strong>ObjectWaiter</strong>对象)，_owner指向持有ObjectMonitor对象的线程，当多个线程同时访问一段同步代码时，首先会进入 <strong>_EntryList(处于等待锁block状态的线程，会被加入到该列表)</strong> 集合，当线程获取到对象的monitor 后进入 _Owner 区域并把monitor中的owner变量设置为当前线程同时monitor中的计数器count加1，</li>
</ol>
<p><strong>若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入 WaitSet集合中等待被唤醒</strong>。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。<br>5. monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁，因此：Java中任意对象可以作为锁，notify/notifyAll/wait等方法存在于顶级对象Object中<br>6. 在对代码块synchronized时，是monitorenter 和 monitorexit指令来控制的 ：monitorenter指令指向同步代码块的开始位置，monitorexit指令则指明同步代码块的结束位置，当执行monitorenter指令时，当前线程将试图获取 <strong>objectref(即对象锁)</strong> 所对应的 monitor 的持有权，当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。<br>7. 编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，<strong>编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令</strong>。<br>8. 方法级的synchronized是隐式，即无需通过字节码指令来控制的，它实现在<strong>方法调用和返回操作</strong>之中。JVM可以从方法常量池中的<strong>方法表结构(method_info Structure)</strong> 中的 <strong>ACC_SYNCHRONIZED 访问标志</strong>区分一个方法是否同步方法。<br>当方法调用时，调用指令将会 检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先持有monitor（虚拟机规范中用的是管程一词）， 然后再执行方法，最后在方法完成(无论是正常完成还是非正常完成)时释放monitor。在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。<br>9. synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的Mutex Lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因。Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了<strong>轻量级锁和偏向锁</strong>。</p>
<ul>
<li>优化</li>
</ul>
<ol>
<li>多数时锁不仅不存在多线程竞争，而且总是由<strong>同一线程多次获得</strong>，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提供程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是<strong>先升级为轻量级锁</strong>。</li>
<li>轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。</li>
<li>轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。</li>
<li>Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。</li>
</ol>
<ul>
<li>中断、 wait &amp; notify</li>
</ul>
<ol>
<li>对于synchronized来说，如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效</li>
<li>调用这几个方法前必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，在前面的分析中，我们知道monitor 存在于对象头的Mark Word 中(存储monitor引用指针)，而synchronized关键字可以获取 monitor ，这也就是为什么notify/notifyAll和wait方法必须在synchronized代码块或者synchronized方法调用的原因。</li>
<li>同时notify/notifysAll方法调用后，并不会马上释放监视器锁，而是在相应的synchronized(){}/synchronized方法执行结束后才自动释放锁。</li>
</ol>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
</search>
